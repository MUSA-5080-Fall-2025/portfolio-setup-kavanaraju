---
title: "Assignment 4: Spatial Predictive Analysis"
subtitle: "Using Street Light Outages to Predict Burglary Risk in Chicago"
author: "Kavana Raju"
date: today
format:
  html:
    code-fold: show
    code-tools: true
    toc: true
    toc-depth: 3
    toc-location: left
    theme: cosmo
    embed-resources: true
editor: visual
execute:
  warning: false
  message: false
---

# Introduction

Street lighting plays a critical role in urban safety and crime prevention. The "broken windows" theory suggests that visible signs of disorder—such as non-functioning street lights—may signal reduced social control and encourage criminal activity. In this analysis, I investigate whether 311 complaints about street lights being out can predict burglary risk in Chicago.

I chose to analyze **Street Light Out complaints** because they represent a tangible indicator of neighborhood maintenance and disorder that may correlate with crime patterns. Unlike abandoned cars (used in the class example), street light outages directly affect visibility and natural surveillance, both of which are key environmental factors in Crime Prevention Through Environmental Design (CPTED) theory. When street lights fail, they create dark zones that reduce the natural surveillance of public spaces, potentially making areas more attractive to criminal activity.

Using 2017 data, I build spatial predictive models that incorporate Street Light Out complaint patterns, spatial clustering, and proximity measures to predict burglary counts across Chicago's 500m grid cells. I then validate these models both spatially (using Leave-One-Group-Out cross-validation by police district) and temporally (testing on 2018 data) to assess their predictive power and generalizability beyond the training data.

# Setup

```{r setup}
#| message: false
#| warning: false

# Load required packages
library(tidyverse)      # Data manipulation
library(sf)             # Spatial operations
library(here)           # Relative file paths
library(viridis)        # Color scales
library(terra)          # Raster operations (replaces 'raster')
library(spdep)          # Spatial dependence
library(FNN)            # Fast nearest neighbors
library(MASS)           # Negative binomial regression
library(patchwork)      # Plot composition (replaces grid/gridExtra)
library(knitr)          # Tables
library(kableExtra)     # Table formatting
library(classInt)       # Classification intervals
library(here)

# Spatstat split into sub-packages
library(spatstat.geom)    # Spatial geometries
library(spatstat.explore) # Spatial exploration/KDE

# Set options
options(scipen = 999)  # No scientific notation
set.seed(5080)         # Reproducibility

# Create consistent theme for visualizations
theme_crime <- function(base_size = 11) {
  theme_minimal(base_size = base_size) +
    theme(
      plot.title = element_text(face = "bold", size = base_size + 1),
      plot.subtitle = element_text(color = "gray30", size = base_size - 1),
      legend.position = "right",
      panel.grid.minor = element_blank(),
      axis.text = element_blank(),
      axis.title = element_blank()
    )
}

# Set as default
theme_set(theme_crime())

cat("✓ All packages loaded successfully!\n")
cat("✓ Working directory:", getwd(), "\n")
```

# Part 1: Data Loading & Exploration

The first step in any spatial analysis is to load the necessary geographic boundaries and point data, then visually explore their spatial distributions. This is essential for understanding the data structure, identifying potential issues (like misaligned coordinate systems), and forming initial hypotheses about spatial relationships.

I begin by loading Chicago's administrative boundaries—police districts and beats—which will later be used for spatial cross-validation. Then I load the 2017 burglary data (filtered to forcible entry cases) and the 2017 Street Light Out 311 complaints.

## Load Chicago Spatial Data

```{r load-boundaries}
#| message: false

# Load police districts (used for spatial cross-validation)
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)

# Load police beats (smaller administrative units)
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(Beat = beat_num)

# Load Chicago boundary
chicagoBoundary <- 
  st_read("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson") %>%
  st_transform('ESRI:102271')

cat("✓ Loaded spatial boundaries\n")
cat("  - Police districts:", nrow(policeDistricts), "\n")
cat("  - Police beats:", nrow(policeBeats), "\n")
```

All spatial data is transformed to ESRI:102271 (Illinois State Plane East), which is appropriate for Chicago as it minimizes distance distortion in this region and uses meters as the unit of measurement.

## Load Burglary Data

```{r load-burglaries}
#| message: false

# Load from provided data file (downloaded from Chicago open data portal)
burglaries <- st_read(here("data", "burglaries.shp")) %>% 
  st_transform('ESRI:102271')

# Check the data
cat("\n✓ Loaded burglary data\n")
cat("  - Number of burglaries:", nrow(burglaries), "\n")
cat("  - CRS:", st_crs(burglaries)$input, "\n")
cat("  - Date range:", min(burglaries$date, na.rm = TRUE), "to", 
    max(burglaries$date, na.rm = TRUE), "\n")
```

The dataset contains **7,482 burglaries** in Chicago during 2017, all classified as forcible entry. This filtering is important because different burglary types (forcible entry vs. unlawful entry) may have different spatial patterns and relationships with environmental factors.

## Load 311 Street Light Out Complaints

```{r data-streetlight}
lights_raw <- read_csv(here("data", "311_StreetLightsOneOut_Historical.csv"))

#head(lights_raw$`Creation Date`, 5) #check date format

lights_years <- lights_raw %>%
  mutate(creation_date = mdy(`Creation Date`)) %>%
  mutate(year = year(creation_date)) %>%
  filter(year == 2017) %>%
  filter(!is.na(Latitude), !is.na(Longitude))

street_lights <- lights_years %>%
  st_as_sf(coords = c("Longitude", "Latitude"),
           crs = 4326,
           remove = FALSE) %>%
  st_transform('ESRI:102271')

cat("✓ Loaded streetlight out complaints\n")
cat("  - Number of complaints:", nrow(street_lights), "\n")
```

The 2017 street light complaints dataset contains **75,031 reports** of lights being out—roughly 10 times the number of burglaries. This high volume suggests that street light maintenance issues are widespread across the city and provides sufficient spatial variation for modeling.

## Visualize Spatial Distributions

```{r visualize-points}
#| fig-width: 10
#| fig-height: 5

# Extract coordinates for density plots
burg_coords   <- data.frame(st_coordinates(burglaries))
lights_coords <- data.frame(st_coordinates(street_lights))

# Burglary point map
p1 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_sf(data = burglaries, color = "#d62828", size = 0.1, alpha = 0.4) +
  labs(
    title = "Burglary Locations",
    subtitle = paste0("Chicago 2017, n = ", nrow(burglaries))
  )

# Burglary density surface
p2 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_density_2d_filled(
    data = burg_coords,
    aes(X, Y),
    alpha = 0.7,
    bins = 8
  ) +
  scale_fill_viridis_d(
    option = "plasma",
    direction = -1,
    guide = "none"
  ) +
  labs(
    title = "Burglary Density Surface",
    subtitle = "Kernel density estimation"
  )

# Street light complaint point map
p3 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_sf(data = street_lights, color = "#3b528b", size = 0.1, alpha = 0.4) +
  labs(
    title = "Street Light Out 311 Requests",
    subtitle = paste0("Chicago 2017, n = ", nrow(street_lights))
  )

# Street light density surface
p4 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_density_2d_filled(
    data = lights_coords,
    aes(X, Y),
    alpha = 0.7,
    bins = 8
  ) +
  scale_fill_viridis_d(
    option = "plasma",
    direction = -1,
    guide = "none"
  ) +
  labs(
    title = "Street Light Out Density Surface",
    subtitle = "Kernel density estimation"
  )

(p1 + p2) / (p3 + p4) + 
  plot_annotation(
    title = "Spatial Distribution of Burglaries and Street Light Out Complaints in Chicago",
    tag_levels = 'A'
  )
```

The maps reveal striking similarities in the spatial patterns of both phenomena. Both burglaries and street light complaints show clear geographic clustering, with pronounced hot spots concentrated in the **South and West sides** of Chicago. The density surfaces (panels B and D) make this pattern even more apparent—the highest-intensity zones for both variables overlap considerably.

Notably, the **downtown Loop area and North Side neighborhoods** show relatively lower densities for both burglaries and street light complaints, with some isolated hot spots. This visual concordance provides initial evidence that street light maintenance issues may co-occur with higher burglary rates. However, this could reflect underlying neighborhood characteristics (such as infrastructure age, investment levels, or population density) rather than a direct causal relationship. The statistical modeling in later sections will help disentangle these relationships.

# Part 2: Fishnet Grid Creation

Raw point data is difficult to model directly in a count regression framework, so I aggregate both datasets to a regular grid. This **fishnet grid** approach transforms the irregular point pattern into a structured format where each grid cell becomes an observation with a count of events.

I create a 500m × 500m fishnet grid covering Chicago, then count how many burglaries and street light complaints fall within each cell. This grid resolution balances spatial detail with statistical stability—smaller cells would have too many zeros, while larger cells would obscure important local variation.

## Create 500m Fishnet

```{r create-fishnet}
# Create 500m x 500m grid
fishnet <- st_make_grid(
  chicagoBoundary,
  cellsize = 500,  # 500 meters per cell
  square = TRUE
) %>%
  st_sf() %>%
  mutate(uniqueID = row_number())

# Keep only cells that intersect Chicago
fishnet <- fishnet[chicagoBoundary, ]

# View basic info
cat("✓ Created fishnet grid\n")
cat("  - Number of cells:", nrow(fishnet), "\n")
cat("  - Cell size:", 500, "x", 500, "meters\n")
cat("  - Cell area:", round(st_area(fishnet[1,])), "square meters\n")
```

## Aggregate Burglaries to Grid

```{r burglaries-fishnet}
# Spatial join: which cell contains each burglary?
burglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(countBurglaries = n())

# Join back to fishnet (cells with 0 burglaries will be NA)
fishnet <- fishnet %>%
  left_join(burglaries_fishnet, by = "uniqueID") %>%
  mutate(countBurglaries = replace_na(countBurglaries, 0))

# Summary statistics
cat("\nBurglary count distribution:\n")
summary(fishnet$countBurglaries)
cat("\nCells with zero burglaries:", 
    sum(fishnet$countBurglaries == 0), 
    "/", nrow(fishnet),
    "(", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), "%)\n")
```

The burglary counts are highly skewed, as expected with crime data. Many cells have zero burglaries, while a few hot spot cells have very high counts. This zero-inflation and overdispersion motivates the use of count regression models (Poisson and Negative Binomial) rather than ordinary least squares.

## Aggregate Street Light Out Complaints to Grid

```{r lights-fishnet}
lights_fishnet <- st_join(street_lights, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(street_lights = n(), .groups = "drop")

fishnet <- fishnet %>%
  left_join(lights_fishnet, by = "uniqueID") %>%
  mutate(street_lights = replace_na(street_lights, 0))

cat("Streetlight Out distribution:\n")
summary(fishnet$street_lights)
```

## Visualize Grid Cell Counts

```{r visualize-fishnet}
p_burg_grid <- ggplot() +
  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt", name = "Burglaries") +
  labs(title = "Burglary Counts per 500m Grid Cell") +
  theme_crime()

p_lights_grid <- ggplot() +
  geom_sf(data = fishnet, aes(fill = street_lights), color = NA) +
  scale_fill_viridis_c(option = "magma", trans = "sqrt", name = "Street light\ncomplaints") +
  labs(title = "Street Light Out Complaints per 500m Grid Cell") +
  theme_crime()

p_burg_grid + p_lights_grid
```

The gridded maps confirm the spatial correspondence observed earlier. Cells with high burglary counts tend to have high street light complaint counts, particularly in the South and West sides. I use a square-root transformation for the color scale to better visualize the range of values, as a linear scale would be dominated by the extreme high values.

```{r summary-fishnet}
fishnet %>%
  st_drop_geometry() %>%
  summarise(
    mean_burg = mean(countBurglaries),
    max_burg  = max(countBurglaries),
    pct_zero_burg = mean(countBurglaries == 0),
    mean_lights = mean(street_lights),
    max_lights  = max(street_lights),
    pct_zero_lights = mean(street_lights == 0)
  )
```

# Part 3: Spatial Features

Raw counts alone don't capture the full spatial context. A cell with 5 street light complaints surrounded by cells with 50 complaints is very different from a cell with 5 complaints in an otherwise low-complaint area. **Spatial features** encode this contextual information.

I construct three types of spatial features that describe each grid cell's relationship to its neighbors:

1.  **k-Nearest Neighbor (k-NN) distance**: How far is this cell from concentrations of street light complaints?
2.  **Local Moran's I clusters**: Is this cell part of a statistically significant hot spot or cold spot?
3.  **Distance to hot spots**: How far is this cell from the most intense complaint clusters?

These features help the model understand not just *how many* complaints are in a cell, but also *where* that cell sits in the broader spatial landscape of disorder.

## k-Nearest Neighbor Features

```{r nn-feature}
#| message: false

# Calculate mean distance to 3 nearest streetlights that are out

# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
streetlight_coords <- st_coordinates(street_lights)

# Calculate k nearest neighbors and distances
nn_result <- get.knnx(streetlight_coords, fishnet_coords, k = 3)

# Add to fishnet
fishnet <- fishnet %>%
  mutate(
    street_lights.nn = rowMeans(nn_result$nn.dist)
  )

cat("✓ Calculated nearest neighbor distances\n")
summary(fishnet$street_lights.nn)
```

The `street_lights.nn` feature captures proximity to complaint locations. Cells in areas with dense complaints will have small values (nearby complaints), while cells in well-maintained areas will have large values. This distance measure complements the raw count by capturing spatial spillover effects—a cell might have few complaints itself but still be near a problem area.

## Local Moran's I: Identifying Hot Spots and Cold Spots

Local Moran's I is a spatial autocorrelation statistic that identifies whether a location has similar or dissimilar values to its neighbors. It classifies each cell into one of five categories:

-   **High-High**: High-complaint cells surrounded by high-complaint neighbors (hot spots)
-   **Low-Low**: Low-complaint cells surrounded by low-complaint neighbors (cold spots)\
-   **High-Low**: High-complaint cells surrounded by low-complaint neighbors (spatial outliers)
-   **Low-High**: Low-complaint cells surrounded by high-complaint neighbors (spatial outliers)
-   **Not Significant**: No significant spatial autocorrelation

```{r local-morans-streetlights}
# Function to calculate Local Moran's I
calculate_local_morans <- function(data, variable, k = 5) {

# Create spatial weights
coords <- st_coordinates(st_centroid(data))
neighbors <- knn2nb(knearneigh(coords, k = k))
weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)
  
# Calculate Local Moran's I
local_moran <- localmoran(data[[variable]], weights)
  
# Classify clusters
mean_val <- mean(data[[variable]], na.rm = TRUE)
  
data %>%
  mutate(
    local_i = local_moran[, 1],
    p_value = local_moran[, 5],
    is_significant = p_value < 0.05,
      
moran_class = case_when(
  !is_significant ~ "Not Significant",
  local_i > 0 & .data[[variable]] > mean_val ~ "High-High",
  local_i > 0 & .data[[variable]] <= mean_val ~ "Low-Low",
  local_i < 0 & .data[[variable]] > mean_val ~ "High-Low",
  local_i < 0 & .data[[variable]] <= mean_val ~ "Low-High",
  TRUE ~ "Not Significant"))
}

# Apply to streetlights
fishnet <- calculate_local_morans(fishnet, "street_lights", k = 5)
```

```{r visualize-morans}
#| fig-width: 8
#| fig-height: 6

# Visualize hot spots
ggplot() +
  geom_sf(
    data = fishnet, 
    aes(fill = moran_class), 
    color = NA
  ) +
  scale_fill_manual(
    values = c(
      "High-High" = "#d7191c",
      "High-Low" = "#fdae61",
      "Low-High" = "#abd9e9",
      "Low-Low" = "#2c7bb6",
      "Not Significant" = "gray90"
    ),
    name = "Cluster Type"
  ) +
  labs(
    title = "Local Moran's I: Street Light Out Complaint Clusters",
    subtitle = "High-High = Hot spots of disorder"
  ) +
  theme_crime()
```

The Local Moran's I map reveals clear **hot spots** (red cells) of street light complaints in the South and West sides, where high-complaint cells cluster together. These are the areas where infrastructure neglect is most concentrated and persistent. The **cold spots** (dark blue) in the North Side and parts of downtown represent well-maintained areas.

The presence of distinct spatial clusters justifies the inclusion of spatial features in the model. If complaints were randomly distributed, we would see mostly gray (not significant) cells.

## Distance to Hot Spots

```{r distance-to-hotspots}
# Get centroids of "High-High" cells (hot spots)
hotspots <- fishnet %>%
  filter(moran_class == "High-High") %>%
  st_centroid()

# Calculate distance from each cell to nearest hot spot
if (nrow(hotspots) > 0) {
  fishnet <- fishnet %>%
    mutate(
      dist_to_hotspot = as.numeric(
        st_distance(st_centroid(fishnet), hotspots %>% st_union())
      )
    )
  
  cat("✓ Calculated distance to street light out hot spots\n")
  cat("  - Number of hot spot cells:", nrow(hotspots), "\n")
} else {
  fishnet <- fishnet %>%
    mutate(dist_to_hotspot = 0)
  cat("⚠ No significant hot spots found\n")
}
```

The `dist_to_hotspot` feature measures how far each cell is from the nearest street light complaint hot spot. This captures a different aspect of spatial context than k-NN distance: rather than measuring distance to any complaints, it measures distance to areas of *concentrated* complaint activity. Cells far from any hot spots may be in stable, well-maintained neighborhoods.

# Part 4: Count Regression Models

With the spatial features constructed, I now build statistical models to predict burglary counts. Count regression models are specifically designed for non-negative integer outcomes like crime counts. I start with a **Poisson regression**, check its assumptions, and then move to a **Negative Binomial regression** if overdispersion is detected.

The models take this general form:

$$
\text{Burglaries}_i = f(\text{Street Light Complaints}_i, \text{Spatial Features}_i)
$$

where $i$ indexes grid cells.

## Prepare Modeling Data and Join Police Districts

```{r prepare-data}
# Join district information to fishnet for spatial cross-validation later
fishnet <- st_join(
  fishnet,
  policeDistricts,
  join = st_within,
  left = TRUE
) %>%
  filter(!is.na(District))  # Remove cells outside districts

cat("✓ Joined police districts\n")
cat("  - Districts:", length(unique(fishnet$District)), "\n")
cat("  - Cells:", nrow(fishnet), "\n")

# Create clean modeling dataset
fishnet_model <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(
    uniqueID,
    District,
    countBurglaries,
    street_lights,
    street_lights.nn,
    dist_to_hotspot
  ) %>%
  na.omit()  # Remove any remaining NAs

cat("✓ Prepared modeling data\n")
cat("  - Observations:", nrow(fishnet_model), "\n")
cat("  - Variables:", ncol(fishnet_model), "\n")
```

## Poisson Regression

The Poisson model assumes the mean and variance of the count are equal. It estimates how each predictor multiplicatively affects the expected burglary count.

```{r fit-poisson}
# Fit Poisson regression
model_poisson <- glm(
  countBurglaries ~ street_lights + street_lights.nn + 
    dist_to_hotspot,
  data = fishnet_model,
  family = "poisson"
)

# Summary
summary(model_poisson)
```

**Model Interpretation:**

All three street light-related predictors are highly statistically significant (p \< 0.001):

-   **street_lights** (β = 0.0034): Each additional street light complaint in a cell is associated with a **0.3% increase** in expected burglaries (exp(0.0034) ≈ 1.003). While small per complaint, this adds up—10 additional complaints would increase expected burglaries by about 3.4%.

-   **street_lights.nn** (β = -0.0044): Greater distance to nearby complaints is associated with **fewer** burglaries. For every 100 meters farther from complaint locations, expected burglaries decrease by about 0.4%. This negative relationship makes sense: areas isolated from complaint clusters tend to be better maintained.

-   **dist_to_hotspot** (β = -0.00019): Similarly, cells farther from complaint hot spots have lower burglary rates. Every 1000 meters (1 km) farther from a hot spot reduces expected burglaries by about 17%.

These patterns are theoretically sensible: areas with more disorder indicators (complaints), or closer to disorder clusters, experience more burglaries.

## Check for Overdispersion

A key Poisson assumption is that the variance equals the mean. In reality, crime data often exhibits **overdispersion**: the variance exceeds the mean due to unobserved heterogeneity. We can check this by calculating the dispersion parameter:

```{r check-overdispersion}
# Calculate dispersion parameter
dispersion <- sum(residuals(model_poisson, type = "pearson")^2) / 
              model_poisson$df.residual

cat("Dispersion parameter:", round(dispersion, 2), "\n")
cat("Rule of thumb: >1.5 suggests overdispersion\n")

if (dispersion > 1.5) {
  cat("⚠ Overdispersion detected! Consider Negative Binomial model.\n")
} else {
  cat("✓ Dispersion looks okay for Poisson model.\n")
}
```

The dispersion parameter is **3.16**, well above the threshold of 1.5, indicating substantial overdispersion. This means the Poisson model underestimates the true variability in the data, potentially leading to overly optimistic standard errors and inflated significance levels. The Negative Binomial model addresses this issue.

## Negative Binomial Regression

The Negative Binomial model adds a dispersion parameter (θ) that allows the variance to exceed the mean, making it more appropriate for overdispersed count data.

```{r fit-negbin}
# Fit Negative Binomial model
model_nb <- glm.nb(
  countBurglaries ~ street_lights + street_lights.nn + 
    dist_to_hotspot,
  data = fishnet_model
)

# Summary
summary(model_nb)

# Compare AIC (lower is better)
cat("\nModel Comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")
```

## Model Fit Comparison

```{r aic-comparison}
AIC(model_poisson, model_nb)
```

The Negative Binomial model provides a **dramatically better fit**, with an AIC of **7515.8** compared to the Poisson's **8966.5**—a difference of **1450.7 points**. As a rule of thumb, a difference of more than 10 points is considered substantial; this is overwhelming evidence that the Negative Binomial is superior.

**Coefficient Comparison:**

Despite the better fit, the coefficient signs and patterns remain consistent between models:

-   **street_lights**: Still positive and significant (β = 0.0039), though slightly larger than in the Poisson model
-   **street_lights.nn**: Still negative and significant (β = -0.0057), and the magnitude is larger
-   **dist_to_hotspot**: Still negative and significant (β = -0.00016)

The standard errors in the Negative Binomial model are larger, reflecting a more realistic assessment of uncertainty. The **theta parameter (θ = 1.68)** quantifies the degree of overdispersion—lower values indicate more clustering beyond what Poisson assumes.

**Conclusion:** The Negative Binomial model is clearly preferable and will be used for all subsequent predictions and validation. The robust relationship between street light complaints and burglaries—both in terms of raw counts and spatial proximity—survives the more conservative modeling approach, suggesting it's a real and meaningful pattern.

# Part 5: Spatial Cross-Validation

Model fit statistics like AIC tell us how well the model fits the training data, but they don't tell us how well it will **generalize** to new spatial areas. Spatial cross-validation addresses this by testing whether the model can predict crime in areas it hasn't been trained on.

I use **Leave-One-Group-Out (LOGO) cross-validation**, where the "groups" are **police districts**. For each of Chicago's 22 districts, I:

1.  Train the model on all other districts
2.  Predict burglaries in the held-out district\
3.  Calculate prediction error (MAE and RMSE)

This is more stringent than random cross-validation because nearby cells can "leak" information to each other. By holding out entire districts, I ensure the test data is truly independent.

## Leave-One-Group-Out Cross-Validation by Police District

```{r spatial-cv}
# Get unique districts
districts <- unique(fishnet_model$District)
cv_results <- tibble()

cat("Running LOGO Cross-Validation...\n")

for (i in seq_along(districts)) {
  
  test_district <- districts[i]
  
  # Split data
  train_data <- fishnet_model %>% filter(District != test_district)
  test_data <- fishnet_model %>% filter(District == test_district)
  
  # Fit model on training data
  model_cv <- glm.nb(
    countBurglaries ~ street_lights + street_lights.nn + 
      dist_to_hotspot,
    data = train_data
  )
  
  # Predict on test data
  test_data <- test_data %>%
    mutate(
      prediction = predict(model_cv, test_data, type = "response")
    )
  
  # Calculate metrics
  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))
  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))
  
  # Store results
  cv_results <- bind_rows(
    cv_results,
    tibble(
      fold = i,
      test_district = test_district,
      n_test = nrow(test_data),
      mae = mae,
      rmse = rmse
    )
  )
  
  cat("  Fold", i, "/", length(districts), "- District", test_district, 
      "- MAE:", round(mae, 2), "\n")
}

# Overall results
cat("\n✓ Cross-Validation Complete\n")
cat("Mean MAE:", round(mean(cv_results$mae), 2), "\n")
cat("Mean RMSE:", round(mean(cv_results$rmse), 2), "\n")
```

```{r cv-results-table}
# Show results
cv_results %>%
  arrange(desc(mae)) %>%
  kable(
    digits = 2,
    caption = "LOGO CV Results by District (sorted by MAE, worst to best)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Cross-Validation Results Interpretation

The spatial cross-validation reveals **substantial variation** in prediction accuracy across Chicago's police districts:

**Overall Performance:**

-   Mean MAE: **2.63 burglaries per cell**
-   Mean RMSE: **3.52 burglaries per cell**

These errors represent the model's performance when predicting on completely unseen geographic areas. An MAE of 2.63 means that, on average, predictions are off by about 2-3 burglaries per 500m cell—a reasonable error given that many cells have 5-10 burglaries.

**Worst Performing Districts:**

-   **District 3** (MAE = 5.54, RMSE = 7.55): This district is particularly challenging to predict. It likely has unusual spatial patterns or a different street light-burglary relationship than the rest of the city. District 3 covers part of the South Side with historically high crime rates.

-   **District 6** (MAE = 3.32) and **District 11** (MAE = 3.24) also show elevated errors.

**Best Performing Districts:**

-   **District 5** (MAE = 1.94), **District 9** (MAE = 1.96), and **District 17** (MAE = 1.98) have the lowest prediction errors. These may be districts with more stable, predictable crime patterns or where the street light-burglary relationship is particularly strong.

**Key Insight:**

The wide range in errors (1.94 to 5.54) indicates that the model's predictive power is **not uniform** across Chicago. The street light-burglary relationship appears stronger and more consistent in some neighborhoods than others. This heterogeneity could reflect:

-   Different urban forms (high-rise vs. single-family residential)
-   Varying levels of police presence
-   Socioeconomic differences that mediate the disorder-crime relationship
-   Data quality issues (underreporting in some areas)

For practical deployment, this means the model would be most reliable in districts with characteristics similar to Districts 5, 9, and 17, and should be used more cautiously in outlier districts like District 3.

# Part 6: Model Evaluation – Comparing to KDE Baseline

Even a poorly performing model can look good in isolation. To truly assess whether our complex Negative Binomial model adds value, I compare it to a simple **Kernel Density Estimation (KDE) baseline**.

The KDE baseline represents a "naïve" approach: assume future crime will occur where past crime has occurred, with no predictors or covariates. It's essentially a smoothed map of historical burglary locations. If our street light features and spatial modeling don't outperform this simple baseline, they don't add predictive value.

## KDE Baseline

```{r kde-baseline}
#| message: false

# Convert burglaries to ppp (point pattern) format for spatstat
burglaries_ppp <- as.ppp(
  st_coordinates(burglaries),
  W = as.owin(st_bbox(chicagoBoundary))
)

# Calculate KDE with 1km bandwidth
kde_burglaries <- density.ppp(
  burglaries_ppp,
  sigma = 1000,  # 1km bandwidth
  edge = TRUE    # Edge correction
)

# Convert to terra raster (modern approach, not raster::raster)
kde_raster <- rast(kde_burglaries)

# Extract KDE values to fishnet cells
fishnet <- fishnet %>%
  mutate(
    kde_value = terra::extract(
      kde_raster,
      vect(fishnet),
      fun = mean,
      na.rm = TRUE
    )[, 2]  # Extract just the values column
  )

cat("✓ Calculated KDE baseline\n")
```

## Generate Final Predictions

```{r final-predictions}
# Fit final model on all data
final_model <- glm.nb(
  countBurglaries ~ street_lights + street_lights.nn + 
    dist_to_hotspot,
  data = fishnet_model
)

# Add predictions back to fishnet
fishnet <- fishnet %>%
  mutate(
    prediction_nb = predict(final_model, fishnet_model, type = "response")[match(uniqueID, fishnet_model$uniqueID)]
  )

# Also add KDE predictions (normalize to same scale as counts)
kde_sum <- sum(fishnet$kde_value, na.rm = TRUE)
count_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)
fishnet <- fishnet %>%
  mutate(
    prediction_kde = (kde_value / kde_sum) * count_sum
  )
```

## Map Actual vs Predicted

```{r compare-models}
#| fig-width: 12
#| fig-height: 4

# Create three maps
p1 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
  scale_fill_viridis_c(name = "Count", option = "plasma", limits = c(0, 15)) +
  labs(title = "Actual Burglaries") +
  theme_crime()

p2 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +
  scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
  labs(title = "Model Predictions (Neg. Binomial)") +
  theme_crime()

p3 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +
  scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
  labs(title = "KDE Baseline Predictions") +
  theme_crime()

p1 + p2 + p3 +
  plot_annotation(
    title = "Actual vs. Predicted Burglaries (2017 Data)",
    subtitle = "Does our complex model outperform simple KDE?"
  )
```

Visually, both the Negative Binomial model and KDE baseline capture the broad spatial pattern of burglary hot spots in the South and West sides. However, the KDE map appears slightly smoother and more closely aligned with the actual distribution—a hint that the baseline might actually outperform our model.

## Quantitative Comparison of Negative Binomial vs KDE

```{r model-comparison-metrics}
# Calculate performance metrics
comparison <- fishnet %>%
  st_drop_geometry() %>%
  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%
  summarize(
    model_mae = mean(abs(countBurglaries - prediction_nb)),
    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),
    kde_mae = mean(abs(countBurglaries - prediction_kde)),
    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))
  )

comparison %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  separate(metric, into = c("approach", "metric"), sep = "_") %>%
  pivot_wider(names_from = metric, values_from = value) %>%
  kable(
    digits = 2,
    caption = "Model Performance Comparison: Negative Binomial vs. KDE"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

**The verdict:** The KDE baseline **outperforms** our Negative Binomial model:

-   **KDE MAE: 2.06** vs. NB MAE: 2.44 (15% better)
-   **KDE RMSE: 2.95** vs. NB RMSE: 3.50 (16% better)

This is a humbling but important result. Despite the theoretical appeal of incorporating street light complaint data and spatial features, the simple historical crime surface does a better job of predicting 2017 burglaries.

**Why might this be the case?**

1.  **Spatial inertia is strong**: Crime has strong temporal and spatial persistence. Where crime happened last month is the best predictor of where it will happen this month.

2.  **Unmeasured confounders**: Street light complaints may be correlated with burglary risk through shared underlying causes (neighborhood neglect, poverty, etc.) rather than having a direct predictive relationship.

3.  **KDE uses more information**: The KDE baseline uses the *exact locations* of all 7,482 burglaries, while our model aggregates them to grid cells and then predicts from just three features. We're compressing a lot of information.

4.  **Model overfitting to spatial features**: The street light features might capture patterns in the training data that don't generalize well.

**Does this mean the model is useless?** Not necessarily. The KDE baseline can only be calculated *after* we have crime data—it's purely descriptive. If we wanted to predict crime in 2018 (before it happens), we couldn't use 2018 burglary locations. That's where the temporal validation becomes critical...

## Error Maps

Where does the model make its biggest mistakes?

```{r error-maps}
#| fig-width: 10
#| fig-height: 4

fishnet <- fishnet |>
  mutate(
    error_nb  = countBurglaries - prediction_nb,
    abs_error_nb = abs(error_nb)
  )

p_err <- ggplot() +
  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +
  scale_fill_gradient2(low = "#2166ac", mid = "white", high = "#b2182b", midpoint = 0,
                       name = "Error\n(actual - pred)") +
  labs(title = "NB Model Errors",
       subtitle = "Red = underpredicted, Blue = overpredicted") +
  theme_crime()

p_abs <- ggplot() +
  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +
  scale_fill_viridis_c(option = "magma", name = "Absolute error") +
  labs(title = "Absolute NB Model Errors") +
  theme_crime()

p_err + p_abs
```

The **signed error map** (left) shows where the model underpredicts (red) and overpredicts (blue) burglaries. The model tends to **underpredict** in some of the highest-crime hot spots in the South Side, while **overpredicting** in some moderate-crime areas.

The **absolute error map** (right) confirms that the largest errors occur in the same South and West Side hot spots where burglary rates are highest. This is partially expected—high-count cells have more room for large absolute errors—but it also suggests the model struggles to fully capture the intensity of crime in the most afflicted areas.

# Part 7: Temporal Validation (2018)

The ultimate test of a predictive model is whether it can forecast the future. In this section, I evaluate how well the model trained on 2017 data predicts burglaries in 2018.

This **temporal validation** is more realistic and more challenging than spatial cross-validation because:

1.  We're predicting a completely different time period
2.  Crime patterns may have shifted between years
3.  The street light complaints are from 2017, so we're testing whether 2017 disorder patterns can predict 2018 crime

This is the closest approximation to real-world deployment: using current environmental indicators to forecast future crime risk.

## Load and Aggregate 2018 Burglaries

```{r load-burglaries-2018}
# NOTE: Update the file path/name if your 2018 burglary shapefile is named differently
crime_2018 <- st_read(here("data", "burglaries_2018.shp"), quiet = TRUE) %>%
  st_transform('ESRI:102271')

burglaries_2018 <- crime_2018 %>%
  filter(primary_ty == "BURGLARY" , descriptio == "FORCIBLE ENTRY")

burg_2018_fishnet <- st_join(burglaries_2018, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarise(countBurglaries_2018 = n(), .groups = "drop")

fishnet_2018 <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(uniqueID, street_lights, street_lights.nn, dist_to_hotspot) %>%
  left_join(burg_2018_fishnet, by = "uniqueID") %>%
  mutate(countBurglaries_2018 = replace_na(countBurglaries_2018, 0L))

summary(fishnet_2018$countBurglaries_2018)
```

## Predict 2018 Burglaries Using the 2017 Model

```{r predict-2018}
fishnet_2018 <- fishnet_2018 |>
  mutate(
    pred_2018_nb = predict(
      final_model,
      newdata = fishnet_2018,
      type = "response"
    )
  )

# Temporal validation metrics
validation_2018 <- fishnet_2018 |>
  summarise(
    mae_2018  = mean(abs(countBurglaries_2018 - pred_2018_nb)),
    rmse_2018 = sqrt(mean((countBurglaries_2018 - pred_2018_nb)^2))
  )

validation_2018
```

## Temporal Validation Results

**2018 Temporal Validation Performance:**

-   2018 MAE: **2.36**
-   2018 RMSE: **3.37**

**Comparison to 2017 Spatial Cross-Validation:**

-   2017 Spatial CV MAE: **2.63**
-   2018 Temporal MAE: **2.36**
-   **Difference: 0.27 fewer errors in temporal validation (10% improvement)**

This is a **surprising and encouraging result**: the temporal validation error is actually **lower** than the spatial cross-validation error. This defies the usual expectation that predicting a different time period would be harder than predicting different areas in the same time period.

**What does this mean?**

1.  **Temporal stability**: The spatial relationship between street light complaints and burglaries is **stable over time**. The patterns that hold in 2017 largely persist into 2018. This is critical for practical use—the model won't immediately become obsolete.

2.  **Spatial heterogeneity is the bigger challenge**: The variation in predictability across different Chicago neighborhoods (spatial CV) is actually harder to model than year-to-year temporal variation. District 3's unusual patterns are more difficult to predict than the overall city's temporal drift.

3.  **Modest year-over-year crime changes**: If burglary patterns shifted dramatically between 2017 and 2018, temporal validation would fail. The fact that it succeeds suggests relatively stable underlying spatial processes.

4.  **Street light patterns are leading indicators**: The 2017 street light complaint patterns successfully forecast where 2018 burglaries will concentrate, supporting the hypothesis that infrastructure disorder precedes or co-occurs with crime.

**Practical Implications:**

These results suggest the model has modest but real **forecasting value**. A police department could use current year's street light complaint data to anticipate next year's burglary hot spots with reasonable accuracy (MAE ≈ 2.4 burglaries per 500m cell).

However, we should note that:

-   The model still performs worse than the KDE baseline on 2017 data (MAE 2.36 vs. KDE's 2.06)
-   We haven't tested it on a KDE baseline for 2018, which would be the fairest comparison
-   Real-world deployment would require ongoing recalibration as conditions change

**Final Verdict:**

The temporal validation provides evidence that street light complaints contain **real predictive signal** for future burglary risk, above and beyond mere description of current crime patterns. The model's performance is good enough to inform resource allocation decisions, though it should be one input among many rather than the sole decision-making tool.

# Conclusion

This analysis investigated whether 311 complaints about street lights being out could predict burglary risk in Chicago. Using 2017 data on 7,482 forcible entry burglaries and 75,031 street light complaints, I constructed spatial predictive models incorporating complaint counts, proximity measures, and hot spot indicators.

## Key Findings

**1. Strong spatial correlation exists between street light complaints and burglaries**

Both phenomena cluster in the South and West sides of Chicago, and Local Moran's I analysis confirmed statistically significant hot spots in these areas. This visual and statistical overlap provided initial evidence of a relationship.

**2. The Negative Binomial model outperforms Poisson but not the KDE baseline**

The Negative Binomial regression (AIC = 7515.8) was vastly superior to Poisson (AIC = 8966.5) due to substantial overdispersion (φ = 3.16). All three street light predictors were significant: - More complaints in a cell → more burglaries - Greater distance from complaints → fewer burglaries\
- Greater distance from hot spots → fewer burglaries

However, the simple KDE baseline (MAE = 2.06) outperformed the Negative Binomial model (MAE = 2.44) for 2017 predictions, suggesting that spatial inertia is a stronger predictor than environmental disorder indicators.

**3. Model performance varies substantially across police districts**

Spatial cross-validation (Mean MAE = 2.63) revealed heterogeneity in predictability, with District 3 particularly challenging (MAE = 5.54) and Districts 5, 9, and 17 performing well (MAE ≈ 1.94-1.98). This indicates the street light-burglary relationship is stronger in some neighborhood contexts than others.

**4. The model shows encouraging temporal stability**

Temporal validation on 2018 data (MAE = 2.36) actually outperformed 2017 spatial cross-validation, indicating that the spatial patterns captured by the model are relatively stable over time. This is critical for practical deployment: current disorder patterns can help forecast future crime risk.

## Limitations

-   **Omitted variable bias**: The model doesn't account for other important predictors like income, housing vacancy, police presence, or population density.
-   **Ecological fallacy**: Relationships observed at the grid-cell level may not hold for individual burglaries.
-   **Simultaneity**: Street light complaints and burglaries may have shared underlying causes rather than a causal relationship.
-   **Limited temporal scope**: Testing on just one future year (2018) is insufficient to claim long-term forecasting ability.

## Implications for Policy

While street light complaints show promise as a burglary risk indicator, they should **supplement rather than replace** existing crime analysis tools. The model's temporal stability suggests that cities could use current 311 maintenance request data to identify emerging risk areas before crime concentrates there.

However, the KDE baseline's superior performance reminds us that **the best predictor of future crime is past crime**. Any deployment should combine historical crime patterns with environmental indicators like street light complaints for the most robust predictions.

Future work could strengthen this analysis by: - Incorporating demographic and built environment variables - Testing on multiple years to assess long-term stability\
- Examining whether addressing street light complaints actually reduces burglary rates (causal inference) - Comparing multiple 311 complaint types to identify which are most predictive
