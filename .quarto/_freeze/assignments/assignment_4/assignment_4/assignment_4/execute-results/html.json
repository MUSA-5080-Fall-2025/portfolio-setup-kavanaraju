{
  "hash": "4e065189a1763db02a16ac575d89a4af",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 4: Spatial Predictive Analysis\"\nsubtitle: \"Using Street Light Outages to Predict Burglary Risk in Chicago\"\nauthor: \"Kavana Raju\"\ndate: today\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n# Introduction\n\nStreet lighting plays an important role in shaping urban safety and crime prevention. The broken windows perspective states that visible signs of disorder, such as street lights that do not work, can signal weakened social control and encourage criminal activity. Crime Prevention Through Environmental Design also emphasizes visibility, natural surveillance, and well maintained public spaces as environmental factors that influence offending. For this reason, complaints about street lights being out provide a clear and measurable indicator of neighborhood maintenance and environmental disorder that may relate to burglary risk.\n\nThis analysis investigates whether patterns of street light outages help predict burglary risk in Chicago. I use data on burglaries and 311 complaints from the year 2017 and begin by examining the spatial distribution of both datasets in order to identify prominent clusters and areas where outages and burglaries appear together. I then aggregate all features to a regular 500 meter fishnet grid that covers the entire city. This grid provides a consistent spatial structure for modeling. For each grid cell I create several spatial predictors, including the count of burglaries, the count of street light outages, the distance to nearby burglary hotspots, and a Local Morans I statistic that captures spatial clustering and outlier patterns.\n\nUsing these features, I estimate Poisson and Negative Binomial count regression models to evaluate how well street light outages and spatial context explain variation in burglary counts across the grid. I assess the fit of the models using AIC values and also evaluate predictive performance through spatial validation using a Leave One Group Out cross validation that separates the data by community area. I also compare the regression models to a kernel density estimate, which is a commonly used spatial baseline for crime prediction.\n\nAs a final step, I test the model that was trained on 2017 data using burglaries from the year 2018. This allows me to evaluate how well the model performs when predicting a future year rather than data from the same period. Together, these steps help determine whether street light outage patterns contain meaningful predictive information about burglary risk and whether these patterns can support forward looking urban safety strategies.\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n:::\n\n\n# Part 1: Data Loading & Exploration\n\nIn this part, I load the Chicago spatial boundaries, the 2017 burglary data set, and the 311 Street Lights Out data set. I then create point maps and kernel density maps to explore the spatial distribution of burglaries and Street Light Out complaints.\n\nThis step is important because it confirms that the data sets align in space and time and it gives a first look at whether the Street Light Out complaints appear in similar broad locations as burglaries. From these maps I begin to see whether the violation type has a clustered pattern that might be useful for prediction.\n\n## 1.1 Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\", quiet = TRUE) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\nThe city boundary and the police district and beat layers define the spatial context for all later analysis. Loading these layers first ensures that every other data set can be transformed into a common reference system and clipped to the same geographic extent.\n\n## 1.2. Load Burglary Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"data\", \"burglaries.shp\"), quiet = TRUE) %>% \n  st_transform('ESRI:102271')\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n:::\n\nThe burglary layer provides the outcome that the models will try to predict. \n\n## 1.3 Load 311 Street Light Out Complaints\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#lights_raw <- read_csv(here(\"data\", \"311_StreetLightsOneOut_Historical.csv\"))\n\n#head(lights_raw$`Creation Date`, 5) #check date format\n\n#lights_years <- lights_raw %>%\n  #mutate(creation_date = mdy(`Creation Date`)) %>%\n  #mutate(year = year(creation_date)) %>%\n  #filter(year == 2017) %>%\n  #filter(!is.na(Latitude), !is.na(Longitude))\n\n#street_lights <- lights_years %>%\n  #st_as_sf(coords = c(\"Longitude\", \"Latitude\"),\n           #crs = 4326,\n           #remove = FALSE) %>%\n  #st_transform('ESRI:102271')\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nstreet_lights <- readRDS(here(\"data\", \"street_lights_2017.rds\"))\n\ncat(\"✓ Loaded streetlight out complaints\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded streetlight out complaints\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of complaints:\", nrow(street_lights), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of complaints: 75031 \n```\n\n\n:::\n:::\n\nFor the Street Light Out data, I filter the full historical record to the year 2017 and remove any records that are missing coordinates. Converting these complaints into a spatial layer in the same reference system as the burglaries allows a direct comparison in map form.\n\n## 1.4 Visualize Point Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract coordinates for density plots\nburg_coords   <- data.frame(st_coordinates(burglaries))\nlights_coords <- data.frame(st_coordinates(street_lights))\n\n# Burglary point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Burglary density surface\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = burg_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Burglary Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Street light complaint point map\np3 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = street_lights, color = \"#3b528b\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Street Light Out 311 Requests\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(street_lights))\n  )\n\n# Street light density surface\np4 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = lights_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Street Light Out Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n(p1 + p2) / (p3 + p4) + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries and Street Light Out Complaints in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](assignment_4_files/figure-html/visualize-points-1.png){width=1728}\n:::\n:::\n\n\nThe comparison of kernels and point maps shows that both burglaries and Street Light Out complaints have strong clustering and that some clusters overlap in similar regions. This pattern supports the idea that outage patterns may provide useful information for predicting burglary risk.\n\n# Part 2: Fishnet Grid Creation\n\nHere I create a 500m X 500m fishnet grid over Chicago, aggregate both burglaries and Street Light Out complaints to each grid cell, and visualize the resulting count distributions.\n\nThis step is important because the count models operate at the grid cell level rather than on individual points. Aggregation also allows me to compute spatial features and to compare cells in a consistent way across the entire city. The maps and summary statistics reveal how skewed the distributions are and how many cells have zero incidents.\n\n## 2.1 Create 500m Fishnet\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\nThe fishnet creates a regular grid that covers the Chicago boundary, with each cell representing an equal area unit of analysis. Working with this grid makes it possible to treat every part of the city in the same way, rather than relying on irregular administrative boundaries.\n\n## 2.2 Aggregate Burglaries to Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\nAggregating burglaries to the grid reveals how concentrated burglary incidents are when viewed at this spatial scale. The summary output reports the distribution of counts per cell and the proportion of cells that have no burglaries at all. A large share of cells contain no incidents, while a smaller number have several, which indicates a very uneven distribution of risk across space.\n\n## 2.3 Aggregate Street Light Out Complaints to Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlights_fishnet <- st_join(street_lights, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(street_lights = n(), .groups = \"drop\")\n\nfishnet <- fishnet %>%\n  left_join(lights_fishnet, by = \"uniqueID\") %>%\n  mutate(street_lights = replace_na(street_lights, 0))\n\ncat(\"Streetlight Out distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStreetlight Out distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$street_lights)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    8.00   23.00   30.49   45.00  213.00 \n```\n\n\n:::\n:::\n\n\nRepeating the same aggregation for Street Light Out complaints produces a comparable count for each grid cell. The summary output again shows many cells with no outages and a smaller number with multiple complaints. This reinforces the idea that the Street Light Out variable is also highly skewed and that outages tend to occur in clusters rather than uniformly across the city.\n\n## 2.4 Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_burg_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(option = \"plasma\", trans = \"sqrt\", name = \"Burglaries\") +\n  labs(title = \"Burglary Counts per 500m Grid Cell\") +\n  theme_crime()\n\np_lights_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = street_lights), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", trans = \"sqrt\", name = \"Street light\\ncomplaints\") +\n  labs(title = \"Street Light Out Complaints per 500m Grid Cell\") +\n  theme_crime()\n\np_burg_grid + p_lights_grid\n```\n\n::: {.cell-output-display}\n![](assignment_4_files/figure-html/visualize-fishnet-1.png){width=1728}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishnet %>%\n  st_drop_geometry() %>%\n  summarise(\n    mean_burg = mean(countBurglaries),\n    max_burg  = max(countBurglaries),\n    pct_zero_burg = mean(countBurglaries == 0),\n    mean_lights = mean(street_lights),\n    max_lights  = max(street_lights),\n    pct_zero_lights = mean(street_lights == 0)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mean_burg max_burg pct_zero_burg mean_lights max_lights pct_zero_lights\n1  3.042311       40      0.317738    30.48902        213       0.1167616\n```\n\n\n:::\n:::\n\nThe grid maps show strongly skewed count distributions for both burglaries and outages, with many zero count cells and a small number of high count cells. This pattern confirms the need for models that can handle over dispersed count outcomes.\n\n# Part 3: Spatial Features\n\nIn this part, I construct spatial features that describe how each grid cell relates to nearby Street Light Out complaints and to the broader pattern of disorder. I create nearest neighbor features, identify Local Moran's I clusters of Street Light Out complaints, and compute distance to hot spot cells.\n\nThese features are important because they capture spatial context that simple counts cannot. For example, a cell with no outages but that sits next to a cluster of outages may still be influenced by local maintenance conditions.\n\n## 3.1 k-Nearest Neighbor Features\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest streetlights that are out\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nstreetlight_coords <- st_coordinates(street_lights)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(streetlight_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    street_lights.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$street_lights.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   4.494   61.697   98.685  172.645  174.718 1646.965 \n```\n\n\n:::\n:::\n\nFor each grid cell, I compute the average distance from the cell centroid to the three nearest Street Light Out complaints. This feature captures how close a given location is to the surrounding pattern of outages, even if the cell itself has no complaints. The summary output shows that some cells are very close to outages, while others are relatively far away. Larger values indicate more distant or sparse outage activity, while smaller values indicate that complaints are nearby.\n\n## 3.2 Local Moran’s I: Hot Spots and Cold Spots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n\n# Create spatial weights\ncoords <- st_coordinates(st_centroid(data))\nneighbors <- knn2nb(knearneigh(coords, k = k))\nweights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n# Calculate Local Moran's I\nlocal_moran <- localmoran(data[[variable]], weights)\n  \n# Classify clusters\nmean_val <- mean(data[[variable]], na.rm = TRUE)\n  \ndata %>%\n  mutate(\n    local_i = local_moran[, 1],\n    p_value = local_moran[, 5],\n    is_significant = p_value < 0.05,\n      \nmoran_class = case_when(\n  !is_significant ~ \"Not Significant\",\n  local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n  local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n  local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n  local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n  TRUE ~ \"Not Significant\"))\n}\n\n# Apply to streetlights\nfishnet <- calculate_local_morans(fishnet, \"street_lights\", k = 5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Street Light Out Complaint Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment_4_files/figure-html/visualize-morans-1.png){width=1728}\n:::\n:::\n\n\nThe Local Moran's I classification shows where Street Light Out complaints form clusters of high or low values. High High cells are locations with many outages surrounded by neighbors that also have many outages. Low Low cells are locations with few outages where neighbors also have few outages. High Low and Low High cells represent outliers that behave differently from their neighbors. In the map, hot spots of disorder appear as groups of High High cells, while large parts of the city fall into the Low Low or not significant classes. This confirms that outages are highly clustered and that some neighborhoods experience much more maintenance related disorder than others.\n\n## 3.3 Distance to Hot Spots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to street light out complaints\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to street light out complaints\n  - Number of hot spot cells: 212 \n```\n\n\n:::\n:::\n\nUsing the High High cells as hot spots of Street Light Out complaints, I calculate the distance from every grid cell centroid to the nearest hot spot. This feature reflects how close each location is to the most severe maintenance problems in the city. If outages contribute to burglary risk, I expect cells that are closer to hot spots of outages to have higher predicted burglary counts than cells that are far away.\n\n# Part 4: Count Regression Models\n\nIn this part, I fit count regression models that use Street Light Out features and spatial context to predict burglary counts per grid cell. I begin with a Poisson model, check for over dispersion, and then fit a Negative Binomial model. This sequence gives a formal way to quantify the relationship between the predictors and burglary risk and to judge which model form is more appropriate.\n\n## 4.1 Prepare Modeling Data and Join Police Districts\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet for spatial cross-validation later\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    street_lights,\n    street_lights.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 6 \n```\n\n\n:::\n:::\n\nJoining police districts to the grid prepares the data set for spatial cross validation in a later section. Dropping geometry and selecting only the predictor and outcome columns produces a clean modeling table where each row represents a grid cell. Removing any remaining missing values ensures that the regression models use only complete records.\n\n## 4.2 Poisson Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot, family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                    Estimate  Std. Error z value             Pr(>|z|)    \n(Intercept)       1.84963285  0.04196939   44.07 < 0.0000000000000002 ***\nstreet_lights     0.00339729  0.00047716    7.12     0.00000000000108 ***\nstreet_lights.nn -0.00440554  0.00024636  -17.88 < 0.0000000000000002 ***\ndist_to_hotspot  -0.00018738  0.00001126  -16.64 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6710.3  on 1707  degrees of freedom\nResidual deviance: 4898.2  on 1704  degrees of freedom\nAIC: 8966.5\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\nAll three predictors are statistically significant. Higher counts of Street Light Out complaints are associated with higher expected burglary counts. The nearest neighbor distance to outages has a strong negative effect, which means burglary counts tend to be higher when outages are located close to the grid cell. Distance to the major outage hot spots also has a negative effect, which indicates that burglary counts are higher in places located near clusters of outages. Among the predictors, the nearest neighbor distance has the strongest effect in magnitude, which suggests that the spatial structure of outage locations explains more variation than the raw count alone.\n\n## 4.3 Check for Overdispersion\n\nA key Poisson assumption is that the variance equals the mean. In reality, crime data often exhibits overdispersion: the variance exceeds the mean due to unobserved heterogeneity. We can check this by calculating the dispersion parameter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 3.16 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n:::\n\nThe residual deviance is far larger than the degrees of freedom, which confirms strong overdispersion. This means the Poisson model is not appropriate for these data and a Negative Binomial model is required\n\n## 4.4 Negative Binomial Regression\n\nThe Negative Binomial model adds a dispersion parameter that allows the variance to exceed the mean, making it more appropriate for overdispersed count data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot, data = fishnet_model, init.theta = 1.675323296, \n    link = log)\n\nCoefficients:\n                    Estimate  Std. Error z value             Pr(>|z|)    \n(Intercept)       1.91692396  0.07743417  24.756 < 0.0000000000000002 ***\nstreet_lights     0.00387097  0.00096514   4.011            0.0000605 ***\nstreet_lights.nn -0.00569071  0.00040009 -14.224 < 0.0000000000000002 ***\ndist_to_hotspot  -0.00016479  0.00001793  -9.192 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6753) family taken to be 1)\n\n    Null deviance: 2593.1  on 1707  degrees of freedom\nResidual deviance: 1832.0  on 1704  degrees of freedom\nAIC: 7515.8\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.6753 \n          Std. Err.:  0.0956 \n\n 2 x log-likelihood:  -7505.8040 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 8966.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7515.8 \n```\n\n\n:::\n:::\n\nThe Negative Binomial model produces the same pattern of results as the Poisson model, but with a much better fit. All predictors remain statistically significant and the signs of the coefficients are unchanged. Higher Street Light Out counts are associated with higher expected burglary counts. Both the nearest neighbor distance and the distance to outage hot spots remain negative and significant, which means burglary counts increase in places where outages are close and where outage clusters are nearby.\n\nThe nearest neighbor distance has the strongest effect in magnitude, which reinforces the importance of the spatial arrangement of outages rather than the simple number of outages in each cell. The AIC comparison shows a major improvement. The Poisson model has an AIC of 8966.5, while the Negative Binomial model has an AIC of 7515.8. This very large reduction shows that the Negative Binomial distribution fits the data far better and is the appropriate choice for prediction and interpretation.\n\n\n# Part 5: Spatial Cross-Validation (2017)\n\nHere I evaluate how well the 2017 Negative Binomial model generalizes across space using Leave-One-Group-Out cross-validation, where the group is the police district. This step matters because random cross validation can mix nearby cells into both training and test sets, which can give an overly optimistic view of performance. By holding out entire districts, I force the model to predict areas that it has not seen during training.\n\n## 5.1 Leave-One-Group-Out Cross-Validation by Police District\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ street_lights + street_lights.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 1.94 \n  Fold 2 / 22 - District 4 - MAE: 1.62 \n  Fold 3 / 22 - District 22 - MAE: 2.78 \n  Fold 4 / 22 - District 6 - MAE: 3.32 \n  Fold 5 / 22 - District 8 - MAE: 2.9 \n  Fold 6 / 22 - District 7 - MAE: 2.88 \n  Fold 7 / 22 - District 3 - MAE: 5.54 \n  Fold 8 / 22 - District 2 - MAE: 2.92 \n  Fold 9 / 22 - District 9 - MAE: 1.96 \n  Fold 10 / 22 - District 10 - MAE: 2.8 \n  Fold 11 / 22 - District 1 - MAE: 2.1 \n  Fold 12 / 22 - District 12 - MAE: 3.22 \n  Fold 13 / 22 - District 15 - MAE: 2.12 \n  Fold 14 / 22 - District 11 - MAE: 3.24 \n  Fold 15 / 22 - District 18 - MAE: 2.92 \n  Fold 16 / 22 - District 25 - MAE: 2.68 \n  Fold 17 / 22 - District 14 - MAE: 2.59 \n  Fold 18 / 22 - District 19 - MAE: 1.99 \n  Fold 19 / 22 - District 16 - MAE: 2.07 \n  Fold 20 / 22 - District 17 - MAE: 1.98 \n  Fold 21 / 22 - District 20 - MAE: 1.81 \n  Fold 22 / 22 - District 24 - MAE: 2.44 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.63 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.52 \n```\n\n\n:::\n:::\n\n\nThe cross validation loop fits the Negative Binomial model many times, each time leaving out a different police district from the training data and using that district as the test set. For each fold, I record the mean absolute error and the root mean squared error between observed and predicted burglary counts in the held out district. The summary lines at the end report the average error across all districts. These numbers represent a realistic measure of how far the model tends to be from the true burglary counts when it is used to predict new parts of the city.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>LOGO CV Results by District</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fold </th>\n   <th style=\"text-align:left;\"> test_district </th>\n   <th style=\"text-align:right;\"> n_test </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 5.54 </td>\n   <td style=\"text-align:right;\"> 7.55 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 3.32 </td>\n   <td style=\"text-align:right;\"> 4.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 3.24 </td>\n   <td style=\"text-align:right;\"> 3.80 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 3.22 </td>\n   <td style=\"text-align:right;\"> 4.37 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 2.92 </td>\n   <td style=\"text-align:right;\"> 3.69 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 2.92 </td>\n   <td style=\"text-align:right;\"> 4.46 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:right;\"> 197 </td>\n   <td style=\"text-align:right;\"> 2.90 </td>\n   <td style=\"text-align:right;\"> 3.82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 52 </td>\n   <td style=\"text-align:right;\"> 2.88 </td>\n   <td style=\"text-align:right;\"> 3.72 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.80 </td>\n   <td style=\"text-align:right;\"> 3.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 22 </td>\n   <td style=\"text-align:right;\"> 112 </td>\n   <td style=\"text-align:right;\"> 2.78 </td>\n   <td style=\"text-align:right;\"> 3.22 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 85 </td>\n   <td style=\"text-align:right;\"> 2.68 </td>\n   <td style=\"text-align:right;\"> 3.89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 2.59 </td>\n   <td style=\"text-align:right;\"> 3.90 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:left;\"> 24 </td>\n   <td style=\"text-align:right;\"> 41 </td>\n   <td style=\"text-align:right;\"> 2.44 </td>\n   <td style=\"text-align:right;\"> 3.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 2.12 </td>\n   <td style=\"text-align:right;\"> 2.59 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 2.10 </td>\n   <td style=\"text-align:right;\"> 2.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:right;\"> 129 </td>\n   <td style=\"text-align:right;\"> 2.07 </td>\n   <td style=\"text-align:right;\"> 2.61 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> 19 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 1.99 </td>\n   <td style=\"text-align:right;\"> 2.55 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 1.98 </td>\n   <td style=\"text-align:right;\"> 2.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 1.96 </td>\n   <td style=\"text-align:right;\"> 2.51 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n   <td style=\"text-align:right;\"> 1.94 </td>\n   <td style=\"text-align:right;\"> 2.58 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:left;\"> 20 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 1.81 </td>\n   <td style=\"text-align:right;\"> 2.21 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 235 </td>\n   <td style=\"text-align:right;\"> 1.62 </td>\n   <td style=\"text-align:right;\"> 3.40 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nThe cross validation results show that the model performs consistently across most districts. The range of mean absolute error values is fairly narrow, which indicates that the model does not depend on any single part of the city to achieve good performance. Districts with higher error tend to be those with unusual or sparse burglary activity, which naturally produces more volatile predictions. The model does not systematically fail in any specific district. Taken together, the results show that the model generalizes well across space and that the Street Light Out features provide stable predictive information throughout the city.\n\n# Part 6: Model Evaluation Compare to KDE baseline\n\nIn this part, I compare the fitted Negative Binomial model to a simple spatial baseline using kernel density estimation. The baseline assumes that crime is most likely to occur near locations where it has occurred in the past and ignores explicit predictors.\n\n## 6.1 Kernal Density Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\nThe kernel density estimate takes the point pattern of burglaries and smooths it into a continuous surface of risk. Extracting mean values from this surface for each grid cell gives a set of predicted counts that rely entirely on the historical spatial pattern rather than on Street Light Out features or distances. This serves as a useful benchmark because many police agencies rely on kernel density maps for near term forecasting.\n\n## 6.2 Final Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\nHere I refit the Negative Binomial model on the full 2017 data set and generate predicted burglary counts for every grid cell. I also scale the kernel density values so that the total predicted count matches the total observed count. This makes the two sets of predictions directly comparable at the grid cell level.\n\n## 6.3 Map Actual vs Predicted\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](assignment_4_files/figure-html/compare-models-1.png){width=1728}\n:::\n:::\n\nThe three panel figure compares actual burglary counts to the predictions from the Negative Binomial model and from the kernel density baseline. Visually, both prediction maps reproduce the main hot spot areas that appear in the observed data. The kernel density predictions tend to follow the strongest clusters closely, while the Negative Binomial predictions reflect both the history of crime and the influence of Street Light Out features and distances. In some fringe areas, the model spreads risk slightly differently than the kernel density method, especially where outage patterns diverge from past burglary patterns.\n\n## 6.4 Quantitative Comparison of Negative Binomial vs KDE\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> approach </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.44 </td>\n   <td style=\"text-align:right;\"> 3.50 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.06 </td>\n   <td style=\"text-align:right;\"> 2.95 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nThe kernel density approach produces lower prediction error than the Negative Binomial model. This result is expected because kernel density estimation directly reproduces the spatial structure of past burglaries. The Negative Binomial model trades a small amount of predictive accuracy for interpretability about how Street Light Out features and spatial context relate to burglary counts.\n\n## 6.5 Error Maps\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishnet <- fishnet |>\n  mutate(\n    error_nb  = countBurglaries - prediction_nb,\n    abs_error_nb = abs(error_nb)\n  )\n\np_err <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(low = \"#2166ac\", mid = \"white\", high = \"#b2182b\", midpoint = 0,\n                       name = \"Error\n(actual - pred)\") +\n  labs(title = \"NB Model Errors\") +\n  theme_crime()\n\np_abs <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", name = \"Absolute error\") +\n  labs(title = \"Absolute NB Errors\") +\n  theme_crime()\n\np_err + p_abs\n```\n\n::: {.cell-output-display}\n![](assignment_4_files/figure-html/error-maps-1.png){width=1728}\n:::\n:::\n\nThe Negative Binomial model performs well in large areas of the city and captures the main hot spot regions correctly. The largest errors occur near the most intense burglary clusters. Outside these core hot spots, the model predicts counts with relatively small error.\n\n# Part 7: Temporal Validation (2018) \n\nFinally, I test how well the 2017 model predicts burglaries in 2018. This is a more challenging and realistic test, because it asks the model to generalize across time rather than just across space.\n\n## 7.1 Load and Aggregate 2018 Burglaries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NOTE: Update the file path/name if your 2018 burglary shapefile is named differently\n#crime_2018 <- st_read(here(\"data\", \"burglaries_2018.shp\"), quiet = TRUE) %>%\n  #st_transform('ESRI:102271')\n\n#burglaries_2018 <- crime_2018 %>%\n  #filter(primary_ty == \"BURGLARY\" , descriptio == \"FORCIBLE ENTRY\")\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nburglaries_2018 <- readRDS(here(\"data\", \"burglaries_2018_filtered.rds\"))\n\nburg_2018_fishnet <- st_join(burglaries_2018, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarise(countBurglaries_2018 = n(), .groups = \"drop\")\n\nfishnet_2018 <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(uniqueID, street_lights, street_lights.nn, dist_to_hotspot) %>%\n  left_join(burg_2018_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries_2018 = replace_na(countBurglaries_2018, 0L))\n\nsummary(fishnet_2018$countBurglaries_2018)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.107   5.000  51.000 \n```\n\n\n:::\n:::\n\nThe 2018 burglary incidents are filtered in the same way as the 2017 incidents and then aggregated to the existing grid. Using the same grid ensures that the two years are directly comparable. The summary of the 2018 counts shows a broadly similar pattern, with many zero cells and a smaller number of higher count cells, although the exact distribution differs from that of 2017.\n\n## 7.2 Predict 2018 Burglaries and Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishnet_2018 <- fishnet_2018 |>\n  mutate(\n    pred_2018_nb = predict(\n      final_model,\n      newdata = fishnet_2018,\n      type = \"response\"\n    )\n  )\n\n# Temporal validation metrics\nvalidation_2018 <- fishnet_2018 |>\n  summarise(\n    mae_2018  = mean(abs(countBurglaries_2018 - pred_2018_nb)),\n    rmse_2018 = sqrt(mean((countBurglaries_2018 - pred_2018_nb)^2))\n  )\n\nvalidation_2018\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mae_2018 rmse_2018\n1 2.363097  3.367603\n```\n\n\n:::\n:::\n\n\nThe temporal validation errors for 2018 are larger than the spatial cross validation errors for 2017. This means the model generalizes across space more reliably than across time. Year to year changes in burglary activity reduce temporal stability. This reinforces the need for frequent model updating if used for operational prediction.\n\n# Conclusion\n\nThis analysis demonstrates that Street Light Out complaints contain meaningful predictive information about burglary risk in Chicago. Areas with more outages, shorter distances to outages, and closer proximity to outage clusters tend to have higher burglary counts. The Negative Binomial model captures these relationships more effectively than the Poisson model. Kernel density predictions produce slightly lower error, which is common for purely spatial methods, but the Negative Binomial model provides clearer interpretability about the influence of infrastructure maintenance on crime. Spatial cross validation shows strong generalization across districts, while temporal validation reveals that burglary patterns shift from year to year. Overall, the results show how operational infrastructure data can be integrated into spatial predictive frameworks to support urban safety analysis.\n",
    "supporting": [
      "assignment_4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}