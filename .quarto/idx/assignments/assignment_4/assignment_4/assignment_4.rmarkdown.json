{"title":"Assignment 4: Spatial Predictive Analysis","markdown":{"yaml":{"title":"Assignment 4: Spatial Predictive Analysis","subtitle":"Using Street Light Outages to Predict Burglary Risk in Chicago","author":"Kavana Raju","date":"today","format":{"html":{"code-fold":"show","code-tools":true,"toc":true,"toc-depth":3,"toc-location":"left","theme":"cosmo","embed-resources":true}},"editor":"visual","execute":{"warning":false,"message":false}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nStreet lighting plays an important role in shaping urban safety and crime prevention. The broken windows perspective states that visible signs of disorder, such as street lights that do not work, can signal weakened social control and encourage criminal activity. Crime Prevention Through Environmental Design also emphasizes visibility, natural surveillance, and well maintained public spaces as environmental factors that influence offending. For this reason, complaints about street lights being out provide a clear and measurable indicator of neighborhood maintenance and environmental disorder that may relate to burglary risk.\n\nThis analysis investigates whether patterns of street light outages help predict burglary risk in Chicago. I use data on burglaries and 311 complaints from the year 2017 and begin by examining the spatial distribution of both datasets in order to identify prominent clusters and areas where outages and burglaries appear together. I then aggregate all features to a regular 500 meter fishnet grid that covers the entire city. This grid provides a consistent spatial structure for modeling. For each grid cell I create several spatial predictors, including the count of burglaries, the count of street light outages, the mean distance to nearby outages, the distance to nearby street light outage hot spots, and a Local Moran’s I statistic that captures spatial clustering and outlier patterns in the outage counts.\n\nUsing these features, I estimate Poisson and Negative Binomial count regression models to evaluate how well street light outages and spatial context explain variation in burglary counts across the grid. I assess the fit of the models using AIC values and also evaluate predictive performance through spatial validation using a Leave One Group Out cross validation that separates the data by police district. I also compare the regression models to a kernel density estimate, which is a commonly used spatial baseline for crime prediction.\n\nAs a final step, I test the model that was trained on 2017 data using burglaries from the year 2018. This allows me to evaluate how well the model performs when predicting a future year rather than data from the same period. Together, these steps help determine whether street light outage patterns contain meaningful predictive information about burglary risk and whether these patterns can support forward looking urban safety strategies.\n\n# Setup\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n# Part 1: Data Loading & Exploration\n\nIn this part, I load the Chicago spatial boundaries, the 2017 burglary data set, and the 311 Street Lights Out data set. I then create point maps and kernel density maps to explore the spatial distribution of burglaries and Street Light Out complaints.\n\nThis step is important because it confirms that the data sets align in space and time and it gives a first look at whether the Street Light Out complaints appear in similar broad locations as burglaries. From these maps I begin to see whether the violation type has a clustered pattern that might be useful for prediction.\n\n## 1.1 Load Chicago Spatial Data\n\n```{r load-boundaries}\n#| message: false\n\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\", quiet = TRUE) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded spatial boundaries\\n\")\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\nThe city boundary and the police district and beat layers define the spatial context for all later analysis. Loading these layers first ensures that every other data set can be transformed into a common reference system and clipped to the same geographic extent.\n\n## 1.2. Load Burglary Data\n\n```{r load-burglaries}\n#| message: false\n\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"data\", \"burglaries.shp\"), quiet = TRUE) %>% \n  st_transform('ESRI:102271')\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\nThe burglary layer provides the outcome that the models will try to predict.\n\n## 1.3 Load 311 Street Light Out Complaints\n\n```{r data-streetlight}\n#lights_raw <- read_csv(here(\"data\", \"311_StreetLightsOneOut_Historical.csv\"))\n\n#head(lights_raw$`Creation Date`, 5) #check date format\n\n#lights_years <- lights_raw %>%\n  #mutate(creation_date = mdy(`Creation Date`)) %>%\n  #mutate(year = year(creation_date)) %>%\n  #filter(year == 2017) %>%\n  #filter(!is.na(Latitude), !is.na(Longitude))\n\n#street_lights <- lights_years %>%\n  #st_as_sf(coords = c(\"Longitude\", \"Latitude\"),\n           #crs = 4326,\n           #remove = FALSE) %>%\n  #st_transform('ESRI:102271')\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nstreet_lights <- readRDS(here(\"data\", \"street_lights_2017.rds\"))\n\ncat(\"✓ Loaded streetlight out complaints\\n\")\ncat(\"  - Number of complaints:\", nrow(street_lights), \"\\n\")\n```\n\nFor the Street Light Out data, I filter the full historical record to the year 2017 and remove any records that are missing coordinates. Converting these complaints into a spatial layer in the same reference system as the burglaries allows a direct comparison in map form.\n\n## 1.4 Visualize Point Data\n\n```{r visualize-points}\n#| fig-width: 18\n#| fig-height: 14\n\n# Extract coordinates for density plots\nburg_coords   <- data.frame(st_coordinates(burglaries))\nlights_coords <- data.frame(st_coordinates(street_lights))\n\n# Burglary point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Burglary density surface\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = burg_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Burglary Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Street light complaint point map\np3 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = street_lights, color = \"#3b528b\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Street Light Out 311 Requests\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(street_lights))\n  )\n\n# Street light density surface\np4 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = lights_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Street Light Out Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n(p1 + p2) / (p3 + p4) + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries and Street Light Out Complaints in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\nThe comparison of kernels and point maps shows that both burglaries and Street Light Out complaints have strong clustering and that some clusters overlap in similar regions. This pattern supports the idea that outage patterns may provide useful information for predicting burglary risk.\n\n# Part 2: Fishnet Grid Creation\n\nHere I create a 500m X 500m fishnet grid over Chicago, aggregate both burglaries and Street Light Out complaints to each grid cell, and visualize the resulting count distributions.\n\nThis step is important because the count models operate at the grid cell level rather than on individual points. Aggregation also allows me to compute spatial features and to compare cells in a consistent way across the entire city. The maps and summary statistics reveal how skewed the distributions are and how many cells have zero incidents.\n\n## 2.1 Create 500m Fishnet\n\n```{r create-fishnet}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\nThe fishnet creates a regular grid that covers the Chicago boundary, with each cell representing an equal area unit of analysis. Working with this grid makes it possible to treat every part of the city in the same way, rather than relying on irregular administrative boundaries.\n\n## 2.2 Aggregate Burglaries to Grid\n\n```{r burglaries-fishnet}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\nsummary(fishnet$countBurglaries)\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\nAggregating burglaries to the grid reveals how concentrated burglary incidents are when viewed at this spatial scale. The summary output reports the distribution of counts per cell and the proportion of cells that have no burglaries at all. A large share of cells contain no incidents, while a smaller number have several, which indicates a very uneven distribution of risk across space.\n\n## 2.3 Aggregate Street Light Out Complaints to Grid\n\n```{r lights-fishnet}\nlights_fishnet <- st_join(street_lights, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(street_lights = n(), .groups = \"drop\")\n\nfishnet <- fishnet %>%\n  left_join(lights_fishnet, by = \"uniqueID\") %>%\n  mutate(street_lights = replace_na(street_lights, 0))\n\ncat(\"Streetlight Out distribution:\\n\")\nsummary(fishnet$street_lights)\n```\n\nRepeating the same aggregation for Street Light Out complaints produces a comparable count for each grid cell. The summary output again shows many cells with no outages and a smaller number with multiple complaints. This reinforces the idea that the Street Light Out variable is also highly skewed and that outages tend to occur in clusters rather than uniformly across the city.\n\n## 2.4 Visualize\n\n```{r visualize-fishnet}\n#| fig-width: 18\n#| fig-height: 10\np_burg_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(option = \"plasma\", trans = \"sqrt\", name = \"Burglaries\") +\n  labs(title = \"Burglary Counts per 500m Grid Cell\") +\n  theme_crime()\n\np_lights_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = street_lights), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", trans = \"sqrt\", name = \"Street light\\ncomplaints\") +\n  labs(title = \"Street Light Out Complaints per 500m Grid Cell\") +\n  theme_crime()\n\np_burg_grid + p_lights_grid\n```\n\n```{r summary-fishnet}\nfishnet %>%\n  st_drop_geometry() %>%\n  summarise(\n    mean_burg = mean(countBurglaries),\n    max_burg  = max(countBurglaries),\n    pct_zero_burg = mean(countBurglaries == 0),\n    mean_lights = mean(street_lights),\n    max_lights  = max(street_lights),\n    pct_zero_lights = mean(street_lights == 0)\n  )\n```\n\nThe grid maps show strongly skewed count distributions for both burglaries and outages, with many zero count cells and a small number of high count cells. This pattern confirms the need for models that can handle over dispersed count outcomes.\n\n# Part 3: Spatial Features\n\nIn this part, I construct spatial features that describe how each grid cell relates to nearby Street Light Out complaints and to the broader pattern of disorder. I create nearest neighbor features, identify Local Moran's I clusters of Street Light Out complaints, and compute distance to hot spot cells.\n\nThese features are important because they capture spatial context that simple counts cannot. For example, a cell with no outages but that sits next to a cluster of outages may still be influenced by local maintenance conditions.\n\n## 3.1 k-Nearest Neighbor Features\n\n```{r nn-feature}\n#| message: false\n\n# Calculate mean distance to 3 nearest streetlights that are out\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nstreetlight_coords <- st_coordinates(street_lights)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(streetlight_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    street_lights.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\nsummary(fishnet$street_lights.nn)\n```\n\nFor each grid cell, I compute the average distance from the cell centroid to the three nearest Street Light Out complaints. This feature captures how close a given location is to the surrounding pattern of outages, even if the cell itself has no complaints. The summary output shows that some cells are very close to outages, while others are relatively far away. Larger values indicate more distant or sparse outage activity, while smaller values indicate that complaints are nearby.\n\n## 3.2 Local Moran’s I: Hot Spots and Cold Spots\n\n```{r local-morans-streetlights}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n\n# Create spatial weights\ncoords <- st_coordinates(st_centroid(data))\nneighbors <- knn2nb(knearneigh(coords, k = k))\nweights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n# Calculate Local Moran's I\nlocal_moran <- localmoran(data[[variable]], weights)\n  \n# Classify clusters\nmean_val <- mean(data[[variable]], na.rm = TRUE)\n  \ndata %>%\n  mutate(\n    local_i = local_moran[, 1],\n    p_value = local_moran[, 5],\n    is_significant = p_value < 0.05,\n      \nmoran_class = case_when(\n  !is_significant ~ \"Not Significant\",\n  local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n  local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n  local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n  local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n  TRUE ~ \"Not Significant\"))\n}\n\n# Apply to streetlights\nfishnet <- calculate_local_morans(fishnet, \"street_lights\", k = 5)\n```\n\n```{r visualize-morans}\n#| fig-width: 18\n#| fig-height: 10\n\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Street Light Out Complaint Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\nThe Local Moran's I classification shows where Street Light Out complaints form clusters of high or low values. High High cells are locations with many outages surrounded by neighbors that also have many outages. Low Low cells are locations with few outages where neighbors also have few outages. High Low and Low High cells represent outliers that behave differently from their neighbors. In the map, hot spots of disorder appear as groups of High High cells, while large parts of the city fall into the Low Low or not significant classes. This confirms that outages are highly clustered and that some neighborhoods experience much more maintenance related disorder than others.\n\n## 3.3 Distance to Hot Spots\n\n```{r distance-to-hotspots}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to street light outage hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\nUsing the High High cells as hot spots of Street Light Out complaints, I calculate the distance from every grid cell centroid to the nearest hot spot. This feature reflects how close each location is to the most severe maintenance problems in the city. If outages contribute to burglary risk, I expect cells that are closer to hot spots of outages to have higher predicted burglary counts than cells that are far away.\n\n# Part 4: Count Regression Models\n\nIn this part, I fit count regression models that use Street Light Out features and spatial context to predict burglary counts per grid cell. I begin with a Poisson model, check for over dispersion, and then fit a Negative Binomial model. This sequence gives a formal way to quantify the relationship between the predictors and burglary risk and to judge which model form is more appropriate.\n\n## 4.1 Prepare Modeling Data and Join Police Districts\n\n```{r prepare-data}\n# Join district information to fishnet for spatial cross-validation later\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    street_lights,\n    street_lights.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\nJoining police districts to the grid prepares the data set for spatial cross validation in a later section. Dropping geometry and selecting only the predictor and outcome columns produces a clean modeling table where each row represents a grid cell. Removing any remaining missing values ensures that the regression models use only complete records.\n\n## 4.2 Poisson Regression\n\n```{r fit-poisson}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\nAll three predictors are statistically significant. Higher counts of Street Light Out complaints are associated with higher expected burglary counts. The nearest neighbor distance to outages has a strong negative effect, which means burglary counts tend to be higher when outages are located close to the grid cell. Distance to the major outage hot spots also has a negative effect, which indicates that burglary counts are higher in places located near clusters of outages. Among the predictors, the nearest neighbor distance has the strongest effect in magnitude, which suggests that the spatial structure of outage locations explains more variation than the raw count alone.\n\n## 4.3 Check for Overdispersion\n\nA key Poisson assumption is that the variance equals the mean. In reality, crime data often exhibits overdispersion: the variance exceeds the mean due to unobserved heterogeneity. We can check this by calculating the dispersion parameter:\n\n```{r check-overdispersion}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\nThe dispersion statistic is well above the rule-of-thumb threshold of 1.5, which confirms strong overdispersion. This means the Poisson model is not appropriate for these data and a Negative Binomial model is required.\n\n## 4.4 Negative Binomial Regression\n\nThe Negative Binomial model adds a dispersion parameter that allows the variance to exceed the mean, making it more appropriate for overdispersed count data.\n\n```{r fit-negbin}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\nThe Negative Binomial model produces the same pattern of results as the Poisson model, but with a much better fit. All predictors remain statistically significant and the signs of the coefficients are unchanged. Higher Street Light Out counts are associated with higher expected burglary counts. Both the nearest neighbor distance and the distance to outage hot spots remain negative and significant, which means burglary counts increase in places where outages are close and where outage clusters are nearby.\n\nThe nearest neighbor distance has the strongest effect in magnitude, which reinforces the importance of the spatial arrangement of outages rather than the simple number of outages in each cell. The AIC comparison shows a major improvement. The Poisson model has an AIC of 8966.5, while the Negative Binomial model has an AIC of 7515.8. This very large reduction shows that the Negative Binomial distribution fits the data far better and is the appropriate choice for prediction and interpretation.\n\n# Part 5: Spatial Cross-Validation (2017)\n\nHere I evaluate how well the 2017 Negative Binomial model generalizes across space using Leave-One-Group-Out cross-validation, where the group is the police district. This step matters because random cross validation can mix nearby cells into both training and test sets, which can give an overly optimistic view of performance. By holding out entire districts, I force the model to predict areas that it has not seen during training.\n\n## 5.1 Leave-One-Group-Out Cross-Validation by Police District\n\n```{r spatial-cv}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ street_lights + street_lights.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\nThe cross validation loop fits the Negative Binomial model many times, each time leaving out a different police district from the training data and using that district as the test set. For each fold, I record the mean absolute error and the root mean squared error between observed and predicted burglary counts in the held out district. The summary lines at the end report the average error across all districts. These numbers represent a realistic measure of how far the model tends to be from the true burglary counts when it is used to predict new parts of the city.\n\n```{r cv-results-table}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n```\n\nThe cross validation results show that the model performs consistently across most districts. The range of mean absolute error values is fairly narrow, which indicates that the model does not depend on any single part of the city to achieve good performance. Districts with higher error tend to be those with unusual or sparse burglary activity, which naturally produces more volatile predictions. The model does not systematically fail in any specific district. Taken together, the results show that the model generalizes well across space and that the Street Light Out features provide stable predictive information throughout the city.\n\n# Part 6: Model Evaluation Compare to KDE baseline\n\nIn this part, I compare the fitted Negative Binomial model to a simple spatial baseline using kernel density estimation. The baseline assumes that crime is most likely to occur near locations where it has occurred in the past and ignores explicit predictors.\n\n## 6.1 Kernel Density Baseline\n\n```{r kde-baseline}\n#| message: false\n\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\nThe kernel density estimate takes the point pattern of burglaries and smooths it into a continuous surface of risk. Extracting mean values from this surface for each grid cell gives a set of predicted counts that rely entirely on the historical spatial pattern rather than on Street Light Out features or distances. This serves as a useful benchmark because many police agencies rely on kernel density maps for near term forecasting.\n\n## 6.2 Final Predictions\n\n```{r final-predictions}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n\nHere I refit the Negative Binomial model on the full 2017 data set and generate predicted burglary counts for every grid cell. I also scale the kernel density values so that the total predicted count matches the total observed count. This makes the two sets of predictions directly comparable at the grid cell level.\n\n## 6.3 Map Actual vs Predicted\n\n```{r compare-models}\n#| fig-width: 18\n#| fig-height: 10\n\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\nThe three panel figure compares actual burglary counts to the predictions from the Negative Binomial model and from the kernel density baseline. Visually, both prediction maps reproduce the main hot spot areas that appear in the observed data. The kernel density predictions tend to follow the strongest clusters closely, while the Negative Binomial predictions reflect both the history of crime and the influence of Street Light Out features and distances. In some fringe areas, the model spreads risk slightly differently than the kernel density method, especially where outage patterns diverge from past burglary patterns.\n\n## 6.4 Quantitative Comparison of Negative Binomial vs KDE\n\n```{r model-comparison-metrics}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\nThe kernel density approach produces lower prediction error than the Negative Binomial model. This result is expected because kernel density estimation directly reproduces the spatial structure of past burglaries. The Negative Binomial model trades a small amount of predictive accuracy for interpretability about how Street Light Out features and spatial context relate to burglary counts.\n\n## 6.5 Error Maps\n\n```{r error-maps}\n#| fig-width: 18\n#| fig-height: 10\n\nfishnet <- fishnet |>\n  mutate(\n    error_nb  = countBurglaries - prediction_nb,\n    abs_error_nb = abs(error_nb)\n  )\n\np_err <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(low = \"#2166ac\", mid = \"white\", high = \"#b2182b\", midpoint = 0,\n                       name = \"Error\n(actual - pred)\") +\n  labs(title = \"NB Model Errors\") +\n  theme_crime()\n\np_abs <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", name = \"Absolute error\") +\n  labs(title = \"Absolute NB Errors\") +\n  theme_crime()\n\np_err + p_abs\n```\n\nThe Negative Binomial model performs well in large areas of the city and captures the main hot spot regions correctly. The largest errors occur near the most intense burglary clusters. Outside these core hot spots, the model predicts counts with relatively small error.\n\n# Part 7: Temporal Validation (2018)\n\nFinally, I test how well the 2017 model predicts burglaries in 2018. This is a more challenging and realistic test, because it asks the model to generalize across time rather than just across space.\n\n## 7.1 Load and Aggregate 2018 Burglaries\n\n```{r load-burglaries-2018}\n# NOTE: Update the file path/name if your 2018 burglary shapefile is named differently\n#crime_2018 <- st_read(here(\"data\", \"burglaries_2018.shp\"), quiet = TRUE) %>%\n  #st_transform('ESRI:102271')\n\n#burglaries_2018 <- crime_2018 %>%\n  #filter(primary_ty == \"BURGLARY\" , descriptio == \"FORCIBLE ENTRY\")\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nburglaries_2018 <- readRDS(here(\"data\", \"burglaries_2018_filtered.rds\"))\n\nburg_2018_fishnet <- st_join(burglaries_2018, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarise(countBurglaries_2018 = n(), .groups = \"drop\")\n\nfishnet_2018 <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(uniqueID, street_lights, street_lights.nn, dist_to_hotspot) %>%\n  left_join(burg_2018_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries_2018 = replace_na(countBurglaries_2018, 0L))\n\nsummary(fishnet_2018$countBurglaries_2018)\n```\n\nThe 2018 burglary incidents are filtered in the same way as the 2017 incidents and then aggregated to the existing grid. Using the same grid ensures that the two years are directly comparable. The summary of the 2018 counts shows a broadly similar pattern, with many zero cells and a smaller number of higher count cells, although the exact distribution differs from that of 2017.\n\n## 7.2 Predict 2018 Burglaries and Evaluate\n\n```{r predict-2018}\nfishnet_2018 <- fishnet_2018 |>\n  mutate(\n    pred_2018_nb = predict(\n      final_model,\n      newdata = fishnet_2018,\n      type = \"response\"\n    )\n  )\n\n# Temporal validation metrics\nvalidation_2018 <- fishnet_2018 |>\n  summarise(\n    mae_2018  = mean(abs(countBurglaries_2018 - pred_2018_nb)),\n    rmse_2018 = sqrt(mean((countBurglaries_2018 - pred_2018_nb)^2))\n  )\n\nvalidation_2018\n```\n\nThe temporal validation errors for 2018 are very similar to, and slightly lower than, the spatial cross-validation errors for 2017. This suggests that the model generalizes about as well across time as it does across space. Even so, year-to-year changes in burglary activity and maintenance conditions mean that the model should be updated regularly if it were used operationally.\n\n# Conclusion\n\nThis analysis shows that Street Light Out complaints carry meaningful information about burglary risk in Chicago. At the grid-cell level, cells with more outages, shorter distances to outages, and closer proximity to outage hot spots tend to have higher burglary counts. The Poisson model captures these patterns, but a strong overdispersion diagnostic and much lower AIC values indicate that the Negative Binomial specification is the appropriate choice for both inference and prediction.\n\nWhen I compare the Negative Binomial model to a kernel density baseline, the kernel density predictions produce lower error. This is expected because kernel density estimation directly reproduces the spatial structure of past burglaries, while the regression model trades some predictive accuracy for interpretability about how outage counts, proximity, and clustering relate to burglary risk. Spatial cross-validation by police district shows that the model generalizes reasonably well across most districts, even though prediction error is higher in a few districts with more unusual or sparse burglary patterns. Temporal validation using 2018 burglaries produces errors that are similar in magnitude to the spatial cross-validation results, which suggests that the relationship between 2017 outage patterns and burglary risk is relatively stable from one year to the next.\n\nThese results highlight both the promise and limits of using operational infrastructure data for crime prediction. Street Light Out complaints are not a substitute for historical crime data, but they do help explain where burglary risk concentrates and offer a forward-looking signal that does not rely on future crime records. In practice, the strongest approach would combine kernel density forecasts based on recent burglaries with explanatory models that incorporate outage patterns and other environmental features. Together, these tools can support more proactive, maintenance-oriented urban safety strategies while making the underlying drivers of predicted hot spots more transparent to planners, engineers, and communities.\n\n","srcMarkdownNoYaml":"\n\n# Introduction\n\nStreet lighting plays an important role in shaping urban safety and crime prevention. The broken windows perspective states that visible signs of disorder, such as street lights that do not work, can signal weakened social control and encourage criminal activity. Crime Prevention Through Environmental Design also emphasizes visibility, natural surveillance, and well maintained public spaces as environmental factors that influence offending. For this reason, complaints about street lights being out provide a clear and measurable indicator of neighborhood maintenance and environmental disorder that may relate to burglary risk.\n\nThis analysis investigates whether patterns of street light outages help predict burglary risk in Chicago. I use data on burglaries and 311 complaints from the year 2017 and begin by examining the spatial distribution of both datasets in order to identify prominent clusters and areas where outages and burglaries appear together. I then aggregate all features to a regular 500 meter fishnet grid that covers the entire city. This grid provides a consistent spatial structure for modeling. For each grid cell I create several spatial predictors, including the count of burglaries, the count of street light outages, the mean distance to nearby outages, the distance to nearby street light outage hot spots, and a Local Moran’s I statistic that captures spatial clustering and outlier patterns in the outage counts.\n\nUsing these features, I estimate Poisson and Negative Binomial count regression models to evaluate how well street light outages and spatial context explain variation in burglary counts across the grid. I assess the fit of the models using AIC values and also evaluate predictive performance through spatial validation using a Leave One Group Out cross validation that separates the data by police district. I also compare the regression models to a kernel density estimate, which is a commonly used spatial baseline for crime prediction.\n\nAs a final step, I test the model that was trained on 2017 data using burglaries from the year 2018. This allows me to evaluate how well the model performs when predicting a future year rather than data from the same period. Together, these steps help determine whether street light outage patterns contain meaningful predictive information about burglary risk and whether these patterns can support forward looking urban safety strategies.\n\n# Setup\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n# Part 1: Data Loading & Exploration\n\nIn this part, I load the Chicago spatial boundaries, the 2017 burglary data set, and the 311 Street Lights Out data set. I then create point maps and kernel density maps to explore the spatial distribution of burglaries and Street Light Out complaints.\n\nThis step is important because it confirms that the data sets align in space and time and it gives a first look at whether the Street Light Out complaints appear in similar broad locations as burglaries. From these maps I begin to see whether the violation type has a clustered pattern that might be useful for prediction.\n\n## 1.1 Load Chicago Spatial Data\n\n```{r load-boundaries}\n#| message: false\n\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\", quiet = TRUE) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded spatial boundaries\\n\")\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\nThe city boundary and the police district and beat layers define the spatial context for all later analysis. Loading these layers first ensures that every other data set can be transformed into a common reference system and clipped to the same geographic extent.\n\n## 1.2. Load Burglary Data\n\n```{r load-burglaries}\n#| message: false\n\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"data\", \"burglaries.shp\"), quiet = TRUE) %>% \n  st_transform('ESRI:102271')\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\nThe burglary layer provides the outcome that the models will try to predict.\n\n## 1.3 Load 311 Street Light Out Complaints\n\n```{r data-streetlight}\n#lights_raw <- read_csv(here(\"data\", \"311_StreetLightsOneOut_Historical.csv\"))\n\n#head(lights_raw$`Creation Date`, 5) #check date format\n\n#lights_years <- lights_raw %>%\n  #mutate(creation_date = mdy(`Creation Date`)) %>%\n  #mutate(year = year(creation_date)) %>%\n  #filter(year == 2017) %>%\n  #filter(!is.na(Latitude), !is.na(Longitude))\n\n#street_lights <- lights_years %>%\n  #st_as_sf(coords = c(\"Longitude\", \"Latitude\"),\n           #crs = 4326,\n           #remove = FALSE) %>%\n  #st_transform('ESRI:102271')\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nstreet_lights <- readRDS(here(\"data\", \"street_lights_2017.rds\"))\n\ncat(\"✓ Loaded streetlight out complaints\\n\")\ncat(\"  - Number of complaints:\", nrow(street_lights), \"\\n\")\n```\n\nFor the Street Light Out data, I filter the full historical record to the year 2017 and remove any records that are missing coordinates. Converting these complaints into a spatial layer in the same reference system as the burglaries allows a direct comparison in map form.\n\n## 1.4 Visualize Point Data\n\n```{r visualize-points}\n#| fig-width: 18\n#| fig-height: 14\n\n# Extract coordinates for density plots\nburg_coords   <- data.frame(st_coordinates(burglaries))\nlights_coords <- data.frame(st_coordinates(street_lights))\n\n# Burglary point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Burglary density surface\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = burg_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Burglary Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Street light complaint point map\np3 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = street_lights, color = \"#3b528b\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Street Light Out 311 Requests\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(street_lights))\n  )\n\n# Street light density surface\np4 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = lights_coords,\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Street Light Out Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n(p1 + p2) / (p3 + p4) + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries and Street Light Out Complaints in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\nThe comparison of kernels and point maps shows that both burglaries and Street Light Out complaints have strong clustering and that some clusters overlap in similar regions. This pattern supports the idea that outage patterns may provide useful information for predicting burglary risk.\n\n# Part 2: Fishnet Grid Creation\n\nHere I create a 500m X 500m fishnet grid over Chicago, aggregate both burglaries and Street Light Out complaints to each grid cell, and visualize the resulting count distributions.\n\nThis step is important because the count models operate at the grid cell level rather than on individual points. Aggregation also allows me to compute spatial features and to compare cells in a consistent way across the entire city. The maps and summary statistics reveal how skewed the distributions are and how many cells have zero incidents.\n\n## 2.1 Create 500m Fishnet\n\n```{r create-fishnet}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\nThe fishnet creates a regular grid that covers the Chicago boundary, with each cell representing an equal area unit of analysis. Working with this grid makes it possible to treat every part of the city in the same way, rather than relying on irregular administrative boundaries.\n\n## 2.2 Aggregate Burglaries to Grid\n\n```{r burglaries-fishnet}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\nsummary(fishnet$countBurglaries)\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\nAggregating burglaries to the grid reveals how concentrated burglary incidents are when viewed at this spatial scale. The summary output reports the distribution of counts per cell and the proportion of cells that have no burglaries at all. A large share of cells contain no incidents, while a smaller number have several, which indicates a very uneven distribution of risk across space.\n\n## 2.3 Aggregate Street Light Out Complaints to Grid\n\n```{r lights-fishnet}\nlights_fishnet <- st_join(street_lights, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(street_lights = n(), .groups = \"drop\")\n\nfishnet <- fishnet %>%\n  left_join(lights_fishnet, by = \"uniqueID\") %>%\n  mutate(street_lights = replace_na(street_lights, 0))\n\ncat(\"Streetlight Out distribution:\\n\")\nsummary(fishnet$street_lights)\n```\n\nRepeating the same aggregation for Street Light Out complaints produces a comparable count for each grid cell. The summary output again shows many cells with no outages and a smaller number with multiple complaints. This reinforces the idea that the Street Light Out variable is also highly skewed and that outages tend to occur in clusters rather than uniformly across the city.\n\n## 2.4 Visualize\n\n```{r visualize-fishnet}\n#| fig-width: 18\n#| fig-height: 10\np_burg_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(option = \"plasma\", trans = \"sqrt\", name = \"Burglaries\") +\n  labs(title = \"Burglary Counts per 500m Grid Cell\") +\n  theme_crime()\n\np_lights_grid <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = street_lights), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", trans = \"sqrt\", name = \"Street light\\ncomplaints\") +\n  labs(title = \"Street Light Out Complaints per 500m Grid Cell\") +\n  theme_crime()\n\np_burg_grid + p_lights_grid\n```\n\n```{r summary-fishnet}\nfishnet %>%\n  st_drop_geometry() %>%\n  summarise(\n    mean_burg = mean(countBurglaries),\n    max_burg  = max(countBurglaries),\n    pct_zero_burg = mean(countBurglaries == 0),\n    mean_lights = mean(street_lights),\n    max_lights  = max(street_lights),\n    pct_zero_lights = mean(street_lights == 0)\n  )\n```\n\nThe grid maps show strongly skewed count distributions for both burglaries and outages, with many zero count cells and a small number of high count cells. This pattern confirms the need for models that can handle over dispersed count outcomes.\n\n# Part 3: Spatial Features\n\nIn this part, I construct spatial features that describe how each grid cell relates to nearby Street Light Out complaints and to the broader pattern of disorder. I create nearest neighbor features, identify Local Moran's I clusters of Street Light Out complaints, and compute distance to hot spot cells.\n\nThese features are important because they capture spatial context that simple counts cannot. For example, a cell with no outages but that sits next to a cluster of outages may still be influenced by local maintenance conditions.\n\n## 3.1 k-Nearest Neighbor Features\n\n```{r nn-feature}\n#| message: false\n\n# Calculate mean distance to 3 nearest streetlights that are out\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nstreetlight_coords <- st_coordinates(street_lights)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(streetlight_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    street_lights.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\nsummary(fishnet$street_lights.nn)\n```\n\nFor each grid cell, I compute the average distance from the cell centroid to the three nearest Street Light Out complaints. This feature captures how close a given location is to the surrounding pattern of outages, even if the cell itself has no complaints. The summary output shows that some cells are very close to outages, while others are relatively far away. Larger values indicate more distant or sparse outage activity, while smaller values indicate that complaints are nearby.\n\n## 3.2 Local Moran’s I: Hot Spots and Cold Spots\n\n```{r local-morans-streetlights}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n\n# Create spatial weights\ncoords <- st_coordinates(st_centroid(data))\nneighbors <- knn2nb(knearneigh(coords, k = k))\nweights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n# Calculate Local Moran's I\nlocal_moran <- localmoran(data[[variable]], weights)\n  \n# Classify clusters\nmean_val <- mean(data[[variable]], na.rm = TRUE)\n  \ndata %>%\n  mutate(\n    local_i = local_moran[, 1],\n    p_value = local_moran[, 5],\n    is_significant = p_value < 0.05,\n      \nmoran_class = case_when(\n  !is_significant ~ \"Not Significant\",\n  local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n  local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n  local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n  local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n  TRUE ~ \"Not Significant\"))\n}\n\n# Apply to streetlights\nfishnet <- calculate_local_morans(fishnet, \"street_lights\", k = 5)\n```\n\n```{r visualize-morans}\n#| fig-width: 18\n#| fig-height: 10\n\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Street Light Out Complaint Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\nThe Local Moran's I classification shows where Street Light Out complaints form clusters of high or low values. High High cells are locations with many outages surrounded by neighbors that also have many outages. Low Low cells are locations with few outages where neighbors also have few outages. High Low and Low High cells represent outliers that behave differently from their neighbors. In the map, hot spots of disorder appear as groups of High High cells, while large parts of the city fall into the Low Low or not significant classes. This confirms that outages are highly clustered and that some neighborhoods experience much more maintenance related disorder than others.\n\n## 3.3 Distance to Hot Spots\n\n```{r distance-to-hotspots}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to street light outage hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\nUsing the High High cells as hot spots of Street Light Out complaints, I calculate the distance from every grid cell centroid to the nearest hot spot. This feature reflects how close each location is to the most severe maintenance problems in the city. If outages contribute to burglary risk, I expect cells that are closer to hot spots of outages to have higher predicted burglary counts than cells that are far away.\n\n# Part 4: Count Regression Models\n\nIn this part, I fit count regression models that use Street Light Out features and spatial context to predict burglary counts per grid cell. I begin with a Poisson model, check for over dispersion, and then fit a Negative Binomial model. This sequence gives a formal way to quantify the relationship between the predictors and burglary risk and to judge which model form is more appropriate.\n\n## 4.1 Prepare Modeling Data and Join Police Districts\n\n```{r prepare-data}\n# Join district information to fishnet for spatial cross-validation later\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    street_lights,\n    street_lights.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\nJoining police districts to the grid prepares the data set for spatial cross validation in a later section. Dropping geometry and selecting only the predictor and outcome columns produces a clean modeling table where each row represents a grid cell. Removing any remaining missing values ensures that the regression models use only complete records.\n\n## 4.2 Poisson Regression\n\n```{r fit-poisson}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\nAll three predictors are statistically significant. Higher counts of Street Light Out complaints are associated with higher expected burglary counts. The nearest neighbor distance to outages has a strong negative effect, which means burglary counts tend to be higher when outages are located close to the grid cell. Distance to the major outage hot spots also has a negative effect, which indicates that burglary counts are higher in places located near clusters of outages. Among the predictors, the nearest neighbor distance has the strongest effect in magnitude, which suggests that the spatial structure of outage locations explains more variation than the raw count alone.\n\n## 4.3 Check for Overdispersion\n\nA key Poisson assumption is that the variance equals the mean. In reality, crime data often exhibits overdispersion: the variance exceeds the mean due to unobserved heterogeneity. We can check this by calculating the dispersion parameter:\n\n```{r check-overdispersion}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\nThe dispersion statistic is well above the rule-of-thumb threshold of 1.5, which confirms strong overdispersion. This means the Poisson model is not appropriate for these data and a Negative Binomial model is required.\n\n## 4.4 Negative Binomial Regression\n\nThe Negative Binomial model adds a dispersion parameter that allows the variance to exceed the mean, making it more appropriate for overdispersed count data.\n\n```{r fit-negbin}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\nThe Negative Binomial model produces the same pattern of results as the Poisson model, but with a much better fit. All predictors remain statistically significant and the signs of the coefficients are unchanged. Higher Street Light Out counts are associated with higher expected burglary counts. Both the nearest neighbor distance and the distance to outage hot spots remain negative and significant, which means burglary counts increase in places where outages are close and where outage clusters are nearby.\n\nThe nearest neighbor distance has the strongest effect in magnitude, which reinforces the importance of the spatial arrangement of outages rather than the simple number of outages in each cell. The AIC comparison shows a major improvement. The Poisson model has an AIC of 8966.5, while the Negative Binomial model has an AIC of 7515.8. This very large reduction shows that the Negative Binomial distribution fits the data far better and is the appropriate choice for prediction and interpretation.\n\n# Part 5: Spatial Cross-Validation (2017)\n\nHere I evaluate how well the 2017 Negative Binomial model generalizes across space using Leave-One-Group-Out cross-validation, where the group is the police district. This step matters because random cross validation can mix nearby cells into both training and test sets, which can give an overly optimistic view of performance. By holding out entire districts, I force the model to predict areas that it has not seen during training.\n\n## 5.1 Leave-One-Group-Out Cross-Validation by Police District\n\n```{r spatial-cv}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ street_lights + street_lights.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\nThe cross validation loop fits the Negative Binomial model many times, each time leaving out a different police district from the training data and using that district as the test set. For each fold, I record the mean absolute error and the root mean squared error between observed and predicted burglary counts in the held out district. The summary lines at the end report the average error across all districts. These numbers represent a realistic measure of how far the model tends to be from the true burglary counts when it is used to predict new parts of the city.\n\n```{r cv-results-table}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n```\n\nThe cross validation results show that the model performs consistently across most districts. The range of mean absolute error values is fairly narrow, which indicates that the model does not depend on any single part of the city to achieve good performance. Districts with higher error tend to be those with unusual or sparse burglary activity, which naturally produces more volatile predictions. The model does not systematically fail in any specific district. Taken together, the results show that the model generalizes well across space and that the Street Light Out features provide stable predictive information throughout the city.\n\n# Part 6: Model Evaluation Compare to KDE baseline\n\nIn this part, I compare the fitted Negative Binomial model to a simple spatial baseline using kernel density estimation. The baseline assumes that crime is most likely to occur near locations where it has occurred in the past and ignores explicit predictors.\n\n## 6.1 Kernel Density Baseline\n\n```{r kde-baseline}\n#| message: false\n\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\nThe kernel density estimate takes the point pattern of burglaries and smooths it into a continuous surface of risk. Extracting mean values from this surface for each grid cell gives a set of predicted counts that rely entirely on the historical spatial pattern rather than on Street Light Out features or distances. This serves as a useful benchmark because many police agencies rely on kernel density maps for near term forecasting.\n\n## 6.2 Final Predictions\n\n```{r final-predictions}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ street_lights + street_lights.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n\nHere I refit the Negative Binomial model on the full 2017 data set and generate predicted burglary counts for every grid cell. I also scale the kernel density values so that the total predicted count matches the total observed count. This makes the two sets of predictions directly comparable at the grid cell level.\n\n## 6.3 Map Actual vs Predicted\n\n```{r compare-models}\n#| fig-width: 18\n#| fig-height: 10\n\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\nThe three panel figure compares actual burglary counts to the predictions from the Negative Binomial model and from the kernel density baseline. Visually, both prediction maps reproduce the main hot spot areas that appear in the observed data. The kernel density predictions tend to follow the strongest clusters closely, while the Negative Binomial predictions reflect both the history of crime and the influence of Street Light Out features and distances. In some fringe areas, the model spreads risk slightly differently than the kernel density method, especially where outage patterns diverge from past burglary patterns.\n\n## 6.4 Quantitative Comparison of Negative Binomial vs KDE\n\n```{r model-comparison-metrics}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\nThe kernel density approach produces lower prediction error than the Negative Binomial model. This result is expected because kernel density estimation directly reproduces the spatial structure of past burglaries. The Negative Binomial model trades a small amount of predictive accuracy for interpretability about how Street Light Out features and spatial context relate to burglary counts.\n\n## 6.5 Error Maps\n\n```{r error-maps}\n#| fig-width: 18\n#| fig-height: 10\n\nfishnet <- fishnet |>\n  mutate(\n    error_nb  = countBurglaries - prediction_nb,\n    abs_error_nb = abs(error_nb)\n  )\n\np_err <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(low = \"#2166ac\", mid = \"white\", high = \"#b2182b\", midpoint = 0,\n                       name = \"Error\n(actual - pred)\") +\n  labs(title = \"NB Model Errors\") +\n  theme_crime()\n\np_abs <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(option = \"magma\", name = \"Absolute error\") +\n  labs(title = \"Absolute NB Errors\") +\n  theme_crime()\n\np_err + p_abs\n```\n\nThe Negative Binomial model performs well in large areas of the city and captures the main hot spot regions correctly. The largest errors occur near the most intense burglary clusters. Outside these core hot spots, the model predicts counts with relatively small error.\n\n# Part 7: Temporal Validation (2018)\n\nFinally, I test how well the 2017 model predicts burglaries in 2018. This is a more challenging and realistic test, because it asks the model to generalize across time rather than just across space.\n\n## 7.1 Load and Aggregate 2018 Burglaries\n\n```{r load-burglaries-2018}\n# NOTE: Update the file path/name if your 2018 burglary shapefile is named differently\n#crime_2018 <- st_read(here(\"data\", \"burglaries_2018.shp\"), quiet = TRUE) %>%\n  #st_transform('ESRI:102271')\n\n#burglaries_2018 <- crime_2018 %>%\n  #filter(primary_ty == \"BURGLARY\" , descriptio == \"FORCIBLE ENTRY\")\n\n#The raw file was too huge for GitHub so I commented the code and added in the rds file.\n\nburglaries_2018 <- readRDS(here(\"data\", \"burglaries_2018_filtered.rds\"))\n\nburg_2018_fishnet <- st_join(burglaries_2018, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarise(countBurglaries_2018 = n(), .groups = \"drop\")\n\nfishnet_2018 <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(uniqueID, street_lights, street_lights.nn, dist_to_hotspot) %>%\n  left_join(burg_2018_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries_2018 = replace_na(countBurglaries_2018, 0L))\n\nsummary(fishnet_2018$countBurglaries_2018)\n```\n\nThe 2018 burglary incidents are filtered in the same way as the 2017 incidents and then aggregated to the existing grid. Using the same grid ensures that the two years are directly comparable. The summary of the 2018 counts shows a broadly similar pattern, with many zero cells and a smaller number of higher count cells, although the exact distribution differs from that of 2017.\n\n## 7.2 Predict 2018 Burglaries and Evaluate\n\n```{r predict-2018}\nfishnet_2018 <- fishnet_2018 |>\n  mutate(\n    pred_2018_nb = predict(\n      final_model,\n      newdata = fishnet_2018,\n      type = \"response\"\n    )\n  )\n\n# Temporal validation metrics\nvalidation_2018 <- fishnet_2018 |>\n  summarise(\n    mae_2018  = mean(abs(countBurglaries_2018 - pred_2018_nb)),\n    rmse_2018 = sqrt(mean((countBurglaries_2018 - pred_2018_nb)^2))\n  )\n\nvalidation_2018\n```\n\nThe temporal validation errors for 2018 are very similar to, and slightly lower than, the spatial cross-validation errors for 2017. This suggests that the model generalizes about as well across time as it does across space. Even so, year-to-year changes in burglary activity and maintenance conditions mean that the model should be updated regularly if it were used operationally.\n\n# Conclusion\n\nThis analysis shows that Street Light Out complaints carry meaningful information about burglary risk in Chicago. At the grid-cell level, cells with more outages, shorter distances to outages, and closer proximity to outage hot spots tend to have higher burglary counts. The Poisson model captures these patterns, but a strong overdispersion diagnostic and much lower AIC values indicate that the Negative Binomial specification is the appropriate choice for both inference and prediction.\n\nWhen I compare the Negative Binomial model to a kernel density baseline, the kernel density predictions produce lower error. This is expected because kernel density estimation directly reproduces the spatial structure of past burglaries, while the regression model trades some predictive accuracy for interpretability about how outage counts, proximity, and clustering relate to burglary risk. Spatial cross-validation by police district shows that the model generalizes reasonably well across most districts, even though prediction error is higher in a few districts with more unusual or sparse burglary patterns. Temporal validation using 2018 burglaries produces errors that are similar in magnitude to the spatial cross-validation results, which suggests that the relationship between 2017 outage patterns and burglary risk is relatively stable from one year to the next.\n\nThese results highlight both the promise and limits of using operational infrastructure data for crime prediction. Street Light Out complaints are not a substitute for historical crime data, but they do help explain where burglary risk concentrates and offer a forward-looking signal that does not rely on future crime records. In practice, the strongest approach would combine kernel density forecasts based on recent burglaries with explanatory models that incorporate outage patterns and other environmental features. Together, these tools can support more proactive, maintenance-oriented urban safety strategies while making the underlying drivers of predicted hot spots more transparent to planners, engineers, and communities.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"embed-resources":true,"output-file":"assignment_4.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Assignment 4: Spatial Predictive Analysis","subtitle":"Using Street Light Outages to Predict Burglary Risk in Chicago","author":"Kavana Raju","date":"today","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}