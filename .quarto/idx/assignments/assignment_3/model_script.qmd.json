{"title":"Philadelphia Housing Price Prediction - Technical Appendix","markdown":{"yaml":{"title":"Philadelphia Housing Price Prediction - Technical Appendix","author":"Nina Carlsen, Ryan Drake, Sujanesh Kakumanu, Kavana Raju, Chloe Robinson, Henry Sywulak-Herr.","execute":{"cache":true},"format":{"html":{"code-fold":"show","toc":true,"toc-location":"left","theme":"cosmo","number-sections":true}}},"headingText":"Packages","containsRefs":false,"markdown":"\n\nThis technical appendix documents the full workflow used to engineer and visualize spatial features for predicting residential housing prices in Philadelphia.\n\n```{r setup-and-files}\noptions(scipen = 999)\n\nif(!require(pacman)){install.packages(\"pacman\"); library(pacman, quietly = T)}\np_load(knitr, sf, tidyverse, tidycensus, tigris, here, dplyr, FNN, ggplot2, scales, patchwork, caret, Hmisc, stargazer)\n\n# Files\nsf_data <- st_read(\"./data/OPA_data.geojson\", quiet = TRUE)\nnhoods <- st_read(\"./data/philadelphia-neighborhoods.geojson\", quiet = TRUE)\n\n```\n\n# Property sales data\n\n## Data Preparation\n\nWe apply several filters to the property data to for quality and relevance. First, we restrict our analysis to residential properties sold between 2023 and 2024, excluding any other property categories. Second, we remove properties with sale prices below \\$10, as these are abnormal prices for residential properties.\n\nTo work with Github file size limits, the data is further trimmed of irrelevant columns.\n\n```{r opa-cleaning}\n#| output: false\n\n# Restrict to residential only\nresidential_categories <- c(\n  \"APARTMENTS > 4 UNITS\",\n  \"MULTI FAMILY\",\n  \"SINGLE FAMILY\",\n  \"MIXED USE\"\n)\nresidential_data <- sf_data %>%\n  filter(category_code_description %in% residential_categories,\n         year(sale_date) %in% c(2023, 2024),\n         mailing_city_state == \"PHILADELPHIA PA\",\n         sale_price > 10\n         )\n\ntable(residential_data$category_code_description)\n\n# Making sure the file saved to the repo is the trimmed data (to stay below GitHub data limits)\nst_write(residential_data, \"./data/OPA_data.geojson\", driver = \"GeoJSON\", delete_dsn = TRUE, quiet = TRUE)\nfile.exists(\"./data/OPA_data.geojson\")\nOPA_raw <- st_read(\"./data/OPA_data.geojson\", quiet = TRUE) %>% \n  st_transform(2272)\n\n# OPA_data -> cutting mostly NA columns or irrelevant columns for this model.\nOPA_raw <- OPA_raw %>%\n  select(-c(\n  cross_reference, date_exterior_condition, exempt_land, fireplaces, fuel, garage_type, house_extension, mailing_address_2, mailing_care_of, market_value_date, number_of_rooms, other_building, owner_2, separate_utilities, sewer, site_type, street_direction, suffix, unfinished, unit, utility\n  ))\n\nnames(OPA_raw)\n```\nThe property sales data was gathered from the OPA properties public data set from the City of Philadelphia. This data set was 32 columns and 583,825 observations. This file was too large for our shared GitHub work space so it was reduced by filtering for residential properties, years 2023 and 2024, location within Philadelphia, and sale price over 10 since some were NA, 1, or 10. This was just enough to get the most basic and general data to work with that ran with GitHub size limits. This reduced the size to 22121 observations. The original geojson file was overwritten and named OPA_data.\n\nProperties selected for residential included apartments >4 units, single family, multi-family, and mixed use. Mixed use was left in as there are still residential unit to account yet add more complex property types to our total data set when comparing sale price and other aspects such as total area to other observations. These properties should also be cross referenced with zoning codes for future research.\n\nWe left mixed use in during this process to give us the most general data set representation. There was also limited data cleaning other than omitting columns that were mostly NA. This gave our model the most general data set to work with despite lower future RMSE values. Future research would be needed to most accurately assess the choices of losing data and a more generalized Philadelphia housing market verses very clean data and more specific Philadelphia housing market that may omit certain aspects of the housing market like data in lower income areas or multi use residential aspects. This could have also been conducted in grouping NA values and sparse categories. More complexity could be accounted for in future work.\n\nThis was our start simple and add complexity approach. Our original to final OPA data set went from 583,825 to 22,121 observations and from 32 to 68 variables.\n\n## Exploratory Data Analysis\n\nBelow are selected property variables—Total Livable Area, Bedrooms, Bathrooms, and Age—in relation to Sale Price. Properties with excessive square footage (\\>10,000 sqft), missing bedroom or bathroom data, over 12 bathrooms with low sale prices, or implausible construction years were removed to reduce skew and data errors. This additional filtering was kept for the rest of the analysis in this report.\n\n```{r filtering-OPA-and-plots}\n\n# filter out outliers from the dataset\nOPA_data <- OPA_raw %>%\n  filter(\n    total_livable_area <= 10000,\n    year_built > 1800,\n    !is.na(number_of_bathrooms),\n    !is.na(number_of_bedrooms),\n    number_of_bathrooms < 12,\n  ) %>%\n  mutate(\n    year_built = as.numeric(year_built),\n    building_age = 2025 - year_built\n  )\n\np1 <- ggplot(OPA_data, aes(x = total_livable_area, y = sale_price)) +\n  geom_point(alpha = 0.3, size = 0.8) +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_x_continuous(labels = comma_format()) +\n  labs(\n    title = \"Sale Price vs. Total Livable Area\",\n    x = \"Total Livable Area (sq ft)\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np2 <- ggplot(OPA_data, aes(x = factor(number_of_bedrooms), y = sale_price)) +\n  geom_boxplot(fill = \"gray\", alpha = 0.6, outlier.alpha = 0.3, outlier.size = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 2, shape = 18) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Number of Bedrooms\",\n    x = \"Number of Bedrooms\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np3 <- ggplot(OPA_data, aes(x = factor(number_of_bathrooms), y = sale_price)) +\n  geom_boxplot(fill = \"gray\", alpha = 0.6, outlier.alpha = 0.3, outlier.size = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 2, shape = 18) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Number of Bathrooms\",\n    x = \"Number of Bathrooms\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np4 <- ggplot(OPA_data, aes(x = building_age, y = sale_price)) +\n  geom_point(alpha = 0.3, size = 0.8) +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Age\",\n    x = \"Age\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\n# Combine plots\n(p1 | p2) / (p3 | p4)\n```\n\n## Feature Engineering\n\n```{r opa-interaction-features}\n\nOPA_data <- OPA_data %>%\n  mutate(\n    # convert to numeric before interactions\n    total_livable_area = as.numeric(total_livable_area),\n    census_tract = as.numeric(as.character(census_tract)),\n    year_built = as.numeric(year_built),\n    total_area = as.numeric(total_area),\n    market_value = as.numeric(market_value),\n    number_of_bedrooms = as.numeric(number_of_bedrooms),\n\n    # building code and total area\n    int_type_tarea = as.numeric(as.factor(building_code_description)) * total_area,\n\n    # market and livable area\n    int_value_larea = market_value * total_livable_area,\n\n    # market and total area\n    int_value_tarea = market_value * total_area,\n\n    # livable area and exterior condition\n    int_larea_econd = total_livable_area * as.numeric(as.factor(exterior_condition)),\n\n    # livable area and interior condition\n    int_larea_icond = total_livable_area * as.numeric(as.factor(interior_condition)),\n\n    # livable area and bedrooms\n    int_larea_beds = total_livable_area * number_of_bedrooms\n  )\n\n```\n\n```{r neighborhood-effects}\n#| output: false\n\npa_crs <- 2272  \nneighbor_points <- st_transform(OPA_data, pa_crs)\n\nnrow(nhoods)\n\nst_crs(neighbor_points)\nnhoods <- st_transform(nhoods, 2272)\n\n#joining houses to neighborhoods\nneighbor_points <- neighbor_points %>%\n  st_join(., nhoods, join = st_intersects)\n\n# one property doesn't lie in any neighborhood\nneighbor_points <- neighbor_points[!is.na(neighbor_points$NAME),]\n\n#results \nneighbor_points %>%\n  st_drop_geometry() %>%\n  count(NAME) %>%\n  arrange(desc(n))\n\n```\n\n```{r prices-by-neighborhood-and-map}\n\n#spatial joins\nprice_by_nhood <- neighbor_points %>%\n  st_drop_geometry() %>%\n  group_by(NAME) %>%\n  dplyr::summarize(\n    median_price = median(sale_price, na.rm = TRUE),\n    n_sales = n()\n  )\n\nnhoods_prices <- nhoods %>%\n  left_join(., price_by_nhood, by = \"NAME\")\n\n#setting median house price classes\nnhoods_prices <- nhoods_prices %>%\n  mutate(\n    price_class = cut(median_price,\n                      breaks = c(0, 400000, 600000, 800000, 1000000, Inf),\n                      labels = c(\"Under $400k\", \"$400k-$600k\", \"$600k-$800k\", \n                                 \"$800k-$1M\", \"Over $1M\"),\n                      include.lowest = TRUE)\n  )\n\n#mapping\nggplot() +\n  geom_sf(data = nhoods_prices, aes(fill = price_class), \n          color = \"white\", size = 0.5) +\n  scale_fill_brewer(\n    name = \"Median Price\",\n    palette = \"YlOrRd\",\n    na.value = \"grey90\",\n    direction = 1\n  ) +\n  labs(\n    title = \"Median Home Prices by Philadelphia Neighborhood\",\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.title = element_text(face = \"bold\")\n  )\n\n```\n\n```{r prices-and-sales}\n#| message: false\n#| output: false\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  head(10)\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  print(n = 50)\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  print(n = 50)\n\nprice_by_nhood %>%\n  arrange(desc(n_sales)) %>%\n  head(5)\n\n```\n\n```{r wealthy-neighborhood-effects}\n\n# Define wealthy as >=$420,000 which is 1.5x city median of 279,900\nnhoods_prices <- nhoods_prices %>%\n  mutate(\n    wealthy_neighborhood = ifelse(median_price >= 420000, \"Wealthy\", \"Not Wealthy\"),\n    wealthy_neighborhood = as.factor(wealthy_neighborhood)\n  )\n\nnhoods_prices %>%\n  st_drop_geometry() %>%\n  count(wealthy_neighborhood)\n\nneighbor_points <- neighbor_points %>%\n  left_join(.,\n            nhoods_prices %>%\n              st_drop_geometry %>%\n              select(NAME, wealthy_neighborhood),\n            by = \"NAME\")\n\n# Still add neighbor points to OPA data\n\n```\n\nHouseholds were denoted as wealthy if their median household price was over \\$420,000, which is 1.5x city median of 279,900. This term will be used in an interaction in Model 4 to account for theoretical differences in wealthy neighborhoods, such as inflated costs for additional home amenities such as bedrooms, bathrooms, or livable floor area.\n\n# Census Data\n\n## Data Preparation\n\n```{r census-var-ids}\n\n# link variables and aliases\nvars <- c(\"pop_tot\" = \"B01001_001\",\n          \"med_hh_inc\" = \"B19013_001\",\n          \"med_age\" = \"B01002_001\")\n\n# the FIPS code for the state of PA is 42\nfips_pa <- 42\n\n```\n\nVariables pulled from the census include total population, median household income, and median age.\n\n```{r census-var-acquisition}\n#| output: false\n\n# retrieve data from the ACS for 2023\ndemo_vars_pa <- get_acs(geography = \"tract\",\n                        variable = vars,\n                        year = 2023,\n                        state = fips_pa,\n                        output = \"wide\",\n                        geometry = T,\n                        progress_bar = F) %>% \n  st_transform(2272)\n\n# separate NAME column into its constituent parts\ndemo_vars_pa <- demo_vars_pa %>%\n  separate(NAME,\n           into = c(\"TRACT\", \"COUNTY\", \"STATE\"),\n           sep = \"; \",\n           remove = T) %>% \n  mutate(TRACT = parse_number(TRACT),\n         COUNTY = sub(x = COUNTY, \" County\", \"\"))\n\n# filter out Philadelphia tracts\ndemo_vars_phl <- demo_vars_pa %>%\n  filter(COUNTY == \"Philadelphia\")\n\n```\n\n```{r census-plot}\n\n# plot cenusus variables to compare\nplot(demo_vars_phl[,\"pop_totE\"],\n     main = \"Total Population\",\n     breaks = seq(0, 10500, 500),\n     nbreaks = 21)\nplot(demo_vars_phl[,\"med_hh_incE\"],\n     main = \"Median Household Income\",\n     breaks = seq(0, 200000, 10000),\n     nbreaks = 20)\nplot(demo_vars_phl[,\"med_ageE\"],\n     main = \"Median Age\",\n     breaks = seq(0, 75, 5),\n     nbreaks = 15)\n\n```\n\n```{r census-na-counts}\n\n# get NA counts per column\nna_counts <- sapply(demo_vars_phl, function(x) {sum(is.na(x))})\nkable(t(as.data.frame(na_counts)))\n\n# filter out all rows that have at least one column with an na value\nna_index <- !complete.cases(demo_vars_phl %>% st_drop_geometry())\ndemo_vars_phl_na <- demo_vars_phl[na_index,]\nkable(head(demo_vars_phl_na, 5) %>% select(-ends_with(\"M\")) %>% st_drop_geometry(),\n      col.names = c(\"GeoID\", \"Tract\", \"County\", \"State\", \"Population\", \"Median HH Inc ($)\", \"Median Age (yrs)\"),\n      row.names = F)\n\n```\n\n27 and 17 census tracts have a value of NA for median household income and median age, respectively. For the 17 census tracts where there is no reported population, the median household income and median age will be set to 0. The remaining 10 census tracts that have population but no reported median household income will be omitted from the dataset.\n\n```{r census-isolate-na}\n\n# create a dataset with NAs replaced with zero where applicable\ndemo_vars_phl_rep <- demo_vars_phl %>% \n  mutate(med_hh_incE = case_when(pop_totE == 0 & is.na(med_hh_incE) ~ 0,\n                                 .default = med_hh_incE),\n         med_ageE = case_when(pop_totE == 0 & is.na(med_ageE) ~ 0,\n                                 .default = med_ageE))\n\n# final cleaned dataset without the 10 census tracts that have population values but have NA values for Median Household Income\ndemo_vars_phl_clean <- demo_vars_phl_rep[complete.cases(demo_vars_phl_rep %>%\n                                                          select(-ends_with(\"M\")) %>%\n                                                          st_drop_geometry()),]\n\n# table with the omitted census tracts\ndemo_vars_phl_omit <- demo_vars_phl_rep[!complete.cases(demo_vars_phl_rep %>% select(-ends_with(\"M\")) %>% st_drop_geometry()),]\nkable(demo_vars_phl_omit %>% select(-ends_with(\"M\")) %>% st_drop_geometry(),\n      col.names = c(\"GeoID\", \"Tract\", \"County\", \"State\", \"Population\", \"Median HH Inc ($)\", \"Median Age (yrs)\"),\n      row.names = F, caption = \"Census Tracts Omitted from Analysis due to Data Unavailability\")\n```\n\n```{r census-join-to-OPA_data}\n\n# join census variables to the OPA data\nOPA_data <- st_join(OPA_data, demo_vars_phl_clean %>% select(pop_totE, med_hh_incE, med_ageE))\n\n# isolate NA rows and plot where they are\ncensusNAs <- OPA_data[is.na(OPA_data$med_hh_incE),]\n\ncensus_plt1 <- ggplot() +\n  geom_sf(data = demo_vars_phl_clean$geometry) +\n  geom_sf(data = censusNAs, size = 0.15) +\n  theme_void() +\n  labs(title = \"Properties without Census Data\")\ncensus_plt2 <- ggplot() +\n  geom_sf(data = demo_vars_phl_clean$geometry, fill = \"black\", color = \"transparent\") +\n  theme_void() +\n  labs(title = \"Census Tracts with Data (Black)\")\n\n(census_plt1 | census_plt2)\n```\n\nOf the 22121 properties in the dataset after cleaning and omitting outliers, 248 - approximately 1.1% of the dataset - have no associated census data due to the lack of a Median Household Income value for those census tracts. Comparing plots of property locations without census data and that of census tracts which have data confirms this spatial relationship.\n\n# Spatial Features\n\n## Data Preparation\n\nThis stage prepares and validates the OpenDataPhilly spatial datasets used to engineer neighborhood-level variables for the housing model.\n\n**Steps Performed**\n\n-   Transformed all spatial datasets to **EPSG 2272 (NAD83 / PA South ftUS)** for consistent distance measurements.\n\n-   Removed invalid geometries, dropped Z/M values, and converted all housing geometries to points.\n\n-   Imported and projected OpenDataPhilly amenities:\n\n    -   Transit Stops\n\n    -   Hospitals\n\n    -   Parks & Recreation Sites\n\n    -   Schools Parcels (centroids created from polygon features)\n\n    -   Crime Incidents (2023 and 2024 combined)\n\n```{r open-data-philly-datasets}\n#| message: false\n#| warning: false\n\n#CRS & radii\npa_crs <- 2272    # NAD83 / PA South (ftUS)\nmi_to_ft   <- 5280\nr_park_ft   <- 0.25 * mi_to_ft\nr_crime_ft  <- 0.50 * mi_to_ft\nr_school_ft <- 0.50 * mi_to_ft\n\n# turn off spherical geometry (makes buffer/join ops faster)\nsf::sf_use_s2(FALSE)\n\n## CONVERT SALES DATA TO POINTS ##\nOPA_points <- st_transform(OPA_data, pa_crs)\n\n#Drop Z/M if present\nst_geometry(OPA_points) <- st_zm(st_geometry(OPA_points), drop = TRUE, what = \"ZM\")\n\n#Make geometries valid\nst_geometry(OPA_points) <- st_make_valid(st_geometry(OPA_points))\n\n#Ensure POINT geometry (works for points/lines/polygons/collections)\nst_geometry(OPA_points) <- st_point_on_surface(st_geometry(OPA_points))\n\n#Add sale ID\nOPA_points <- OPA_points %>%\n  mutate(sale_id = dplyr::row_number())\n\n#read & project layers\ntransit   <- st_read(\"./data/Transit_Stops_(Spring_2025)/Transit_Stops_(Spring_2025).shp\", quiet = TRUE) |> st_transform(pa_crs)\nhospitals <- st_read(\"./data/Hospitals.geojson\", quiet = TRUE) |> st_transform(pa_crs)\nparksrec  <- st_read(\"./data/PPR_Program_Sites.geojson\", quiet = TRUE)|> st_transform(pa_crs)\nschools_polygons   <- st_read(\"./data/Schools_Parcels.geojson\", quiet = TRUE) |> st_transform(pa_crs)\ncrime_2023     <- st_read(\"./data/crime_incidents_2023/incidents_part1_part2.shp\", quiet = TRUE)        |> st_transform(pa_crs)\ncrime_2024     <- st_read(\"./data/crime_incidents_2024/incidents_part1_part2.shp\", quiet = TRUE)        |> st_transform(pa_crs)\n\n#combine 2023 & 2024 crime datasets\ncrime <- rbind(crime_2023, crime_2024)\n\n#create centroids for schools dataset\nschools <- if (any(st_geometry_type(schools_polygons) %in% c(\"POLYGON\",\"MULTIPOLYGON\"))) {\n  st_centroid(schools_polygons, )\n} else {\n  schools_polygons\n}\n\n#crop transit data to philadelphia\nphilly_boundary <- st_union(nhoods)\n\ntransit <- st_filter(transit, philly_boundary, .predicate = st_within)\n```\n\n## Exploratory Data Analysis\n\nExploratory plots and maps examine the raw accessibility patterns across Philadelphia before feature engineering.\n\n```{r exploratory-spatial-feature-plots}\n\n# Transit stops (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = transit, size = 0.3, alpha = 0.6) +\n  labs(title = \"Raw Layer Check: Transit Stops (SEPTA Spring 2025)\") +\n  theme_void()\n\n# Hospitals (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = hospitals, size = 0.6, alpha = 0.7) +\n  labs(title = \"Raw Layer Check: Hospitals\") +\n  theme_void()\n\n# Parks & Recreation Program Sites (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = parksrec, size = 0.4, alpha = 0.6) +\n  labs(title = \"Raw Layer Check: Parks & Recreation Sites\") +\n  theme_void()\n\n# Schools (centroids of polygons) — raw\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = schools, size = 0.4, alpha = 0.7) +\n  labs(title = \"Raw Layer Check: Schools (Centroids)\") +\n  theme_void()\n\n# Crime points are huge; sampling for speed\nset.seed(5080)\ncrime_quick <- if (nrow(crime) > 30000) dplyr::slice_sample(crime, n = 30000) else crime\n\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = crime_quick, size = 0.1, alpha = 0.25) +\n  labs(title = \"Raw Layer Check: Crime Incidents (sampled if large)\") +\n  theme_void()\n\n```\n\n### Interpretation\n\n-   **Transit Stops:** Dense corridors radiate from Center City, showing strong transit coverage.\n\n-   **Hospitals:** Sparse but geographically balanced.\n\n-   **Parks & Recreation:** uneven distribution,\n\n-   **Schools:** evenly distributed across most neighborhoods\n\n-   **Crime:** Visibly concentrated, confirming the need for log-transformed counts\n\n## Feature Engineering\n\nSpatial features were derived using two complementary approaches: **k-Nearest Neighbor (kNN)** and **buffer-based counts,** depending on whether accessibility was best captured as proximity or exposure.\n\n```{r knn-features}\n\n#| message: false\n#| warning: false\n\n#clean sales data\nsales_xy <- st_coordinates(OPA_points)\nok_sales  <- complete.cases(sales_xy)\nOPA_points <- OPA_points[ok_sales, ]    # keep only rows with valid XY\nsales_xy  <- st_coordinates(OPA_points) # refresh coordinates\n\ntransit_xy <- st_coordinates(transit)\nhosp_xy    <- st_coordinates(hospitals)\n\n# feature 1 - distance to nearest transit stop (ft)\nknn_tr <- FNN::get.knnx(\n  data  = st_coordinates(transit),\n  query = sales_xy,\n  k = 1)\n\nOPA_points <- OPA_points %>%\n  mutate(dist_nearest_transit_ft = as.numeric(knn_tr$nn.dist[,1]))\n\n# feature 2 - distance to nearest hospital (ft)\nknn_hp <- FNN::get.knnx(\n  data  = st_coordinates(hospitals),\n  query = sales_xy,\n  k = 1)\n\nOPA_points <- OPA_points %>%\n  mutate(dist_nearest_hospital_ft = as.numeric(knn_hp$nn.dist[,1]))\n```\n\n```{r buffer-features}\n#| message: false\n#| warning: false\n\n# feature 3 - parks/rec sites within 0.25 mi (count)\nrel_parks <- sf::st_is_within_distance(OPA_points, parksrec, dist = r_park_ft)\n\nOPA_points <- OPA_points %>%\n  mutate(parks_cnt_0p25mi = lengths(rel_parks))\n\n# feature 4 - crime count within 0.5 mi (per square mile)\ncrime_buffer <- st_buffer(OPA_points, dist = r_crime_ft)\n\nrel_crime <- st_intersects(crime_buffer, crime, sparse = TRUE)\n\n# count number of crimes\ncrime_cnt <- lengths(rel_crime)\n\nrm(rel_crime)\n\nOPA_points <- OPA_points |>\n  mutate(\n    crime_cnt_0p5mi     = crime_cnt,\n    log1p_crime_cnt_0p5 = log1p(crime_cnt_0p5mi)\n  )\n\n# feature 5 - schools within 0.5 mi (using centroids)\nrel_sch <- sf::st_is_within_distance(OPA_points, schools, dist = r_school_ft)\n\nOPA_points <- OPA_points %>%\n  mutate(schools_cnt_0p5mi = lengths(rel_sch))\n```\n\n### Summary Table and Justification\n\n| Feature                          | Method       | Parameter   | Theoretical Rationale                                                                                                           |\n|-------------|-------------|-------------|---------------------------------|\n| Distance to Nearest Transit Stop | kNN (k = 1)  | –           | Captures ease of access to public transport; nearest stop approximates walkability and job access.                              |\n| Distance to Nearest Hospital     | kNN (k = 1)  | –           | Reflects accessibility to health care and emergency services; proximity adds perceived security for households.                 |\n| Parks & Rec Sites within 0.25 mi | Buffer Count | r = 0.25 mi | Measures exposure to green space and recreational facilities within a 5-minute walk; positive amenity effect on property value. |\n| Crime Incidents within 0.5 mi    | Buffer Count | r = 0.5 mi  | Represents local safety environment; higher crime counts reduce housing desirability.                                           |\n| Schools within 0.5 mi            | Buffer Count | r = 0.5 mi  | Reflects educational access and family appeal; clustering of schools often raises residential demand.                           |\n| Population                       | Census       | –           | Represents the present residential demand within a census tract                                                                 |\n| Median Household Income          | Census       | –           | Indicative of the ability of present residents of a census tract to afford housing                                              |\n| Median Age                       | Census       | –           | Measure of the dominant age group in a census tract (i.e. high student or elderly population)                                   |\n\n### Feature Validation and Visualization\n\n```{r feature-validation-plots}\n\n## Transit Accessibility\nggplot(OPA_points, aes(x = dist_nearest_transit_ft)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Distance to Nearest Transit Stop\",\n       x = \"Feet to Nearest Stop\", y = \"Count\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = dist_nearest_transit_ft), size = 0.5) +\n  scale_color_viridis_c(option = \"plasma\", labels = comma) +\n  labs(title = \"Transit Accessibility Across Sales Parcels\",\n       color = \"Distance (ft)\") +\n  theme_void()\n\n## Hospital Proximity\nggplot(OPA_points, aes(x = dist_nearest_hospital_ft)) +\n  geom_histogram(fill = \"darkorange\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Distance to Nearest Hospital\",\n       x = \"Feet to Nearest Hospital\", y = \"Count\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = dist_nearest_hospital_ft), size = 0.5) +\n  scale_color_viridis_c(option = \"magma\", labels = comma) +\n  labs(title = \"Hospital Accessibility Across Sales Parcels\",\n       color = \"Distance (ft)\") +\n  theme_void()\n\n## Parks & Recreation\nggplot(OPA_points, aes(x = parks_cnt_0p25mi)) +\n  geom_histogram(fill = \"seagreen\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution: Parks & Rec Sites Within 0.25 mi\",\n       x = \"Count within 0.25 mi\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = parks_cnt_0p25mi), size = 0.6) +\n  scale_color_viridis_c(option = \"viridis\") +\n  labs(title = \"Proximity to Parks & Recreation (0.25 mi Buffer)\",\n       color = \"Parks Count\") +\n  theme_void()\n\n## Crime Counts\nggplot(OPA_points, aes(x = crime_cnt_0p5mi)) +\n  geom_histogram(fill = \"firebrick\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Crime Incidents Within 0.5 mi\",\n       x = \"Crime Count (2023–2024)\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = log1p_crime_cnt_0p5), size = 0.6) +\n  scale_color_viridis_c(option = \"inferno\") +\n  labs(title = \"Crime Exposure (log-transformed within 0.5 mi)\",\n       color = \"log(1+Crime Count)\") +\n  theme_void()\n\n## Schools Accessibility\nggplot(OPA_points, aes(x = schools_cnt_0p5mi)) +\n  geom_histogram(fill = \"purple\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution: Schools Within 0.5 mi\",\n       x = \"School Count (0.5 mi Buffer)\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = schools_cnt_0p5mi), size = 0.6) +\n  scale_color_viridis_c(option = \"cividis\") +\n  labs(title = \"School Accessibility (0.5 mi Buffer)\",\n       color = \"Schools Count\") +\n  theme_void()\n```\n\n**Interpretation:**\n\n-   **Transit proximity**: Most parcels are within 500 ft of a stop, confirming strong transit coverage across Philadelphia.\n\n-   **Hospital proximity**: Right-skewed distribution, consistent with limited facility count.\n\n-   **Parks access**: Sparse exposure (mostly 0–1 within 0.25 mi), highlighting recreational inequities.\n\n-   **Crime exposure**: Wide variation, clustered along high-density corridors; log-transformed to stabilize scale.\n\n-   **School proximity**: Uniform urban coverage with typical parcels having 4-7 schools within 0.5 mi.\n\n\n```{r sales-data-histogram}\nsp_data <- st_read(\"./data/OPA_data.geojson\", quiet = T)\n\nstr(sp_data$sale_price)\n\nsp_data_filtered <- sp_data %>%\n  mutate(sale_price = as.numeric(sale_price)) %>%\n  filter(sale_price > 1000)\n\nggplot(sp_data_filtered, aes(x = sale_price)) + \n  geom_histogram(\n    binwidth = 20000, \n    fill = \"grey\",\n    color = \"black\"\n  ) +\n  labs(\n    title = \"Histogram of Sale Prices in Philadelphia\", \n    x = \"Sale Price\",\n    y = \"Count of Homes\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = label_dollar()) +\n  coord_cartesian(xlim = c(0, 2000000), ylim = c(0, 3000))\n\nsummary(sp_data_filtered$sale_price)\n\nsp_data_filtered <- sp_data_filtered %>%\n  mutate(\n    sale_price = as.numeric(sale_price),\n    sale_price_capped = pmin(sale_price, quantile(sale_price, 0.99, na.rm = TRUE))\n  )\n\nggplot(sp_data_filtered) +\n  geom_sf(aes(color = sale_price_capped), size = 0.6, alpha = 0.7) +\n  scale_color_viridis_c(labels = label_dollar(), name = \"Sale Price (USD)\") +\n  labs(title = \"Philadelphia Sale Prices\") +\n  theme_minimal()\n```\n\n```{r VIF-analysis}\n\n# function to check for statistically significant correlations between independent variables\nsig_corr <- function(dat, dep_var) {\n  # remove the independent variable from the dataset\n  dat_corr <- dat %>% select(-all_of(dep_var))\n  \n  # run a correlation matrix for the independent vars\n  correlation_matrix <- rcorr(as.matrix(dat_corr))\n  values <- correlation_matrix$r\n  vifs <- apply(values, 1, function(x){\n    return(round(1/(1-abs(x)), 2))\n  })\n  \n  values_df <- values %>% as.data.frame()\n  vifs_df <- vifs %>% as.data.frame()\n  \n  # convert correlation coefficients and p-values to long format\n  corCoeff_df <- correlation_matrix$r %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  corVIF_df <- vifs %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  corPval_df <- correlation_matrix$P %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  # merge long format data\n  corMerge <- list(\n    corCoeff_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"correlation\") %>% as.data.frame(),\n    corVIF_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"vif_factor\") %>% as.data.frame(),\n    corPval_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"p_value\") %>% as.data.frame()) %>%\n    reduce(left_join, by = c(\"var1\", \"var2\"))\n  \n  # filter to isolate unique pairs, then rows with correlation > 0.5 and p < 0.05\n  corUnfiltered <- corMerge %>% \n    filter(var1 != var2) %>% \n    rowwise() %>% \n    filter(var1 < var2) %>% \n    ungroup() %>% \n    as.data.frame()\n  \n  corFiltered <- corUnfiltered %>% \n    filter(abs(vif_factor) > 3 & p_value < 0.05) %>% \n    arrange(desc(abs(correlation)))\n  \n  # save the raw correlation values and the filtered variable pairs\n  final <- set_names(list(values_df, vifs_df, corUnfiltered, corFiltered),\n                     c(\"R2\", \"VIF\", \"AllCor\", \"SelCor\"))\n  \n  return(final)\n}\n\n# create a dataset with just modeling variables\nOPA_modelvars <- OPA_points %>% select(sale_price, total_livable_area, building_age, number_of_bedrooms, number_of_bathrooms,\n                                       pop_totE, med_hh_incE, med_ageE,\n                                       dist_nearest_transit_ft, dist_nearest_hospital_ft, parks_cnt_0p25mi, log1p_crime_cnt_0p5, schools_cnt_0p5mi,\n                                       )\n\n# calculate VIFs and determine potentially troublesome correlations between variables\nvif_check <- sig_corr(OPA_modelvars %>% st_drop_geometry(), dep_var = \"sale_price\")\n\nkable(vif_check[[\"VIF\"]])\n\n```\n\nNone of the variables tested have a significant VIF score that is above 3, indicating that there is little concern of multicollinearity in the models moving forward.\n\n# Model Building\n\n## Model 1: Structural Terms\n\nOur first model uses structural property characteristics to build a multiple linear regression, regressing sale price on total livable area, number of bedrooms, number of bathrooms, and building age.\n\n```{r model-1}\n\nmodel1_data <- na.omit(OPA_points)\n\nmodel1 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age,\n\n  data = model1_data\n)\n\nsummary(model1)\n```\n\n## Model 2: Incorporation of Census Data\n\nOur second model builds on the structural property characteristics regression by incorporating census tract–level variables, including population, median household income, and median age.\n\n```{r model-2}\n\nmodel2_data <- na.omit(OPA_points)\n\nmodel2 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n\n    pop_totE +\n    med_hh_incE +\n    med_ageE,            \n    \n  data = model2_data\n)\n\nsummary(model2)\n```\n\n## Model 3: Incorporation of Spatial Features\n\n```{r model-3}\n\nmodel3_data <- na.omit(OPA_points)\n\nmodel3 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n\n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5,\n    \n  data = model3_data\n)\n\nsummary(model3)\n\n```\n\n## Model 4: Incorporation of Interactions and Fixed Effects\n\n```{r luxury-premium-hypothesis}\n\n# join data separately here to avoid conflicts with earlier code blocks\nOPA_points_copy <- left_join(OPA_points,\n                             neighbor_points %>%\n                               select(parcel_number, wealthy_neighborhood) %>%\n                               st_drop_geometry(),\n                             by = \"parcel_number\")\n\n```\n\n```{r model-4}\n\nmodel4_data <- na.omit(OPA_points_copy)\n\nmodel4 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n  \n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5 +\n    \n    number_of_bathrooms * wealthy_neighborhood +\n    \n    int_type_tarea +\n    int_value_larea +\n    int_value_tarea +\n    int_larea_econd +\n    int_larea_icond +\n    int_larea_beds,\n    \n                     \n  data = model4_data\n)\n\nsummary(model4)\n\n#there is only a premium on wealth neighborhood for total area, total livable area, and number of bathrooms that are significant. There is also a significant value for int_value_larea just from interacting the OPA data itsself which just assesses market value and size scalability. \n\n\n```\n\n## Comparison of Model Performance\n\nWe can evaluate performance by conducting a 10-fold cross-validation of the 4 models, and comparing their RMSE, MAE, and $R^2$.\n\n```{r k-fold-initiation}\n\n# Define 10-fold CV\ntrain_control <- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\"\n)\n\n```\n\n```{r model1-cv}\n\n# Model 1: Structural Features Only\nmodel1_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel1_cv\n\n```\n\n```{r model2-cv}\n# Model 2: Structural + Census\nmodel2_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    pop_totE +\n    med_hh_incE +\n    med_ageE,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel2_cv\n\n```\n\n```{r model3-cv}\n\n# Model 3: Structural + Census + Spatial\nmodel3_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n\n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel3_cv\n\n```\n\n```{r model4-cv}\n\n# Model 4: Structural + Census + Spatial + Interaction\nmodel4_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n  \n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5 +\n    \n    number_of_bathrooms * wealthy_neighborhood +\n    \n    int_type_tarea +\n    int_value_larea +\n    int_value_tarea +\n    int_larea_econd +\n    int_larea_icond +\n    int_larea_beds,\n  \n  data = na.omit(OPA_points_copy),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel4_cv\n\n```\n\n```{r all-model-comparison}\n\ncv_results <- data.frame(\n  Model = c(\"Model 1\", \n            \"Model 2\", \n            \"Model 3\", \n            \"Model 4\"),\n  RMSE = c(\n        model1_cv$results$RMSE,\n        model2_cv$results$RMSE,\n        model3_cv$results$RMSE,\n        model4_cv$results$RMSE\n      ),\n  \n  log_RMSE = c(\n        log(model1_cv$results$RMSE),\n        log(model2_cv$results$RMSE),\n        log(model3_cv$results$RMSE),\n        log(model4_cv$results$RMSE)\n      ),\n  \n    MAE = c(\n        model1_cv$results$MAE,\n        model2_cv$results$MAE,\n        model3_cv$results$MAE,\n        model4_cv$results$MAE\n      ),\n  R_squared = c(\n        model1_cv$results$Rsquared,\n        model2_cv$results$Rsquared,\n        model3_cv$results$Rsquared,\n        model4_cv$results$Rsquared\n      )\n)\n\nprint(cv_results)\n```\n\n```{r model-summary-table}\n\n# create model coefficient table in stargazer\nmodels_list <- list(model1, model2, model3, model4)\nmodels_summary_table <- stargazer(models_list, type = \"text\", style = \"default\")\n```\n\n```{r cv-scatterplots}\n\n# plot predicted vs actual value plots\nggplot(model1_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 1 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model2_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 2 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model3_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 3 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model4_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 4 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n```\n\n# Model Diagnostics\n\n```{r model-diagnostic-plots}\n\n# create diagnostic plots\nplot(model4)\n\n```\n\nIn the plot of residuals versus fitted values, the data largely displays a random distribution except for a spike in low sale price values. This indicates that the model might be poorly predicting for low sale price values as they don't follow an entirely linear pattern. However, there was no visible cone shape in the data, which was a promising sign that this discrepancy was not due to a trend consistent across the entire dataset. This discrepancy is suspected to follow a neighborhood based spatial pattern, and that exploration is done below. The Q-Q plot indicates that residual values are not perfectly normally distributed, further confirming that the dataset does not seem to display a linear relationship around extreme values. However, an analysis of the residuals in a Cook's Distance plot indicates that despite this lack of normality in the dependent variable, none of the observations are extraordinarily influential. These violations were therefore deemed mild enough to not warrant intervention.\n\n```{r residual-neighborhood-prep}\n\nOPA_points_clean <- na.omit(OPA_points_copy)\nOPA_points_clean$residuals <- residuals(model4)\n\npoints_with_nhoods <- st_join(OPA_points_clean, nhoods)\n\navg_residuals_by_nhood <- points_with_nhoods %>%\n  st_drop_geometry() %>%\n  group_by(NAME) %>%\n  summarise(\n    avg_residual = mean(residuals, na.rm = TRUE),\n    n_properties = n()\n  )\n\nnhoods_with_residuals <- nhoods %>%\n  left_join(avg_residuals_by_nhood, by = \"NAME\")\n```\n\n```{r residual-neighborhood-map}\nggplot(nhoods_with_residuals) +\n  geom_sf(aes(fill = avg_residual), color = \"white\", size = 0.15) +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"gray90\",\n    high = \"purple\",\n    midpoint = 0,\n    name = \"Avg Residual ($)\",\n    limits = c(-1, 1) * max(abs(nhoods_with_residuals$avg_residual), na.rm = TRUE)\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Model Performance by Neighborhood\",\n    subtitle = \"Purple = Over-prediction \\nRed = Under-prediction\"\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 15),\n    plot.subtitle = element_text(size = 10),\n    legend.position = \"right\",\n  )\n```\nThe results of this map confirm suspicions of local parameters affecting sale price, and should guide future work as explained in the following section.\n\n# Conclusion and Recommendations\n\nOur final model had an RMSE value of \\$195,093.2 and an MAE of \\$71,587.66. This was an improvement over previous models, where Model 1 had an RMSE value of \\$315,407.2 and an MAE of \\$146,134.04. Despite these improvements, these values are still extremely high relative to the current median household price in Philadelphia of approximately \\$232,000, according to Zillow. The strongest predicting features utilized in our model included whether the neighborhood a property had a median household income greater than \\$420,000 and could be considered wealthy ($\\beta$ = 47,309.230, p \\< 0.01), the number of bedrooms ($\\beta$ = 35,121.540, p \\< 0.01), and the number of bathrooms ($\\beta$ = 25,942.210, p \\< 0.01). Furthermore, our interaction term between wealthy neighborhood status and the number of bathrooms proved to also strongly influence the model output ($\\beta$ = 22,639.990, p \\< 0.01), indicating that properties in wealthier neighborhoods that have additional bathrooms tend to gain a stronger sale price premium compared to properties in non-wealthy neighborhoods.\n\nSale prices in Philadelphia do not seem to entirely follow a linear relationship, particularly among lower-priced homes. This resulted in limited prediction potential for properties with lower sale prices. This could produce potential equity issues related to pricing homes of lesser value and those in lower-income neighborhoods that are impacted by surrounding properties. Many of the variables used were simply aggregated without being weighted, such as how the count of crime incidents within a half-mile does not take into account the severity of such events or how the quality of parks within a quarter-mile of a property is not considered. This could over- or under-emphasize these variables in the model.\n","srcMarkdownNoYaml":"\n\nThis technical appendix documents the full workflow used to engineer and visualize spatial features for predicting residential housing prices in Philadelphia.\n\n```{r setup-and-files}\noptions(scipen = 999)\n\n# Packages\nif(!require(pacman)){install.packages(\"pacman\"); library(pacman, quietly = T)}\np_load(knitr, sf, tidyverse, tidycensus, tigris, here, dplyr, FNN, ggplot2, scales, patchwork, caret, Hmisc, stargazer)\n\n# Files\nsf_data <- st_read(\"./data/OPA_data.geojson\", quiet = TRUE)\nnhoods <- st_read(\"./data/philadelphia-neighborhoods.geojson\", quiet = TRUE)\n\n```\n\n# Property sales data\n\n## Data Preparation\n\nWe apply several filters to the property data to for quality and relevance. First, we restrict our analysis to residential properties sold between 2023 and 2024, excluding any other property categories. Second, we remove properties with sale prices below \\$10, as these are abnormal prices for residential properties.\n\nTo work with Github file size limits, the data is further trimmed of irrelevant columns.\n\n```{r opa-cleaning}\n#| output: false\n\n# Restrict to residential only\nresidential_categories <- c(\n  \"APARTMENTS > 4 UNITS\",\n  \"MULTI FAMILY\",\n  \"SINGLE FAMILY\",\n  \"MIXED USE\"\n)\nresidential_data <- sf_data %>%\n  filter(category_code_description %in% residential_categories,\n         year(sale_date) %in% c(2023, 2024),\n         mailing_city_state == \"PHILADELPHIA PA\",\n         sale_price > 10\n         )\n\ntable(residential_data$category_code_description)\n\n# Making sure the file saved to the repo is the trimmed data (to stay below GitHub data limits)\nst_write(residential_data, \"./data/OPA_data.geojson\", driver = \"GeoJSON\", delete_dsn = TRUE, quiet = TRUE)\nfile.exists(\"./data/OPA_data.geojson\")\nOPA_raw <- st_read(\"./data/OPA_data.geojson\", quiet = TRUE) %>% \n  st_transform(2272)\n\n# OPA_data -> cutting mostly NA columns or irrelevant columns for this model.\nOPA_raw <- OPA_raw %>%\n  select(-c(\n  cross_reference, date_exterior_condition, exempt_land, fireplaces, fuel, garage_type, house_extension, mailing_address_2, mailing_care_of, market_value_date, number_of_rooms, other_building, owner_2, separate_utilities, sewer, site_type, street_direction, suffix, unfinished, unit, utility\n  ))\n\nnames(OPA_raw)\n```\nThe property sales data was gathered from the OPA properties public data set from the City of Philadelphia. This data set was 32 columns and 583,825 observations. This file was too large for our shared GitHub work space so it was reduced by filtering for residential properties, years 2023 and 2024, location within Philadelphia, and sale price over 10 since some were NA, 1, or 10. This was just enough to get the most basic and general data to work with that ran with GitHub size limits. This reduced the size to 22121 observations. The original geojson file was overwritten and named OPA_data.\n\nProperties selected for residential included apartments >4 units, single family, multi-family, and mixed use. Mixed use was left in as there are still residential unit to account yet add more complex property types to our total data set when comparing sale price and other aspects such as total area to other observations. These properties should also be cross referenced with zoning codes for future research.\n\nWe left mixed use in during this process to give us the most general data set representation. There was also limited data cleaning other than omitting columns that were mostly NA. This gave our model the most general data set to work with despite lower future RMSE values. Future research would be needed to most accurately assess the choices of losing data and a more generalized Philadelphia housing market verses very clean data and more specific Philadelphia housing market that may omit certain aspects of the housing market like data in lower income areas or multi use residential aspects. This could have also been conducted in grouping NA values and sparse categories. More complexity could be accounted for in future work.\n\nThis was our start simple and add complexity approach. Our original to final OPA data set went from 583,825 to 22,121 observations and from 32 to 68 variables.\n\n## Exploratory Data Analysis\n\nBelow are selected property variables—Total Livable Area, Bedrooms, Bathrooms, and Age—in relation to Sale Price. Properties with excessive square footage (\\>10,000 sqft), missing bedroom or bathroom data, over 12 bathrooms with low sale prices, or implausible construction years were removed to reduce skew and data errors. This additional filtering was kept for the rest of the analysis in this report.\n\n```{r filtering-OPA-and-plots}\n\n# filter out outliers from the dataset\nOPA_data <- OPA_raw %>%\n  filter(\n    total_livable_area <= 10000,\n    year_built > 1800,\n    !is.na(number_of_bathrooms),\n    !is.na(number_of_bedrooms),\n    number_of_bathrooms < 12,\n  ) %>%\n  mutate(\n    year_built = as.numeric(year_built),\n    building_age = 2025 - year_built\n  )\n\np1 <- ggplot(OPA_data, aes(x = total_livable_area, y = sale_price)) +\n  geom_point(alpha = 0.3, size = 0.8) +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_x_continuous(labels = comma_format()) +\n  labs(\n    title = \"Sale Price vs. Total Livable Area\",\n    x = \"Total Livable Area (sq ft)\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np2 <- ggplot(OPA_data, aes(x = factor(number_of_bedrooms), y = sale_price)) +\n  geom_boxplot(fill = \"gray\", alpha = 0.6, outlier.alpha = 0.3, outlier.size = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 2, shape = 18) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Number of Bedrooms\",\n    x = \"Number of Bedrooms\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np3 <- ggplot(OPA_data, aes(x = factor(number_of_bathrooms), y = sale_price)) +\n  geom_boxplot(fill = \"gray\", alpha = 0.6, outlier.alpha = 0.3, outlier.size = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 2, shape = 18) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Number of Bathrooms\",\n    x = \"Number of Bathrooms\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\np4 <- ggplot(OPA_data, aes(x = building_age, y = sale_price)) +\n  geom_point(alpha = 0.3, size = 0.8) +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Sale Price vs. Age\",\n    x = \"Age\",\n    y = \"Sale Price\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"))\n\n# Combine plots\n(p1 | p2) / (p3 | p4)\n```\n\n## Feature Engineering\n\n```{r opa-interaction-features}\n\nOPA_data <- OPA_data %>%\n  mutate(\n    # convert to numeric before interactions\n    total_livable_area = as.numeric(total_livable_area),\n    census_tract = as.numeric(as.character(census_tract)),\n    year_built = as.numeric(year_built),\n    total_area = as.numeric(total_area),\n    market_value = as.numeric(market_value),\n    number_of_bedrooms = as.numeric(number_of_bedrooms),\n\n    # building code and total area\n    int_type_tarea = as.numeric(as.factor(building_code_description)) * total_area,\n\n    # market and livable area\n    int_value_larea = market_value * total_livable_area,\n\n    # market and total area\n    int_value_tarea = market_value * total_area,\n\n    # livable area and exterior condition\n    int_larea_econd = total_livable_area * as.numeric(as.factor(exterior_condition)),\n\n    # livable area and interior condition\n    int_larea_icond = total_livable_area * as.numeric(as.factor(interior_condition)),\n\n    # livable area and bedrooms\n    int_larea_beds = total_livable_area * number_of_bedrooms\n  )\n\n```\n\n```{r neighborhood-effects}\n#| output: false\n\npa_crs <- 2272  \nneighbor_points <- st_transform(OPA_data, pa_crs)\n\nnrow(nhoods)\n\nst_crs(neighbor_points)\nnhoods <- st_transform(nhoods, 2272)\n\n#joining houses to neighborhoods\nneighbor_points <- neighbor_points %>%\n  st_join(., nhoods, join = st_intersects)\n\n# one property doesn't lie in any neighborhood\nneighbor_points <- neighbor_points[!is.na(neighbor_points$NAME),]\n\n#results \nneighbor_points %>%\n  st_drop_geometry() %>%\n  count(NAME) %>%\n  arrange(desc(n))\n\n```\n\n```{r prices-by-neighborhood-and-map}\n\n#spatial joins\nprice_by_nhood <- neighbor_points %>%\n  st_drop_geometry() %>%\n  group_by(NAME) %>%\n  dplyr::summarize(\n    median_price = median(sale_price, na.rm = TRUE),\n    n_sales = n()\n  )\n\nnhoods_prices <- nhoods %>%\n  left_join(., price_by_nhood, by = \"NAME\")\n\n#setting median house price classes\nnhoods_prices <- nhoods_prices %>%\n  mutate(\n    price_class = cut(median_price,\n                      breaks = c(0, 400000, 600000, 800000, 1000000, Inf),\n                      labels = c(\"Under $400k\", \"$400k-$600k\", \"$600k-$800k\", \n                                 \"$800k-$1M\", \"Over $1M\"),\n                      include.lowest = TRUE)\n  )\n\n#mapping\nggplot() +\n  geom_sf(data = nhoods_prices, aes(fill = price_class), \n          color = \"white\", size = 0.5) +\n  scale_fill_brewer(\n    name = \"Median Price\",\n    palette = \"YlOrRd\",\n    na.value = \"grey90\",\n    direction = 1\n  ) +\n  labs(\n    title = \"Median Home Prices by Philadelphia Neighborhood\",\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.title = element_text(face = \"bold\")\n  )\n\n```\n\n```{r prices-and-sales}\n#| message: false\n#| output: false\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  head(10)\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  print(n = 50)\n\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  print(n = 50)\n\nprice_by_nhood %>%\n  arrange(desc(n_sales)) %>%\n  head(5)\n\n```\n\n```{r wealthy-neighborhood-effects}\n\n# Define wealthy as >=$420,000 which is 1.5x city median of 279,900\nnhoods_prices <- nhoods_prices %>%\n  mutate(\n    wealthy_neighborhood = ifelse(median_price >= 420000, \"Wealthy\", \"Not Wealthy\"),\n    wealthy_neighborhood = as.factor(wealthy_neighborhood)\n  )\n\nnhoods_prices %>%\n  st_drop_geometry() %>%\n  count(wealthy_neighborhood)\n\nneighbor_points <- neighbor_points %>%\n  left_join(.,\n            nhoods_prices %>%\n              st_drop_geometry %>%\n              select(NAME, wealthy_neighborhood),\n            by = \"NAME\")\n\n# Still add neighbor points to OPA data\n\n```\n\nHouseholds were denoted as wealthy if their median household price was over \\$420,000, which is 1.5x city median of 279,900. This term will be used in an interaction in Model 4 to account for theoretical differences in wealthy neighborhoods, such as inflated costs for additional home amenities such as bedrooms, bathrooms, or livable floor area.\n\n# Census Data\n\n## Data Preparation\n\n```{r census-var-ids}\n\n# link variables and aliases\nvars <- c(\"pop_tot\" = \"B01001_001\",\n          \"med_hh_inc\" = \"B19013_001\",\n          \"med_age\" = \"B01002_001\")\n\n# the FIPS code for the state of PA is 42\nfips_pa <- 42\n\n```\n\nVariables pulled from the census include total population, median household income, and median age.\n\n```{r census-var-acquisition}\n#| output: false\n\n# retrieve data from the ACS for 2023\ndemo_vars_pa <- get_acs(geography = \"tract\",\n                        variable = vars,\n                        year = 2023,\n                        state = fips_pa,\n                        output = \"wide\",\n                        geometry = T,\n                        progress_bar = F) %>% \n  st_transform(2272)\n\n# separate NAME column into its constituent parts\ndemo_vars_pa <- demo_vars_pa %>%\n  separate(NAME,\n           into = c(\"TRACT\", \"COUNTY\", \"STATE\"),\n           sep = \"; \",\n           remove = T) %>% \n  mutate(TRACT = parse_number(TRACT),\n         COUNTY = sub(x = COUNTY, \" County\", \"\"))\n\n# filter out Philadelphia tracts\ndemo_vars_phl <- demo_vars_pa %>%\n  filter(COUNTY == \"Philadelphia\")\n\n```\n\n```{r census-plot}\n\n# plot cenusus variables to compare\nplot(demo_vars_phl[,\"pop_totE\"],\n     main = \"Total Population\",\n     breaks = seq(0, 10500, 500),\n     nbreaks = 21)\nplot(demo_vars_phl[,\"med_hh_incE\"],\n     main = \"Median Household Income\",\n     breaks = seq(0, 200000, 10000),\n     nbreaks = 20)\nplot(demo_vars_phl[,\"med_ageE\"],\n     main = \"Median Age\",\n     breaks = seq(0, 75, 5),\n     nbreaks = 15)\n\n```\n\n```{r census-na-counts}\n\n# get NA counts per column\nna_counts <- sapply(demo_vars_phl, function(x) {sum(is.na(x))})\nkable(t(as.data.frame(na_counts)))\n\n# filter out all rows that have at least one column with an na value\nna_index <- !complete.cases(demo_vars_phl %>% st_drop_geometry())\ndemo_vars_phl_na <- demo_vars_phl[na_index,]\nkable(head(demo_vars_phl_na, 5) %>% select(-ends_with(\"M\")) %>% st_drop_geometry(),\n      col.names = c(\"GeoID\", \"Tract\", \"County\", \"State\", \"Population\", \"Median HH Inc ($)\", \"Median Age (yrs)\"),\n      row.names = F)\n\n```\n\n27 and 17 census tracts have a value of NA for median household income and median age, respectively. For the 17 census tracts where there is no reported population, the median household income and median age will be set to 0. The remaining 10 census tracts that have population but no reported median household income will be omitted from the dataset.\n\n```{r census-isolate-na}\n\n# create a dataset with NAs replaced with zero where applicable\ndemo_vars_phl_rep <- demo_vars_phl %>% \n  mutate(med_hh_incE = case_when(pop_totE == 0 & is.na(med_hh_incE) ~ 0,\n                                 .default = med_hh_incE),\n         med_ageE = case_when(pop_totE == 0 & is.na(med_ageE) ~ 0,\n                                 .default = med_ageE))\n\n# final cleaned dataset without the 10 census tracts that have population values but have NA values for Median Household Income\ndemo_vars_phl_clean <- demo_vars_phl_rep[complete.cases(demo_vars_phl_rep %>%\n                                                          select(-ends_with(\"M\")) %>%\n                                                          st_drop_geometry()),]\n\n# table with the omitted census tracts\ndemo_vars_phl_omit <- demo_vars_phl_rep[!complete.cases(demo_vars_phl_rep %>% select(-ends_with(\"M\")) %>% st_drop_geometry()),]\nkable(demo_vars_phl_omit %>% select(-ends_with(\"M\")) %>% st_drop_geometry(),\n      col.names = c(\"GeoID\", \"Tract\", \"County\", \"State\", \"Population\", \"Median HH Inc ($)\", \"Median Age (yrs)\"),\n      row.names = F, caption = \"Census Tracts Omitted from Analysis due to Data Unavailability\")\n```\n\n```{r census-join-to-OPA_data}\n\n# join census variables to the OPA data\nOPA_data <- st_join(OPA_data, demo_vars_phl_clean %>% select(pop_totE, med_hh_incE, med_ageE))\n\n# isolate NA rows and plot where they are\ncensusNAs <- OPA_data[is.na(OPA_data$med_hh_incE),]\n\ncensus_plt1 <- ggplot() +\n  geom_sf(data = demo_vars_phl_clean$geometry) +\n  geom_sf(data = censusNAs, size = 0.15) +\n  theme_void() +\n  labs(title = \"Properties without Census Data\")\ncensus_plt2 <- ggplot() +\n  geom_sf(data = demo_vars_phl_clean$geometry, fill = \"black\", color = \"transparent\") +\n  theme_void() +\n  labs(title = \"Census Tracts with Data (Black)\")\n\n(census_plt1 | census_plt2)\n```\n\nOf the 22121 properties in the dataset after cleaning and omitting outliers, 248 - approximately 1.1% of the dataset - have no associated census data due to the lack of a Median Household Income value for those census tracts. Comparing plots of property locations without census data and that of census tracts which have data confirms this spatial relationship.\n\n# Spatial Features\n\n## Data Preparation\n\nThis stage prepares and validates the OpenDataPhilly spatial datasets used to engineer neighborhood-level variables for the housing model.\n\n**Steps Performed**\n\n-   Transformed all spatial datasets to **EPSG 2272 (NAD83 / PA South ftUS)** for consistent distance measurements.\n\n-   Removed invalid geometries, dropped Z/M values, and converted all housing geometries to points.\n\n-   Imported and projected OpenDataPhilly amenities:\n\n    -   Transit Stops\n\n    -   Hospitals\n\n    -   Parks & Recreation Sites\n\n    -   Schools Parcels (centroids created from polygon features)\n\n    -   Crime Incidents (2023 and 2024 combined)\n\n```{r open-data-philly-datasets}\n#| message: false\n#| warning: false\n\n#CRS & radii\npa_crs <- 2272    # NAD83 / PA South (ftUS)\nmi_to_ft   <- 5280\nr_park_ft   <- 0.25 * mi_to_ft\nr_crime_ft  <- 0.50 * mi_to_ft\nr_school_ft <- 0.50 * mi_to_ft\n\n# turn off spherical geometry (makes buffer/join ops faster)\nsf::sf_use_s2(FALSE)\n\n## CONVERT SALES DATA TO POINTS ##\nOPA_points <- st_transform(OPA_data, pa_crs)\n\n#Drop Z/M if present\nst_geometry(OPA_points) <- st_zm(st_geometry(OPA_points), drop = TRUE, what = \"ZM\")\n\n#Make geometries valid\nst_geometry(OPA_points) <- st_make_valid(st_geometry(OPA_points))\n\n#Ensure POINT geometry (works for points/lines/polygons/collections)\nst_geometry(OPA_points) <- st_point_on_surface(st_geometry(OPA_points))\n\n#Add sale ID\nOPA_points <- OPA_points %>%\n  mutate(sale_id = dplyr::row_number())\n\n#read & project layers\ntransit   <- st_read(\"./data/Transit_Stops_(Spring_2025)/Transit_Stops_(Spring_2025).shp\", quiet = TRUE) |> st_transform(pa_crs)\nhospitals <- st_read(\"./data/Hospitals.geojson\", quiet = TRUE) |> st_transform(pa_crs)\nparksrec  <- st_read(\"./data/PPR_Program_Sites.geojson\", quiet = TRUE)|> st_transform(pa_crs)\nschools_polygons   <- st_read(\"./data/Schools_Parcels.geojson\", quiet = TRUE) |> st_transform(pa_crs)\ncrime_2023     <- st_read(\"./data/crime_incidents_2023/incidents_part1_part2.shp\", quiet = TRUE)        |> st_transform(pa_crs)\ncrime_2024     <- st_read(\"./data/crime_incidents_2024/incidents_part1_part2.shp\", quiet = TRUE)        |> st_transform(pa_crs)\n\n#combine 2023 & 2024 crime datasets\ncrime <- rbind(crime_2023, crime_2024)\n\n#create centroids for schools dataset\nschools <- if (any(st_geometry_type(schools_polygons) %in% c(\"POLYGON\",\"MULTIPOLYGON\"))) {\n  st_centroid(schools_polygons, )\n} else {\n  schools_polygons\n}\n\n#crop transit data to philadelphia\nphilly_boundary <- st_union(nhoods)\n\ntransit <- st_filter(transit, philly_boundary, .predicate = st_within)\n```\n\n## Exploratory Data Analysis\n\nExploratory plots and maps examine the raw accessibility patterns across Philadelphia before feature engineering.\n\n```{r exploratory-spatial-feature-plots}\n\n# Transit stops (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = transit, size = 0.3, alpha = 0.6) +\n  labs(title = \"Raw Layer Check: Transit Stops (SEPTA Spring 2025)\") +\n  theme_void()\n\n# Hospitals (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = hospitals, size = 0.6, alpha = 0.7) +\n  labs(title = \"Raw Layer Check: Hospitals\") +\n  theme_void()\n\n# Parks & Recreation Program Sites (raw)\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = parksrec, size = 0.4, alpha = 0.6) +\n  labs(title = \"Raw Layer Check: Parks & Recreation Sites\") +\n  theme_void()\n\n# Schools (centroids of polygons) — raw\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = schools, size = 0.4, alpha = 0.7) +\n  labs(title = \"Raw Layer Check: Schools (Centroids)\") +\n  theme_void()\n\n# Crime points are huge; sampling for speed\nset.seed(5080)\ncrime_quick <- if (nrow(crime) > 30000) dplyr::slice_sample(crime, n = 30000) else crime\n\nggplot() +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(data = crime_quick, size = 0.1, alpha = 0.25) +\n  labs(title = \"Raw Layer Check: Crime Incidents (sampled if large)\") +\n  theme_void()\n\n```\n\n### Interpretation\n\n-   **Transit Stops:** Dense corridors radiate from Center City, showing strong transit coverage.\n\n-   **Hospitals:** Sparse but geographically balanced.\n\n-   **Parks & Recreation:** uneven distribution,\n\n-   **Schools:** evenly distributed across most neighborhoods\n\n-   **Crime:** Visibly concentrated, confirming the need for log-transformed counts\n\n## Feature Engineering\n\nSpatial features were derived using two complementary approaches: **k-Nearest Neighbor (kNN)** and **buffer-based counts,** depending on whether accessibility was best captured as proximity or exposure.\n\n```{r knn-features}\n\n#| message: false\n#| warning: false\n\n#clean sales data\nsales_xy <- st_coordinates(OPA_points)\nok_sales  <- complete.cases(sales_xy)\nOPA_points <- OPA_points[ok_sales, ]    # keep only rows with valid XY\nsales_xy  <- st_coordinates(OPA_points) # refresh coordinates\n\ntransit_xy <- st_coordinates(transit)\nhosp_xy    <- st_coordinates(hospitals)\n\n# feature 1 - distance to nearest transit stop (ft)\nknn_tr <- FNN::get.knnx(\n  data  = st_coordinates(transit),\n  query = sales_xy,\n  k = 1)\n\nOPA_points <- OPA_points %>%\n  mutate(dist_nearest_transit_ft = as.numeric(knn_tr$nn.dist[,1]))\n\n# feature 2 - distance to nearest hospital (ft)\nknn_hp <- FNN::get.knnx(\n  data  = st_coordinates(hospitals),\n  query = sales_xy,\n  k = 1)\n\nOPA_points <- OPA_points %>%\n  mutate(dist_nearest_hospital_ft = as.numeric(knn_hp$nn.dist[,1]))\n```\n\n```{r buffer-features}\n#| message: false\n#| warning: false\n\n# feature 3 - parks/rec sites within 0.25 mi (count)\nrel_parks <- sf::st_is_within_distance(OPA_points, parksrec, dist = r_park_ft)\n\nOPA_points <- OPA_points %>%\n  mutate(parks_cnt_0p25mi = lengths(rel_parks))\n\n# feature 4 - crime count within 0.5 mi (per square mile)\ncrime_buffer <- st_buffer(OPA_points, dist = r_crime_ft)\n\nrel_crime <- st_intersects(crime_buffer, crime, sparse = TRUE)\n\n# count number of crimes\ncrime_cnt <- lengths(rel_crime)\n\nrm(rel_crime)\n\nOPA_points <- OPA_points |>\n  mutate(\n    crime_cnt_0p5mi     = crime_cnt,\n    log1p_crime_cnt_0p5 = log1p(crime_cnt_0p5mi)\n  )\n\n# feature 5 - schools within 0.5 mi (using centroids)\nrel_sch <- sf::st_is_within_distance(OPA_points, schools, dist = r_school_ft)\n\nOPA_points <- OPA_points %>%\n  mutate(schools_cnt_0p5mi = lengths(rel_sch))\n```\n\n### Summary Table and Justification\n\n| Feature                          | Method       | Parameter   | Theoretical Rationale                                                                                                           |\n|-------------|-------------|-------------|---------------------------------|\n| Distance to Nearest Transit Stop | kNN (k = 1)  | –           | Captures ease of access to public transport; nearest stop approximates walkability and job access.                              |\n| Distance to Nearest Hospital     | kNN (k = 1)  | –           | Reflects accessibility to health care and emergency services; proximity adds perceived security for households.                 |\n| Parks & Rec Sites within 0.25 mi | Buffer Count | r = 0.25 mi | Measures exposure to green space and recreational facilities within a 5-minute walk; positive amenity effect on property value. |\n| Crime Incidents within 0.5 mi    | Buffer Count | r = 0.5 mi  | Represents local safety environment; higher crime counts reduce housing desirability.                                           |\n| Schools within 0.5 mi            | Buffer Count | r = 0.5 mi  | Reflects educational access and family appeal; clustering of schools often raises residential demand.                           |\n| Population                       | Census       | –           | Represents the present residential demand within a census tract                                                                 |\n| Median Household Income          | Census       | –           | Indicative of the ability of present residents of a census tract to afford housing                                              |\n| Median Age                       | Census       | –           | Measure of the dominant age group in a census tract (i.e. high student or elderly population)                                   |\n\n### Feature Validation and Visualization\n\n```{r feature-validation-plots}\n\n## Transit Accessibility\nggplot(OPA_points, aes(x = dist_nearest_transit_ft)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Distance to Nearest Transit Stop\",\n       x = \"Feet to Nearest Stop\", y = \"Count\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = dist_nearest_transit_ft), size = 0.5) +\n  scale_color_viridis_c(option = \"plasma\", labels = comma) +\n  labs(title = \"Transit Accessibility Across Sales Parcels\",\n       color = \"Distance (ft)\") +\n  theme_void()\n\n## Hospital Proximity\nggplot(OPA_points, aes(x = dist_nearest_hospital_ft)) +\n  geom_histogram(fill = \"darkorange\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Distance to Nearest Hospital\",\n       x = \"Feet to Nearest Hospital\", y = \"Count\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = dist_nearest_hospital_ft), size = 0.5) +\n  scale_color_viridis_c(option = \"magma\", labels = comma) +\n  labs(title = \"Hospital Accessibility Across Sales Parcels\",\n       color = \"Distance (ft)\") +\n  theme_void()\n\n## Parks & Recreation\nggplot(OPA_points, aes(x = parks_cnt_0p25mi)) +\n  geom_histogram(fill = \"seagreen\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution: Parks & Rec Sites Within 0.25 mi\",\n       x = \"Count within 0.25 mi\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = parks_cnt_0p25mi), size = 0.6) +\n  scale_color_viridis_c(option = \"viridis\") +\n  labs(title = \"Proximity to Parks & Recreation (0.25 mi Buffer)\",\n       color = \"Parks Count\") +\n  theme_void()\n\n## Crime Counts\nggplot(OPA_points, aes(x = crime_cnt_0p5mi)) +\n  geom_histogram(fill = \"firebrick\", color = \"white\", bins = 30) +\n  labs(title = \"Distribution: Crime Incidents Within 0.5 mi\",\n       x = \"Crime Count (2023–2024)\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = log1p_crime_cnt_0p5), size = 0.6) +\n  scale_color_viridis_c(option = \"inferno\") +\n  labs(title = \"Crime Exposure (log-transformed within 0.5 mi)\",\n       color = \"log(1+Crime Count)\") +\n  theme_void()\n\n## Schools Accessibility\nggplot(OPA_points, aes(x = schools_cnt_0p5mi)) +\n  geom_histogram(fill = \"purple\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution: Schools Within 0.5 mi\",\n       x = \"School Count (0.5 mi Buffer)\", y = \"Number of Parcels\") +\n  theme_minimal()\n\nggplot(OPA_points) +\n  geom_sf(data = nhoods, \n          fill = NA, color = \"grey70\", linewidth = 0.3) +\n  geom_sf(aes(color = schools_cnt_0p5mi), size = 0.6) +\n  scale_color_viridis_c(option = \"cividis\") +\n  labs(title = \"School Accessibility (0.5 mi Buffer)\",\n       color = \"Schools Count\") +\n  theme_void()\n```\n\n**Interpretation:**\n\n-   **Transit proximity**: Most parcels are within 500 ft of a stop, confirming strong transit coverage across Philadelphia.\n\n-   **Hospital proximity**: Right-skewed distribution, consistent with limited facility count.\n\n-   **Parks access**: Sparse exposure (mostly 0–1 within 0.25 mi), highlighting recreational inequities.\n\n-   **Crime exposure**: Wide variation, clustered along high-density corridors; log-transformed to stabilize scale.\n\n-   **School proximity**: Uniform urban coverage with typical parcels having 4-7 schools within 0.5 mi.\n\n\n```{r sales-data-histogram}\nsp_data <- st_read(\"./data/OPA_data.geojson\", quiet = T)\n\nstr(sp_data$sale_price)\n\nsp_data_filtered <- sp_data %>%\n  mutate(sale_price = as.numeric(sale_price)) %>%\n  filter(sale_price > 1000)\n\nggplot(sp_data_filtered, aes(x = sale_price)) + \n  geom_histogram(\n    binwidth = 20000, \n    fill = \"grey\",\n    color = \"black\"\n  ) +\n  labs(\n    title = \"Histogram of Sale Prices in Philadelphia\", \n    x = \"Sale Price\",\n    y = \"Count of Homes\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = label_dollar()) +\n  coord_cartesian(xlim = c(0, 2000000), ylim = c(0, 3000))\n\nsummary(sp_data_filtered$sale_price)\n\nsp_data_filtered <- sp_data_filtered %>%\n  mutate(\n    sale_price = as.numeric(sale_price),\n    sale_price_capped = pmin(sale_price, quantile(sale_price, 0.99, na.rm = TRUE))\n  )\n\nggplot(sp_data_filtered) +\n  geom_sf(aes(color = sale_price_capped), size = 0.6, alpha = 0.7) +\n  scale_color_viridis_c(labels = label_dollar(), name = \"Sale Price (USD)\") +\n  labs(title = \"Philadelphia Sale Prices\") +\n  theme_minimal()\n```\n\n```{r VIF-analysis}\n\n# function to check for statistically significant correlations between independent variables\nsig_corr <- function(dat, dep_var) {\n  # remove the independent variable from the dataset\n  dat_corr <- dat %>% select(-all_of(dep_var))\n  \n  # run a correlation matrix for the independent vars\n  correlation_matrix <- rcorr(as.matrix(dat_corr))\n  values <- correlation_matrix$r\n  vifs <- apply(values, 1, function(x){\n    return(round(1/(1-abs(x)), 2))\n  })\n  \n  values_df <- values %>% as.data.frame()\n  vifs_df <- vifs %>% as.data.frame()\n  \n  # convert correlation coefficients and p-values to long format\n  corCoeff_df <- correlation_matrix$r %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  corVIF_df <- vifs %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  corPval_df <- correlation_matrix$P %>% \n    as.data.frame() %>% \n    mutate(var1 = rownames(.))\n  \n  # merge long format data\n  corMerge <- list(\n    corCoeff_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"correlation\") %>% as.data.frame(),\n    corVIF_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"vif_factor\") %>% as.data.frame(),\n    corPval_df %>% pivot_longer(-var1, names_to = \"var2\", values_to = \"p_value\") %>% as.data.frame()) %>%\n    reduce(left_join, by = c(\"var1\", \"var2\"))\n  \n  # filter to isolate unique pairs, then rows with correlation > 0.5 and p < 0.05\n  corUnfiltered <- corMerge %>% \n    filter(var1 != var2) %>% \n    rowwise() %>% \n    filter(var1 < var2) %>% \n    ungroup() %>% \n    as.data.frame()\n  \n  corFiltered <- corUnfiltered %>% \n    filter(abs(vif_factor) > 3 & p_value < 0.05) %>% \n    arrange(desc(abs(correlation)))\n  \n  # save the raw correlation values and the filtered variable pairs\n  final <- set_names(list(values_df, vifs_df, corUnfiltered, corFiltered),\n                     c(\"R2\", \"VIF\", \"AllCor\", \"SelCor\"))\n  \n  return(final)\n}\n\n# create a dataset with just modeling variables\nOPA_modelvars <- OPA_points %>% select(sale_price, total_livable_area, building_age, number_of_bedrooms, number_of_bathrooms,\n                                       pop_totE, med_hh_incE, med_ageE,\n                                       dist_nearest_transit_ft, dist_nearest_hospital_ft, parks_cnt_0p25mi, log1p_crime_cnt_0p5, schools_cnt_0p5mi,\n                                       )\n\n# calculate VIFs and determine potentially troublesome correlations between variables\nvif_check <- sig_corr(OPA_modelvars %>% st_drop_geometry(), dep_var = \"sale_price\")\n\nkable(vif_check[[\"VIF\"]])\n\n```\n\nNone of the variables tested have a significant VIF score that is above 3, indicating that there is little concern of multicollinearity in the models moving forward.\n\n# Model Building\n\n## Model 1: Structural Terms\n\nOur first model uses structural property characteristics to build a multiple linear regression, regressing sale price on total livable area, number of bedrooms, number of bathrooms, and building age.\n\n```{r model-1}\n\nmodel1_data <- na.omit(OPA_points)\n\nmodel1 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age,\n\n  data = model1_data\n)\n\nsummary(model1)\n```\n\n## Model 2: Incorporation of Census Data\n\nOur second model builds on the structural property characteristics regression by incorporating census tract–level variables, including population, median household income, and median age.\n\n```{r model-2}\n\nmodel2_data <- na.omit(OPA_points)\n\nmodel2 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n\n    pop_totE +\n    med_hh_incE +\n    med_ageE,            \n    \n  data = model2_data\n)\n\nsummary(model2)\n```\n\n## Model 3: Incorporation of Spatial Features\n\n```{r model-3}\n\nmodel3_data <- na.omit(OPA_points)\n\nmodel3 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n\n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5,\n    \n  data = model3_data\n)\n\nsummary(model3)\n\n```\n\n## Model 4: Incorporation of Interactions and Fixed Effects\n\n```{r luxury-premium-hypothesis}\n\n# join data separately here to avoid conflicts with earlier code blocks\nOPA_points_copy <- left_join(OPA_points,\n                             neighbor_points %>%\n                               select(parcel_number, wealthy_neighborhood) %>%\n                               st_drop_geometry(),\n                             by = \"parcel_number\")\n\n```\n\n```{r model-4}\n\nmodel4_data <- na.omit(OPA_points_copy)\n\nmodel4 <- lm(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n  \n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5 +\n    \n    number_of_bathrooms * wealthy_neighborhood +\n    \n    int_type_tarea +\n    int_value_larea +\n    int_value_tarea +\n    int_larea_econd +\n    int_larea_icond +\n    int_larea_beds,\n    \n                     \n  data = model4_data\n)\n\nsummary(model4)\n\n#there is only a premium on wealth neighborhood for total area, total livable area, and number of bathrooms that are significant. There is also a significant value for int_value_larea just from interacting the OPA data itsself which just assesses market value and size scalability. \n\n\n```\n\n## Comparison of Model Performance\n\nWe can evaluate performance by conducting a 10-fold cross-validation of the 4 models, and comparing their RMSE, MAE, and $R^2$.\n\n```{r k-fold-initiation}\n\n# Define 10-fold CV\ntrain_control <- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\"\n)\n\n```\n\n```{r model1-cv}\n\n# Model 1: Structural Features Only\nmodel1_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel1_cv\n\n```\n\n```{r model2-cv}\n# Model 2: Structural + Census\nmodel2_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    pop_totE +\n    med_hh_incE +\n    med_ageE,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel2_cv\n\n```\n\n```{r model3-cv}\n\n# Model 3: Structural + Census + Spatial\nmodel3_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n\n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5,\n  data = na.omit(OPA_points),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel3_cv\n\n```\n\n```{r model4-cv}\n\n# Model 4: Structural + Census + Spatial + Interaction\nmodel4_cv <- train(\n  sale_price ~ \n    total_livable_area +\n    number_of_bedrooms +\n    number_of_bathrooms +\n    building_age +\n    total_area +\n    \n    pop_totE +\n    med_hh_incE +\n    med_ageE +  \n  \n    dist_nearest_transit_ft +\n    dist_nearest_hospital_ft +\n    parks_cnt_0p25mi +\n    log1p_crime_cnt_0p5 +\n    \n    number_of_bathrooms * wealthy_neighborhood +\n    \n    int_type_tarea +\n    int_value_larea +\n    int_value_tarea +\n    int_larea_econd +\n    int_larea_icond +\n    int_larea_beds,\n  \n  data = na.omit(OPA_points_copy),\n  method = \"lm\",\n  trControl = train_control\n)\n\nmodel4_cv\n\n```\n\n```{r all-model-comparison}\n\ncv_results <- data.frame(\n  Model = c(\"Model 1\", \n            \"Model 2\", \n            \"Model 3\", \n            \"Model 4\"),\n  RMSE = c(\n        model1_cv$results$RMSE,\n        model2_cv$results$RMSE,\n        model3_cv$results$RMSE,\n        model4_cv$results$RMSE\n      ),\n  \n  log_RMSE = c(\n        log(model1_cv$results$RMSE),\n        log(model2_cv$results$RMSE),\n        log(model3_cv$results$RMSE),\n        log(model4_cv$results$RMSE)\n      ),\n  \n    MAE = c(\n        model1_cv$results$MAE,\n        model2_cv$results$MAE,\n        model3_cv$results$MAE,\n        model4_cv$results$MAE\n      ),\n  R_squared = c(\n        model1_cv$results$Rsquared,\n        model2_cv$results$Rsquared,\n        model3_cv$results$Rsquared,\n        model4_cv$results$Rsquared\n      )\n)\n\nprint(cv_results)\n```\n\n```{r model-summary-table}\n\n# create model coefficient table in stargazer\nmodels_list <- list(model1, model2, model3, model4)\nmodels_summary_table <- stargazer(models_list, type = \"text\", style = \"default\")\n```\n\n```{r cv-scatterplots}\n\n# plot predicted vs actual value plots\nggplot(model1_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 1 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model2_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 2 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model3_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 3 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n\nggplot(model4_cv$pred, aes(x = obs, y = pred)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Model 4 Cross-Validation: Predicted vs. Actual Sale Price\",\n    x = \"Actual Sale Price\",\n    y = \"Predicted Sale Price\"\n  ) +\n  theme_minimal()\n```\n\n# Model Diagnostics\n\n```{r model-diagnostic-plots}\n\n# create diagnostic plots\nplot(model4)\n\n```\n\nIn the plot of residuals versus fitted values, the data largely displays a random distribution except for a spike in low sale price values. This indicates that the model might be poorly predicting for low sale price values as they don't follow an entirely linear pattern. However, there was no visible cone shape in the data, which was a promising sign that this discrepancy was not due to a trend consistent across the entire dataset. This discrepancy is suspected to follow a neighborhood based spatial pattern, and that exploration is done below. The Q-Q plot indicates that residual values are not perfectly normally distributed, further confirming that the dataset does not seem to display a linear relationship around extreme values. However, an analysis of the residuals in a Cook's Distance plot indicates that despite this lack of normality in the dependent variable, none of the observations are extraordinarily influential. These violations were therefore deemed mild enough to not warrant intervention.\n\n```{r residual-neighborhood-prep}\n\nOPA_points_clean <- na.omit(OPA_points_copy)\nOPA_points_clean$residuals <- residuals(model4)\n\npoints_with_nhoods <- st_join(OPA_points_clean, nhoods)\n\navg_residuals_by_nhood <- points_with_nhoods %>%\n  st_drop_geometry() %>%\n  group_by(NAME) %>%\n  summarise(\n    avg_residual = mean(residuals, na.rm = TRUE),\n    n_properties = n()\n  )\n\nnhoods_with_residuals <- nhoods %>%\n  left_join(avg_residuals_by_nhood, by = \"NAME\")\n```\n\n```{r residual-neighborhood-map}\nggplot(nhoods_with_residuals) +\n  geom_sf(aes(fill = avg_residual), color = \"white\", size = 0.15) +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"gray90\",\n    high = \"purple\",\n    midpoint = 0,\n    name = \"Avg Residual ($)\",\n    limits = c(-1, 1) * max(abs(nhoods_with_residuals$avg_residual), na.rm = TRUE)\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Model Performance by Neighborhood\",\n    subtitle = \"Purple = Over-prediction \\nRed = Under-prediction\"\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 15),\n    plot.subtitle = element_text(size = 10),\n    legend.position = \"right\",\n  )\n```\nThe results of this map confirm suspicions of local parameters affecting sale price, and should guide future work as explained in the following section.\n\n# Conclusion and Recommendations\n\nOur final model had an RMSE value of \\$195,093.2 and an MAE of \\$71,587.66. This was an improvement over previous models, where Model 1 had an RMSE value of \\$315,407.2 and an MAE of \\$146,134.04. Despite these improvements, these values are still extremely high relative to the current median household price in Philadelphia of approximately \\$232,000, according to Zillow. The strongest predicting features utilized in our model included whether the neighborhood a property had a median household income greater than \\$420,000 and could be considered wealthy ($\\beta$ = 47,309.230, p \\< 0.01), the number of bedrooms ($\\beta$ = 35,121.540, p \\< 0.01), and the number of bathrooms ($\\beta$ = 25,942.210, p \\< 0.01). Furthermore, our interaction term between wealthy neighborhood status and the number of bathrooms proved to also strongly influence the model output ($\\beta$ = 22,639.990, p \\< 0.01), indicating that properties in wealthier neighborhoods that have additional bathrooms tend to gain a stronger sale price premium compared to properties in non-wealthy neighborhoods.\n\nSale prices in Philadelphia do not seem to entirely follow a linear relationship, particularly among lower-priced homes. This resulted in limited prediction potential for properties with lower sale prices. This could produce potential equity issues related to pricing homes of lesser value and those in lower-income neighborhoods that are impacted by surrounding properties. Many of the variables used were simply aggregated without being weighted, such as how the count of crime incidents within a half-mile does not take into account the severity of such events or how the quality of parks within a quarter-mile of a property is not considered. This could over- or under-emphasize these variables in the model.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"model_script.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Philadelphia Housing Price Prediction - Technical Appendix","author":"Nina Carlsen, Ryan Drake, Sujanesh Kakumanu, Kavana Raju, Chloe Robinson, Henry Sywulak-Herr.","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}