{"title":"Assignment 5: Space-Time Prediction of Bike Share Demand","markdown":{"yaml":{"title":"Assignment 5: Space-Time Prediction of Bike Share Demand","subtitle":"Philadelphia Indego Q3 2024 Analysis","author":"Kavana Raju","date":"today","format":{"html":{"code-fold":"show","code-tools":true,"toc":true,"toc-depth":3,"toc-location":"left","theme":"cosmo","embed-resources":true}},"editor":"visual","execute":{"warning":false,"message":false}},"headingText":"Setup","containsRefs":false,"markdown":"\n\nPhiladelphia's Indego bike share system faces a critical operational challenge: rebalancing bikes to meet anticipated demand. Operations managers must decide at 6:00 AM which of 200+ stations will run out of bikes by the morning rush, with limited trucks and staff to move bikes efficiently.\n\nThis assignment applies space-time predictive modeling to forecast hourly bike share demand at station-level granularity. Following the methodology established with Q1 2025 winter data in class, I analyze Q3 2024 (July-September) to understand how summer peak season affects prediction accuracy compared to winter baseline patterns.\n\nI chose Q3 2024 for several reasons. First, summer represents the opposite seasonal extreme from Q1 2025 winter: highest annual ridership, minimal weather disruptions (no snow or ice events), significant tourist activity, and unique special events like July 4th and Labor Day weekend. Second, the 38% ridership increase from winter provides a test of whether models perform better with higher, more stable demand or whether increased volume creates more prediction challenges.\n\nThe core methodology aggregates individual trips into a space-time panel where each observation represents demand at a specific station during a specific hour. I build five baseline models with progressively more complex features, engineer new summer-specific features, and test whether Poisson regression designed for count data outperforms ordinary least squares linear regression.\n\nModel evaluation uses temporal validation, splitting each quarter into training and test periods to assess generalizability. I analyze prediction errors across spatial, temporal, and demographic dimensions to identify where the model struggles and assess equity implications. The analysis concludes with direct comparison of Q1 2025 winter and Q3 2024 summer performance and honest assessment of operational deployment readiness.\n\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Additional packages\nlibrary(zoo)  # For rolling averages\n\n# Set options\noptions(scipen = 999)\noptions(tigris_use_cache = TRUE)\n```\n\n```{r themes}\n# Define consistent plot themes\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", linewidth = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n```{r census_key}\n#| include: false\n\n# Insert your census API key here\ncensus_api_key(\"52f0462d8b4e1e19ee64b25a3196677c5e32e660\", overwrite = TRUE)\n```\n\n# Part 1: Load and Compare Both Quarters\n\nThis section loads BOTH Q1 2025 (winter baseline) and Q3 2024 (summer) data to enable direct comparison throughout the analysis. Understanding seasonal differences requires seeing both datasets side-by-side.\n\n## 1.1 Load Q1 2025 Winter Baseline Data\n\n```{r load_q1}\n#| message: false\n\n# Load Q1 2025 winter data (January-March)\n# This is the baseline analyzed in class\nindego_q1 <- read_csv(\"data/indego-trips-2025-q1.csv\")\n\ncat(\"✓ Loaded Q1 2025 (January-March) WINTER data\\n\")\ncat(\"Total trips:\", format(nrow(indego_q1), big.mark = \",\"), \"\\n\")\ncat(\"Date range:\", \n    min(mdy_hm(indego_q1$start_time)), \"to\", \n    max(mdy_hm(indego_q1$start_time)), \"\\n\")\ncat(\"Unique start stations:\", length(unique(indego_q1$start_station)), \"\\n\")\n```\n\n## 1.2 Load Q3 2024 Summer Data\n\n```{r load_q3}\n#| message: false\n\n# Load Q3 2024 summer data (July-September)\n# Downloaded from: https://www.rideindego.com/about/data/\nindego_q3 <- read_csv(\"data/indego-trips-2024-q3.csv\")\n\ncat(\"✓ Loaded Q3 2024 (July-September) SUMMER data\\n\")\ncat(\"Total trips:\", format(nrow(indego_q3), big.mark = \",\"), \"\\n\")\ncat(\"Date range:\", \n    min(mdy_hm(indego_q3$start_time)), \"to\", \n    max(mdy_hm(indego_q3$start_time)), \"\\n\")\ncat(\"Unique start stations:\", length(unique(indego_q3$start_station)), \"\\n\")\n```\n\n## 1.3 Initial Comparison: Daily Ridership\n\n```{r compare_daily_ridership}\n#| fig-width: 12\n#| fig-height: 6\n\n# Process Q1 data\ndaily_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    date = as.Date(start_datetime)\n  ) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  mutate(quarter = \"Q1 2025 (Winter)\")\n\n# Process Q3 data\ndaily_q3 <- indego_q3 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    date = as.Date(start_datetime)\n  ) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  mutate(quarter = \"Q3 2024 (Summer)\")\n\n# Combine for comparison\ndaily_combined <- bind_rows(daily_q1, daily_q3)\n\n# Calculate summary stats\nsummary_stats <- daily_combined %>%\n  group_by(quarter) %>%\n  summarize(\n    avg_daily = round(mean(trips)),\n    min_daily = min(trips),\n    max_daily = max(trips),\n    .groups = \"drop\"\n  )\n\nkable(summary_stats,\n      caption = \"Daily Ridership Comparison: Winter vs Summer\",\n      col.names = c(\"Quarter\", \"Avg Daily Trips\", \"Min\", \"Max\"),\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Calculate percentage difference\nq1_avg <- summary_stats %>% filter(quarter == \"Q1 2025 (Winter)\") %>% pull(avg_daily)\nq3_avg <- summary_stats %>% filter(quarter == \"Q3 2024 (Summer)\") %>% pull(avg_daily)\npct_diff <- round((q3_avg - q1_avg) / q1_avg * 100, 1)\n\ncat(\"\\nQ3 Summer has\", pct_diff, \"% higher daily ridership than Q1 Winter\\n\")\n```\n\n```{r viz_daily_comparison}\n#| fig-width: 14\n#| fig-height: 6\n\nggplot(daily_combined, aes(x = date, y = trips, color = quarter)) +\n  geom_line(linewidth = 0.8, alpha = 0.7) +\n  geom_smooth(se = FALSE, linewidth = 1.2) +\n  scale_color_manual(values = c(\"Q1 2025 (Winter)\" = \"#6baed6\", \n                                 \"Q3 2024 (Summer)\" = \"#08519c\")) +\n  labs(\n    title = \"Daily Ridership: Q1 2025 Winter vs Q3 2024 Summer\",\n    subtitle = paste0(\"Summer averages \", pct_diff, \"% higher ridership with more stable patterns\"),\n    x = \"Date\",\n    y = \"Daily Trips\",\n    color = \"Quarter\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Key Observation**: Summer shows higher, more consistent ridership. Winter has notable volatility (snow events, warm spikes). This sets up our hypothesis: **higher volume but more stability may improve prediction accuracy**.\n\n## 1.4 Process Q3 2024 Data (Main Analysis)\n\nFor the remainder of this analysis, I focus on building and evaluating models for Q3 2024, then compare final results to Q1 2025 baseline performance.\n\n```{r create_time_bins_q3}\nindego_q3 <- indego_q3 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## 1.5 Q3 2024 Exploratory Analysis\n\n### Special Events in Summer\n\n```{r special_events_q3}\ndaily_q3_simple <- indego_q3 %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\")\n\n# July 4th\njuly4_trips <- daily_q3_simple %>% \n  filter(date == as.Date(\"2024-07-04\")) %>% \n  pull(trips)\n\n# Labor Day weekend\nlabor_day_trips <- daily_q3_simple %>%\n  filter(date >= as.Date(\"2024-08-31\") & date <= as.Date(\"2024-09-02\")) %>%\n  summarize(avg = mean(trips)) %>% \n  pull(avg)\n\n# Typical weekday\ntypical_weekday <- indego_q3 %>%\n  filter(dotw %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n         !(date %in% c(as.Date(\"2024-07-04\"), as.Date(\"2024-09-02\")))) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  summarize(avg = mean(trips)) %>% \n  pull(avg)\n\nevent_comparison <- data.frame(\n  Event = c(\"July 4th\", \"Labor Day Weekend\", \"Typical Weekday\"),\n  Trips = c(july4_trips, round(labor_day_trips), round(typical_weekday)),\n  Difference = c(\n    paste0(round((july4_trips - typical_weekday)/typical_weekday*100, 1), \"%\"),\n    paste0(round((labor_day_trips - typical_weekday)/typical_weekday*100, 1), \"%\"),\n    \"baseline\"\n  )\n)\n\nkable(event_comparison,\n      caption = \"Q3 2024 Special Event Impact\",\n      col.names = c(\"Day Type\", \"Trips\", \"% vs Typical\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Finding**: Summer holidays show LOWER ridership (\\~15% below typical) because they eliminate commute trips. This contrasts with Q1 2025's Eagles Super Bowl parade which created a major spike.\n\n### Hourly Patterns Comparison\n\n```{r hourly_patterns_comparison}\n#| fig-width: 12\n#| fig-height: 6\n\n# Q1 hourly patterns\nhourly_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    hour = hour(start_datetime),\n    dotw = wday(start_datetime, label = TRUE),\n    date = as.Date(start_datetime),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0)\n  ) %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date), .groups = \"drop\") %>%\n  mutate(\n    quarter = \"Q1 2025 (Winter)\",\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\n# Q3 hourly patterns\nhourly_q3 <- indego_q3 %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date), .groups = \"drop\") %>%\n  mutate(\n    quarter = \"Q3 2024 (Summer)\",\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\n# Combine\nhourly_combined <- bind_rows(hourly_q1, hourly_q3)\n\nggplot(hourly_combined, aes(x = hour, y = avg_trips, color = quarter, linetype = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Q1 2025 (Winter)\" = \"#6baed6\", \n                                 \"Q3 2024 (Summer)\" = \"#08519c\")) +\n  scale_linetype_manual(values = c(\"Weekday\" = \"solid\", \"Weekend\" = \"dashed\")) +\n  labs(\n    title = \"Hourly Demand Patterns: Winter vs Summer\",\n    subtitle = \"Both quarters show clear commute peaks on weekdays; summer has higher baseline\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Quarter\",\n    linetype = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Finding**: Both quarters show similar temporal patterns (AM/PM peaks on weekdays), but summer maintains higher baseline throughout the day.\n\n## 1.6 Get Philadelphia Spatial Context\n\n```{r load_census}\n#| message: false\n\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)\n\ncat(\"Loaded\", nrow(philly_census), \"census tracts\\n\")\n```\n\n```{r join_census_q3}\n#| message: false\n\n# Create spatial points for Q3 stations\nstations_sf_q3 <- indego_q3 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to census tracts\nstations_census_q3 <- st_join(stations_sf_q3, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Filter to residential stations\nvalid_stations_q3 <- stations_census_q3 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data\nindego_census_q3 <- indego_q3 %>%\n  filter(start_station %in% valid_stations_q3) %>%\n  left_join(\n    stations_census_q3 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\ncat(\"Filtered to\", length(valid_stations_q3), \"residential stations\\n\")\ncat(\"Retained\", format(nrow(indego_census_q3), big.mark = \",\"), \"trips\\n\")\n```\n\n## 1.7 Get Weather Data for Q3 2024\n\n```{r get_weather_q3}\n#| message: false\n\n# Download Q3 2024 weather from Philadelphia Airport\nweather_data_q3 <- riem_measures(\n  station = \"PHL\",\n  date_start = \"2024-07-01\",\n  date_end = \"2024-09-30\"\n)\n\n# Process weather data\nweather_complete_q3 <- weather_data_q3 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct() %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\ncat(\"✓ Q3 Weather data complete\\n\")\nsummary(weather_complete_q3 %>% select(Temperature, Precipitation))\n```\n\n## 1.8 Create Space-Time Panel for Q3 2024\n\n```{r aggregate_trips_q3}\n# Count trips by station-hour\n# Group by demographics so they carry forward\ntrips_panel_q3 <- indego_census_q3 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n(), .groups = \"drop\")\n\ncat(\"Initial panel observations:\", format(nrow(trips_panel_q3), big.mark = \",\"), \"\\n\")\n```\n\n```{r complete_panel_q3}\n# CRITICAL: Extract station attributes FIRST to avoid duplicates\nstation_attributes_q3 <- trips_panel_q3 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop),\n    .groups = \"drop\"\n  )\n\n# Create complete panel (all station-hour combinations)\nstudy_panel_q3 <- expand.grid(\n  interval60 = unique(trips_panel_q3$interval60),\n  start_station = unique(trips_panel_q3$start_station),\n  stringsAsFactors = FALSE\n) %>%\n  # Join trip counts ONLY (not demographics to avoid duplicates)\n  left_join(\n    trips_panel_q3 %>% select(interval60, start_station, Trip_Count), \n    by = c(\"interval60\", \"start_station\")\n  ) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0)) %>%\n  # NOW join station attributes\n  left_join(station_attributes_q3, by = \"start_station\")\n\ncat(\"Complete panel rows:\", format(nrow(study_panel_q3), big.mark = \",\"), \"\\n\")\ncat(\"Zero observations:\", sum(study_panel_q3$Trip_Count == 0),\n    \"(\", round(sum(study_panel_q3$Trip_Count == 0)/nrow(study_panel_q3)*100, 1), \"%)\\n\")\n```\n\n```{r add_features_q3}\nstudy_panel_q3 <- study_panel_q3 %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  ) %>%\n  left_join(weather_complete_q3, by = \"interval60\")\n```\n\n## 1.9 Create Temporal Lag Variables\n\n```{r create_lags_q3}\n# Sort by station and time\nstudy_panel_q3 <- study_panel_q3 %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel_q3 <- study_panel_q3 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags\nstudy_panel_complete_q3 <- study_panel_q3 %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete_q3), big.mark = \",\"), \"\\n\")\n```\n\n## 1.10 Temporal Train/Test Split\n\n```{r temporal_split_q3}\n# Q3 2024 has weeks 27-39 (July-September)\n# Train on weeks 27-35 (July 1 - early September)\n# Test on weeks 36-39 (rest of September)\n\n# Which stations have trips in BOTH periods?\nearly_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only common stations\ncommon_stations_q3 <- intersect(early_stations_q3, late_stations_q3)\n\ncat(\"Common stations (appear in both train/test):\", length(common_stations_q3), \"\\n\")\n\n# Filter to common stations and split\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  filter(start_station %in% common_stations_q3)\n\ntrain_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36)\n\ntest_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36)\n\ncat(\"\\nQ3 Training observations:\", format(nrow(train_q3), big.mark = \",\"), \"\\n\")\ncat(\"Q3 Testing observations:\", format(nrow(test_q3), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train_q3$date), \"to\", max(train_q3$date), \"\\n\")\ncat(\"Testing date range:\", min(test_q3$date), \"to\", max(test_q3$date), \"\\n\")\n```\n\n## 1.11 Build Five Baseline Models (Q3 2024)\n\n```{r prepare_factors_q3}\n# Create day of week factor with treatment coding (Monday = baseline)\ntrain_q3 <- train_q3 %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q3$dotw_simple) <- contr.treatment(7)\n\ntest_q3 <- test_q3 %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n```\n\n```{r model1_q3}\nmodel1_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q3\n)\n\ncat(\"Model 1 Q3: Time + Weather\\n\")\ncat(\"R-squared:\", round(summary(model1_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model2_q3}\nmodel2_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q3\n)\n\ncat(\"Model 2 Q3: + Temporal Lags\\n\")\ncat(\"R-squared:\", round(summary(model2_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model3_q3}\nmodel3_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q3\n)\n\ncat(\"Model 3 Q3: + Demographics\\n\")\ncat(\"R-squared:\", round(summary(model3_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model4_q3}\nmodel4_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q3\n)\n\ncat(\"Model 4 Q3: + Station FE\\n\")\ncat(\"R-squared:\", round(summary(model4_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model5_q3}\nmodel5_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q3\n)\n\ncat(\"Model 5 Q3: + Rush Hour Interaction\\n\")\ncat(\"R-squared:\", round(summary(model5_q3)$r.squared, 4), \"\\n\")\n```\n\n## 1.12 Calculate MAE for Q3 2024\n\n```{r calculate_mae_q3}\n# Get predictions\ntest_q3 <- test_q3 %>%\n  mutate(\n    pred1 = predict(model1_q3, newdata = test_q3),\n    pred2 = predict(model2_q3, newdata = test_q3),\n    pred3 = predict(model3_q3, newdata = test_q3),\n    pred4 = predict(model4_q3, newdata = test_q3),\n    pred5 = predict(model5_q3, newdata = test_q3)\n  )\n\n# Calculate MAE\nmae_q3 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE_Q3 = c(\n    mean(abs(test_q3$Trip_Count - test_q3$pred1), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred2), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred3), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred4), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred5), na.rm = TRUE)\n  )\n)\n```\n\n## 1.13 Load and Calculate MAE for Q1 2025 (For Comparison)\n\nFor a fair comparison, I now build the same 5 models on Q1 2025 data to calculate MAE values directly.\n\n```{r process_q1_full}\n#| message: false\n\n# Process Q1 data same way as Q3\nindego_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Join census\nstations_sf_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\nstations_census_q1 <- st_join(stations_sf_q1, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\nvalid_stations_q1 <- stations_census_q1 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\nindego_census_q1 <- indego_q1 %>%\n  filter(start_station %in% valid_stations_q1) %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Get Q1 weather\nweather_data_q1 <- riem_measures(\n  station = \"PHL\",\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\nweather_complete_q1 <- weather_data_q1 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct() %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Create panel\ntrips_panel_q1 <- indego_census_q1 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n(), .groups = \"drop\")\n\nstation_attributes_q1 <- trips_panel_q1 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop),\n    .groups = \"drop\"\n  )\n\nstudy_panel_q1 <- expand.grid(\n  interval60 = unique(trips_panel_q1$interval60),\n  start_station = unique(trips_panel_q1$start_station),\n  stringsAsFactors = FALSE\n) %>%\n  left_join(\n    trips_panel_q1 %>% select(interval60, start_station, Trip_Count), \n    by = c(\"interval60\", \"start_station\")\n  ) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0)) %>%\n  left_join(station_attributes_q1, by = \"start_station\") %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  ) %>%\n  left_join(weather_complete_q1, by = \"interval60\")\n\n# Add lags\nstudy_panel_q1 <- study_panel_q1 %>%\n  arrange(start_station, interval60) %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag3Hours = lag(Trip_Count, 3),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\nstudy_panel_complete_q1 <- study_panel_q1 %>%\n  filter(!is.na(lag1day))\n\n# Train/test split (Q1 has weeks 1-13)\n# Train on weeks 1-9, test on weeks 10-13\nearly_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations_q1 <- intersect(early_stations_q1, late_stations_q1)\n\nstudy_panel_complete_q1 <- study_panel_complete_q1 %>%\n  filter(start_station %in% common_stations_q1)\n\ntrain_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q1$dotw_simple) <- contr.treatment(7)\ncontrasts(test_q1$dotw_simple) <- contr.treatment(7)\n\ncat(\"Q1 Training observations:\", format(nrow(train_q1), big.mark = \",\"), \"\\n\")\ncat(\"Q1 Testing observations:\", format(nrow(test_q1), big.mark = \",\"), \"\\n\")\n```\n\n```{r build_q1_models}\n# Build same 5 models for Q1\nmodel1_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q1\n)\n\nmodel2_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q1\n)\n\nmodel3_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q1\n)\n\nmodel4_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q1\n)\n\nmodel5_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q1\n)\n\n# Get predictions\ntest_q1 <- test_q1 %>%\n  mutate(\n    pred1 = predict(model1_q1, newdata = test_q1),\n    pred2 = predict(model2_q1, newdata = test_q1),\n    pred3 = predict(model3_q1, newdata = test_q1),\n    pred4 = predict(model4_q1, newdata = test_q1),\n    pred5 = predict(model5_q1, newdata = test_q1)\n  )\n\n# Calculate MAE\nmae_q1 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE_Q1 = c(\n    mean(abs(test_q1$Trip_Count - test_q1$pred1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred2), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred3), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred4), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred5), na.rm = TRUE)\n  )\n)\n\ncat(\"✓ Q1 2025 models built and evaluated\\n\")\n```\n\n## 1.14 Direct Q1 vs Q3 Comparison\n\n```{r final_comparison}\n# Combine results\nmae_comparison <- mae_q3 %>%\n  left_join(mae_q1, by = \"Model\") %>%\n  mutate(\n    Q3_Better = MAE_Q3 < MAE_Q1,\n    Improvement = round((MAE_Q1 - MAE_Q3) / MAE_Q1 * 100, 1)\n  )\n\nkable(mae_comparison,\n      caption = \"Part 1 Results: Q3 2024 Summer vs Q1 2025 Winter Performance\",\n      col.names = c(\"Model\", \"Q3 MAE\\n(Summer)\", \"Q1 MAE\\n(Winter)\", \n                    \"Summer\\nBetter?\", \"% Improvement\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r viz_final_comparison}\n#| fig-width: 12\n#| fig-height: 6\n\nmae_long <- mae_comparison %>%\n  select(Model, MAE_Q3, MAE_Q1) %>%\n  pivot_longer(cols = c(MAE_Q3, MAE_Q1), names_to = \"Quarter\", values_to = \"MAE\") %>%\n  mutate(Quarter = recode(Quarter, \n                          \"MAE_Q3\" = \"Q3 2024 (Summer)\", \n                          \"MAE_Q1\" = \"Q1 2025 (Winter)\"))\n\nggplot(mae_long, aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  scale_fill_manual(values = c(\"Q3 2024 (Summer)\" = \"#08519c\", \n                                \"Q1 2025 (Winter)\" = \"#6baed6\")) +\n  labs(\n    title = \"Model Performance: Q3 2024 Summer vs Q1 2025 Winter\",\n    subtitle = \"Summer achieves lower MAE across all models despite 38% higher ridership\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Quarter\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Part 1 Key Findings:**\n\n-   **Summer is more predictable**: Q3 achieves 10-20% lower MAE than Q1 across all models\n-   **Temporal lags dominate**: Model 2 achieves biggest improvement in both seasons\n-   **Similar improvement patterns**: Features add value consistently across seasons\n-   **Core approach generalizes**: Same model architecture works well in both winter and summer\n\n# Part 2: Error Analysis (Q3 2024 Focus)\n\nThe remainder of the analysis focuses on Q3 2024 to conduct detailed error analysis and feature engineering.\n\n## 2.1 Spatial Error Patterns\n\n```{r spatial_errors_q3}\n#| fig-width: 12\n#| fig-height: 8\n\n# Calculate errors\ntest_q3 <- test_q3 %>%\n  mutate(\n    error = Trip_Count - pred5,\n    abs_error = abs(error)\n  )\n\nstation_errors_q3 <- test_q3 %>%\n  filter(!is.na(pred5)) %>%\n  group_by(start_station, start_lat, start_lon) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    mean_error = mean(error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat), !is.na(start_lon))\n\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(data = station_errors_q3, aes(x = start_lon, y = start_lat, color = MAE),\n             size = 3, alpha = 0.7) +\n  scale_color_viridis(option = \"plasma\", name = \"MAE\\n(trips)\", direction = -1) +\n  labs(title = \"Prediction Errors by Station\", \n       subtitle = \"Higher in Center City high-demand areas\") +\n  mapTheme\n\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(data = station_errors_q3, aes(x = start_lon, y = start_lat, color = avg_demand),\n             size = 3, alpha = 0.7) +\n  scale_color_viridis(option = \"viridis\", name = \"Avg\\nDemand\", direction = -1) +\n  labs(title = \"Average Demand by Station\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme\n\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n**Spatial Finding**: Errors concentrate in Center City/University City where demand is highest.\n\n## 2.2 Temporal Error Patterns\n\n```{r temporal_errors_q3}\n#| fig-width: 12\n#| fig-height: 10\n\n# Errors by hour\nhourly_errors_q3 <- test_q3 %>%\n  group_by(hour) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    mean_error = mean(error, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\np1 <- ggplot(hourly_errors_q3, aes(x = hour)) +\n  geom_col(aes(y = MAE), fill = \"#3182bd\", alpha = 0.7) +\n  geom_line(aes(y = mean_error * 2), color = \"red\", linewidth = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Prediction Errors by Hour (Q3 2024)\",\n       subtitle = \"Blue = MAE; Red = Mean Error (×2 for scale)\",\n       x = \"Hour\", y = \"Error (trips)\") +\n  plotTheme\n\n# Errors by time of day\ntest_q3 <- test_q3 %>%\n  mutate(\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM_Rush\",\n      hour >= 10 & hour < 15 ~ \"Midday\",\n      hour >= 15 & hour <= 18 ~ \"PM_Rush\",\n      hour > 18 ~ \"Evening\"\n    ),\n    time_of_day = factor(time_of_day, \n                         levels = c(\"Overnight\", \"AM_Rush\", \"Midday\", \"PM_Rush\", \"Evening\")),\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\ntemporal_errors_q3 <- test_q3 %>%\n  group_by(time_of_day, day_type) %>%\n  summarize(MAE = mean(abs_error, na.rm = TRUE), .groups = \"drop\")\n\np2 <- ggplot(temporal_errors_q3, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(title = \"Errors by Time Period (Q3 2024)\",\n       subtitle = \"Highest during weekday PM rush\",\n       x = \"Time of Day\", y = \"MAE (trips)\", fill = \"Day Type\") +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngrid.arrange(p1, p2, ncol = 1)\n```\n\n**Temporal Finding**: PM Rush on weekdays shows highest errors—the most operationally critical period.\n\n## 2.3 Equity Analysis\n\n```{r equity_analysis_q3}\nstation_errors_demo_q3 <- station_errors_q3 %>%\n  left_join(station_attributes_q3 %>% \n              select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n            by = \"start_station\") %>%\n  filter(!is.na(Med_Inc)) %>%\n  mutate(\n    pct_error = ifelse(avg_demand > 0, (MAE / avg_demand) * 100, NA),\n    income_quartile = cut(Med_Inc,\n                          breaks = quantile(Med_Inc, probs = 0:4/4, na.rm = TRUE),\n                          labels = c(\"Q1 (Lowest)\", \"Q2\", \"Q3\", \"Q4 (Highest)\"),\n                          include.lowest = TRUE)\n  )\n\nequity_summary_q3 <- station_errors_demo_q3 %>%\n  filter(!is.na(pct_error), is.finite(pct_error)) %>%\n  group_by(income_quartile) %>%\n  summarize(\n    avg_MAE = mean(MAE, na.rm = TRUE),\n    avg_pct_error = mean(pct_error, na.rm = TRUE),\n    avg_demand = mean(avg_demand, na.rm = TRUE),\n    stations = n(),\n    .groups = \"drop\"\n  )\n\nkable(equity_summary_q3,\n      caption = \"Part 2: Performance by Income Level (Q3 2024)\",\n      col.names = c(\"Income Quartile\", \"Avg MAE\", \"Avg % Error\", \"Avg Demand\", \"# Stations\"),\n      digits = c(0, 2, 1, 2, 0)) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r equity_viz_q3}\n#| fig-width: 12\n#| fig-height: 5\n\np_abs <- ggplot(equity_summary_q3, aes(x = income_quartile, y = avg_MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(avg_MAE, 2)), vjust = -0.5) +\n  labs(title = \"Absolute Errors by Income (Q3 2024)\",\n       subtitle = \"Higher in wealthier areas (reflects demand)\",\n       x = \"Income Quartile\", y = \"Avg MAE\") +\n  plotTheme\n\np_pct <- ggplot(equity_summary_q3, aes(x = income_quartile, y = avg_pct_error)) +\n  geom_col(fill = \"#6baed6\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(avg_pct_error, 1), \"%\")), vjust = -0.5) +\n  labs(title = \"Percentage Errors by Income (Q3 2024)\",\n       subtitle = \"Similar across groups - no bias\",\n       x = \"Income Quartile\", y = \"Avg % Error\") +\n  plotTheme\n\ngrid.arrange(p_abs, p_pct, ncol = 2)\n```\n\n**Part 2 Equity Finding**: No systematic bias when measured as percentage errors. Higher absolute errors in wealthier areas reflect higher demand, not worse model performance.\n\n# Part 3: Feature Engineering\n\n## 3.1 Add New Features for Q3\n\n```{r add_new_features_q3}\n# Add to complete panel\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  arrange(start_station, interval60) %>%\n  group_by(start_station) %>%\n  mutate(\n    # Feature 1: Holidays\n    july4 = ifelse(date == as.Date(\"2024-07-04\"), 1, 0),\n    labor_day = ifelse(date >= as.Date(\"2024-08-31\") & date <= as.Date(\"2024-09-02\"), 1, 0),\n    holiday = ifelse(july4 == 1 | labor_day == 1, 1, 0),\n    \n    # Feature 2: Weather conditions\n    perfect_weather = ifelse(Temperature >= 60 & Temperature <= 75 & Precipitation == 0, 1, 0),\n    too_hot = ifelse(Temperature > 85, 1, 0),\n    weekend_nice = weekend * perfect_weather,\n    \n    # Feature 3: Rolling averages\n    lag7day_avg = zoo::rollmean(Trip_Count, k = 168, fill = NA, align = \"right\"),\n    lag1week_samehour = lag(Trip_Count, 168)\n  ) %>%\n  ungroup()\n\n# Re-create train/test with new features\ntrain_q3_new <- study_panel_complete_q3 %>%\n  filter(week < 36, start_station %in% common_stations_q3) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q3_new <- study_panel_complete_q3 %>%\n  filter(week >= 36, start_station %in% common_stations_q3) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q3_new$dotw_simple) <- contr.treatment(7)\ncontrasts(test_q3_new$dotw_simple) <- contr.treatment(7)\n```\n\n## 3.2 Model 6: Add New Features\n\n```{r model6_q3}\nmodel6_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag7day_avg + lag1week_samehour +\n    rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    holiday + perfect_weather + too_hot + weekend_nice +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q3_new\n)\n\ncat(\"Model 6 Q3: + New Features\\n\")\ncat(\"R-squared:\", round(summary(model6_q3)$r.squared, 4), \"\\n\")\n```\n\n## 3.3 Model 7: Poisson Regression\n\n```{r model7_q3}\nmodel7_q3 <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag7day_avg +\n    holiday + perfect_weather + too_hot +\n    as.factor(start_station),\n  data = train_q3_new,\n  family = poisson(link = \"log\")\n)\n\ncat(\"Model 7 Q3: Poisson Regression\\n\")\ncat(\"AIC:\", round(AIC(model7_q3), 0), \"\\n\")\n```\n\n## 3.4 Evaluate All Models\n\n```{r evaluate_all_models_q3}\n# Get predictions for new models\ntest_q3_new <- test_q3_new %>%\n  mutate(\n    pred6 = predict(model6_q3, newdata = test_q3_new),\n    pred7 = predict(model7_q3, newdata = test_q3_new, type = \"response\")\n  )\n\n# Also need predictions from original 5 models\ntest_q3_new <- test_q3_new %>%\n  mutate(\n    pred1 = predict(model1_q3, newdata = test_q3_new),\n    pred2 = predict(model2_q3, newdata = test_q3_new),\n    pred3 = predict(model3_q3, newdata = test_q3_new),\n    pred4 = predict(model4_q3, newdata = test_q3_new),\n    pred5 = predict(model5_q3, newdata = test_q3_new)\n  )\n\nmae_all_q3 <- data.frame(\n  Model = paste0(\"Model \", 1:7),\n  Description = c(\n    \"Time + Weather\",\n    \"+ Temporal Lags\",\n    \"+ Demographics\",\n    \"+ Station FE\",\n    \"+ Rush Hour Interaction\",\n    \"+ New Features\",\n    \"Poisson\"\n  ),\n  MAE = c(\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred1), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred2), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred3), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred4), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred5), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred6), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred7), na.rm = TRUE)\n  )\n) %>%\n  mutate(improvement = round((MAE[1] - MAE) / MAE[1] * 100, 1))\n\nkable(mae_all_q3,\n      caption = \"Part 3: All Models Performance (Q3 2024)\",\n      col.names = c(\"Model\", \"Description\", \"MAE (trips)\", \"% Improvement\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r viz_all_models_q3}\n#| fig-width: 10\n#| fig-height: 6\n\nggplot(mae_all_q3, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 3)), vjust = -0.5, size = 3) +\n  geom_hline(yintercept = mae_all_q3$MAE[2], linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"All Models Performance - Q3 2024\",\n    subtitle = \"Model 2 (temporal lags) captures most improvement; additional features add minimal value\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\",\n    caption = \"Dashed line = Model 2 (temporal lags)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Part 3 Results**: Temporal lags (Model 2) capture most of the achievable improvement. New features and Poisson regression add only marginal gains. **Finding: Simple temporal lags are the key to performance.**\n\n# Part 4: Critical Reflection\n\n## 4.1 Operational Implications\n\n```{r operational_metrics_q3}\navg_demand_q3 <- mean(test_q3_new$Trip_Count, na.rm = TRUE)\nmae_best_q3 <- min(mae_all_q3$MAE)\nmedian_demand_q3 <- median(test_q3_new$Trip_Count, na.rm = TRUE)\nzero_pct_q3 <- mean(test_q3_new$Trip_Count == 0, na.rm = TRUE) * 100\n\ncat(\"Q3 2024 Operational Metrics:\\n\")\ncat(\"Average demand:\", round(avg_demand_q3, 2), \"trips/hour\\n\")\ncat(\"Median demand:\", median_demand_q3, \"trips/hour\\n\")\ncat(\"Zero observations:\", round(zero_pct_q3, 1), \"%\\n\")\ncat(\"Best MAE:\", round(mae_best_q3, 3), \"trips/hour\\n\")\ncat(\"MAE as % of mean:\", round((mae_best_q3/avg_demand_q3)*100, 1), \"%\\n\")\n```\n\n**Deployment Recommendation:**\n\nYES, conditionally. Deploy for regional rebalancing strategy and medium-confidence routing. Combine with real-time dock data, weather forecasts, and human oversight. Don't use alone for critical AM rush decisions at busiest stations. Requires quarterly retraining with recent data.\n\n## 4.2 Equity Considerations\n\n**Finding**: No systematic bias when measured as percentage errors. All income quartiles show similar error rates.\n\n**Potential Concerns**: Spatial coverage bias, data feedback loops, supply-driven demand.\n\n**Recommended Safeguards**: Equity audit dashboard, minimum service standards, proactive over-supply in underserved areas, community feedback integration.\n\n## 4.3 Model Limitations\n\n**Missing patterns**: Special events, weather forecasts (not actuals), supply constraints, academic calendar impacts, infrastructure changes.\n\n**Violated assumptions**: Past predicts future, station independence, no capacity constraints, normal operations.\n\n**Improvements needed**: - High priority: Weather forecasts, zero-inflated models, event calendar API - Medium priority: Station-to-station flows, real-time features, spatial features - Lower priority: Ensemble methods, user-level modeling\n\n# Conclusion\n\nThis analysis demonstrates that **seasonal stability matters more than absolute volume for prediction accuracy**. Q3 summer achieves 10-20% lower MAE than Q1 winter despite 38% higher ridership.\n\n**Key Findings:**\n\n1.  **Seasonal Performance**: Summer's stable patterns enable better predictions than winter's volatile weather\n2.  **Model Architecture**: Simple temporal lags capture 95% of achievable improvement\n3.  **Feature Engineering**: Complex features add minimal value beyond basic lags\n4.  **Equity**: No systematic bias across income levels when measured appropriately\n5.  **Generalizability**: Core modeling approach works well across both seasons\n\n**Operational Recommendation**: Conditionally deploy as decision support for regional rebalancing, combined with real-time data and human oversight.\n\n**Research Contribution**: Demonstrates that stability enables prediction more than volume does, with important implications for bike share operations and predictive modeling broadly.\n","srcMarkdownNoYaml":"\n\nPhiladelphia's Indego bike share system faces a critical operational challenge: rebalancing bikes to meet anticipated demand. Operations managers must decide at 6:00 AM which of 200+ stations will run out of bikes by the morning rush, with limited trucks and staff to move bikes efficiently.\n\nThis assignment applies space-time predictive modeling to forecast hourly bike share demand at station-level granularity. Following the methodology established with Q1 2025 winter data in class, I analyze Q3 2024 (July-September) to understand how summer peak season affects prediction accuracy compared to winter baseline patterns.\n\nI chose Q3 2024 for several reasons. First, summer represents the opposite seasonal extreme from Q1 2025 winter: highest annual ridership, minimal weather disruptions (no snow or ice events), significant tourist activity, and unique special events like July 4th and Labor Day weekend. Second, the 38% ridership increase from winter provides a test of whether models perform better with higher, more stable demand or whether increased volume creates more prediction challenges.\n\nThe core methodology aggregates individual trips into a space-time panel where each observation represents demand at a specific station during a specific hour. I build five baseline models with progressively more complex features, engineer new summer-specific features, and test whether Poisson regression designed for count data outperforms ordinary least squares linear regression.\n\nModel evaluation uses temporal validation, splitting each quarter into training and test periods to assess generalizability. I analyze prediction errors across spatial, temporal, and demographic dimensions to identify where the model struggles and assess equity implications. The analysis concludes with direct comparison of Q1 2025 winter and Q3 2024 summer performance and honest assessment of operational deployment readiness.\n\n# Setup\n\n```{r setup}\n#| message: false\n#| warning: false\n\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Additional packages\nlibrary(zoo)  # For rolling averages\n\n# Set options\noptions(scipen = 999)\noptions(tigris_use_cache = TRUE)\n```\n\n```{r themes}\n# Define consistent plot themes\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", linewidth = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n```{r census_key}\n#| include: false\n\n# Insert your census API key here\ncensus_api_key(\"52f0462d8b4e1e19ee64b25a3196677c5e32e660\", overwrite = TRUE)\n```\n\n# Part 1: Load and Compare Both Quarters\n\nThis section loads BOTH Q1 2025 (winter baseline) and Q3 2024 (summer) data to enable direct comparison throughout the analysis. Understanding seasonal differences requires seeing both datasets side-by-side.\n\n## 1.1 Load Q1 2025 Winter Baseline Data\n\n```{r load_q1}\n#| message: false\n\n# Load Q1 2025 winter data (January-March)\n# This is the baseline analyzed in class\nindego_q1 <- read_csv(\"data/indego-trips-2025-q1.csv\")\n\ncat(\"✓ Loaded Q1 2025 (January-March) WINTER data\\n\")\ncat(\"Total trips:\", format(nrow(indego_q1), big.mark = \",\"), \"\\n\")\ncat(\"Date range:\", \n    min(mdy_hm(indego_q1$start_time)), \"to\", \n    max(mdy_hm(indego_q1$start_time)), \"\\n\")\ncat(\"Unique start stations:\", length(unique(indego_q1$start_station)), \"\\n\")\n```\n\n## 1.2 Load Q3 2024 Summer Data\n\n```{r load_q3}\n#| message: false\n\n# Load Q3 2024 summer data (July-September)\n# Downloaded from: https://www.rideindego.com/about/data/\nindego_q3 <- read_csv(\"data/indego-trips-2024-q3.csv\")\n\ncat(\"✓ Loaded Q3 2024 (July-September) SUMMER data\\n\")\ncat(\"Total trips:\", format(nrow(indego_q3), big.mark = \",\"), \"\\n\")\ncat(\"Date range:\", \n    min(mdy_hm(indego_q3$start_time)), \"to\", \n    max(mdy_hm(indego_q3$start_time)), \"\\n\")\ncat(\"Unique start stations:\", length(unique(indego_q3$start_station)), \"\\n\")\n```\n\n## 1.3 Initial Comparison: Daily Ridership\n\n```{r compare_daily_ridership}\n#| fig-width: 12\n#| fig-height: 6\n\n# Process Q1 data\ndaily_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    date = as.Date(start_datetime)\n  ) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  mutate(quarter = \"Q1 2025 (Winter)\")\n\n# Process Q3 data\ndaily_q3 <- indego_q3 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    date = as.Date(start_datetime)\n  ) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  mutate(quarter = \"Q3 2024 (Summer)\")\n\n# Combine for comparison\ndaily_combined <- bind_rows(daily_q1, daily_q3)\n\n# Calculate summary stats\nsummary_stats <- daily_combined %>%\n  group_by(quarter) %>%\n  summarize(\n    avg_daily = round(mean(trips)),\n    min_daily = min(trips),\n    max_daily = max(trips),\n    .groups = \"drop\"\n  )\n\nkable(summary_stats,\n      caption = \"Daily Ridership Comparison: Winter vs Summer\",\n      col.names = c(\"Quarter\", \"Avg Daily Trips\", \"Min\", \"Max\"),\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Calculate percentage difference\nq1_avg <- summary_stats %>% filter(quarter == \"Q1 2025 (Winter)\") %>% pull(avg_daily)\nq3_avg <- summary_stats %>% filter(quarter == \"Q3 2024 (Summer)\") %>% pull(avg_daily)\npct_diff <- round((q3_avg - q1_avg) / q1_avg * 100, 1)\n\ncat(\"\\nQ3 Summer has\", pct_diff, \"% higher daily ridership than Q1 Winter\\n\")\n```\n\n```{r viz_daily_comparison}\n#| fig-width: 14\n#| fig-height: 6\n\nggplot(daily_combined, aes(x = date, y = trips, color = quarter)) +\n  geom_line(linewidth = 0.8, alpha = 0.7) +\n  geom_smooth(se = FALSE, linewidth = 1.2) +\n  scale_color_manual(values = c(\"Q1 2025 (Winter)\" = \"#6baed6\", \n                                 \"Q3 2024 (Summer)\" = \"#08519c\")) +\n  labs(\n    title = \"Daily Ridership: Q1 2025 Winter vs Q3 2024 Summer\",\n    subtitle = paste0(\"Summer averages \", pct_diff, \"% higher ridership with more stable patterns\"),\n    x = \"Date\",\n    y = \"Daily Trips\",\n    color = \"Quarter\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Key Observation**: Summer shows higher, more consistent ridership. Winter has notable volatility (snow events, warm spikes). This sets up our hypothesis: **higher volume but more stability may improve prediction accuracy**.\n\n## 1.4 Process Q3 2024 Data (Main Analysis)\n\nFor the remainder of this analysis, I focus on building and evaluating models for Q3 2024, then compare final results to Q1 2025 baseline performance.\n\n```{r create_time_bins_q3}\nindego_q3 <- indego_q3 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## 1.5 Q3 2024 Exploratory Analysis\n\n### Special Events in Summer\n\n```{r special_events_q3}\ndaily_q3_simple <- indego_q3 %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\")\n\n# July 4th\njuly4_trips <- daily_q3_simple %>% \n  filter(date == as.Date(\"2024-07-04\")) %>% \n  pull(trips)\n\n# Labor Day weekend\nlabor_day_trips <- daily_q3_simple %>%\n  filter(date >= as.Date(\"2024-08-31\") & date <= as.Date(\"2024-09-02\")) %>%\n  summarize(avg = mean(trips)) %>% \n  pull(avg)\n\n# Typical weekday\ntypical_weekday <- indego_q3 %>%\n  filter(dotw %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n         !(date %in% c(as.Date(\"2024-07-04\"), as.Date(\"2024-09-02\")))) %>%\n  group_by(date) %>%\n  summarize(trips = n(), .groups = \"drop\") %>%\n  summarize(avg = mean(trips)) %>% \n  pull(avg)\n\nevent_comparison <- data.frame(\n  Event = c(\"July 4th\", \"Labor Day Weekend\", \"Typical Weekday\"),\n  Trips = c(july4_trips, round(labor_day_trips), round(typical_weekday)),\n  Difference = c(\n    paste0(round((july4_trips - typical_weekday)/typical_weekday*100, 1), \"%\"),\n    paste0(round((labor_day_trips - typical_weekday)/typical_weekday*100, 1), \"%\"),\n    \"baseline\"\n  )\n)\n\nkable(event_comparison,\n      caption = \"Q3 2024 Special Event Impact\",\n      col.names = c(\"Day Type\", \"Trips\", \"% vs Typical\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Finding**: Summer holidays show LOWER ridership (\\~15% below typical) because they eliminate commute trips. This contrasts with Q1 2025's Eagles Super Bowl parade which created a major spike.\n\n### Hourly Patterns Comparison\n\n```{r hourly_patterns_comparison}\n#| fig-width: 12\n#| fig-height: 6\n\n# Q1 hourly patterns\nhourly_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    hour = hour(start_datetime),\n    dotw = wday(start_datetime, label = TRUE),\n    date = as.Date(start_datetime),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0)\n  ) %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date), .groups = \"drop\") %>%\n  mutate(\n    quarter = \"Q1 2025 (Winter)\",\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\n# Q3 hourly patterns\nhourly_q3 <- indego_q3 %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date), .groups = \"drop\") %>%\n  mutate(\n    quarter = \"Q3 2024 (Summer)\",\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\n# Combine\nhourly_combined <- bind_rows(hourly_q1, hourly_q3)\n\nggplot(hourly_combined, aes(x = hour, y = avg_trips, color = quarter, linetype = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Q1 2025 (Winter)\" = \"#6baed6\", \n                                 \"Q3 2024 (Summer)\" = \"#08519c\")) +\n  scale_linetype_manual(values = c(\"Weekday\" = \"solid\", \"Weekend\" = \"dashed\")) +\n  labs(\n    title = \"Hourly Demand Patterns: Winter vs Summer\",\n    subtitle = \"Both quarters show clear commute peaks on weekdays; summer has higher baseline\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Quarter\",\n    linetype = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Finding**: Both quarters show similar temporal patterns (AM/PM peaks on weekdays), but summer maintains higher baseline throughout the day.\n\n## 1.6 Get Philadelphia Spatial Context\n\n```{r load_census}\n#| message: false\n\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)\n\ncat(\"Loaded\", nrow(philly_census), \"census tracts\\n\")\n```\n\n```{r join_census_q3}\n#| message: false\n\n# Create spatial points for Q3 stations\nstations_sf_q3 <- indego_q3 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to census tracts\nstations_census_q3 <- st_join(stations_sf_q3, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Filter to residential stations\nvalid_stations_q3 <- stations_census_q3 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data\nindego_census_q3 <- indego_q3 %>%\n  filter(start_station %in% valid_stations_q3) %>%\n  left_join(\n    stations_census_q3 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\ncat(\"Filtered to\", length(valid_stations_q3), \"residential stations\\n\")\ncat(\"Retained\", format(nrow(indego_census_q3), big.mark = \",\"), \"trips\\n\")\n```\n\n## 1.7 Get Weather Data for Q3 2024\n\n```{r get_weather_q3}\n#| message: false\n\n# Download Q3 2024 weather from Philadelphia Airport\nweather_data_q3 <- riem_measures(\n  station = \"PHL\",\n  date_start = \"2024-07-01\",\n  date_end = \"2024-09-30\"\n)\n\n# Process weather data\nweather_complete_q3 <- weather_data_q3 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct() %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\ncat(\"✓ Q3 Weather data complete\\n\")\nsummary(weather_complete_q3 %>% select(Temperature, Precipitation))\n```\n\n## 1.8 Create Space-Time Panel for Q3 2024\n\n```{r aggregate_trips_q3}\n# Count trips by station-hour\n# Group by demographics so they carry forward\ntrips_panel_q3 <- indego_census_q3 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n(), .groups = \"drop\")\n\ncat(\"Initial panel observations:\", format(nrow(trips_panel_q3), big.mark = \",\"), \"\\n\")\n```\n\n```{r complete_panel_q3}\n# CRITICAL: Extract station attributes FIRST to avoid duplicates\nstation_attributes_q3 <- trips_panel_q3 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop),\n    .groups = \"drop\"\n  )\n\n# Create complete panel (all station-hour combinations)\nstudy_panel_q3 <- expand.grid(\n  interval60 = unique(trips_panel_q3$interval60),\n  start_station = unique(trips_panel_q3$start_station),\n  stringsAsFactors = FALSE\n) %>%\n  # Join trip counts ONLY (not demographics to avoid duplicates)\n  left_join(\n    trips_panel_q3 %>% select(interval60, start_station, Trip_Count), \n    by = c(\"interval60\", \"start_station\")\n  ) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0)) %>%\n  # NOW join station attributes\n  left_join(station_attributes_q3, by = \"start_station\")\n\ncat(\"Complete panel rows:\", format(nrow(study_panel_q3), big.mark = \",\"), \"\\n\")\ncat(\"Zero observations:\", sum(study_panel_q3$Trip_Count == 0),\n    \"(\", round(sum(study_panel_q3$Trip_Count == 0)/nrow(study_panel_q3)*100, 1), \"%)\\n\")\n```\n\n```{r add_features_q3}\nstudy_panel_q3 <- study_panel_q3 %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  ) %>%\n  left_join(weather_complete_q3, by = \"interval60\")\n```\n\n## 1.9 Create Temporal Lag Variables\n\n```{r create_lags_q3}\n# Sort by station and time\nstudy_panel_q3 <- study_panel_q3 %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel_q3 <- study_panel_q3 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags\nstudy_panel_complete_q3 <- study_panel_q3 %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete_q3), big.mark = \",\"), \"\\n\")\n```\n\n## 1.10 Temporal Train/Test Split\n\n```{r temporal_split_q3}\n# Q3 2024 has weeks 27-39 (July-September)\n# Train on weeks 27-35 (July 1 - early September)\n# Test on weeks 36-39 (rest of September)\n\n# Which stations have trips in BOTH periods?\nearly_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only common stations\ncommon_stations_q3 <- intersect(early_stations_q3, late_stations_q3)\n\ncat(\"Common stations (appear in both train/test):\", length(common_stations_q3), \"\\n\")\n\n# Filter to common stations and split\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  filter(start_station %in% common_stations_q3)\n\ntrain_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36)\n\ntest_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36)\n\ncat(\"\\nQ3 Training observations:\", format(nrow(train_q3), big.mark = \",\"), \"\\n\")\ncat(\"Q3 Testing observations:\", format(nrow(test_q3), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train_q3$date), \"to\", max(train_q3$date), \"\\n\")\ncat(\"Testing date range:\", min(test_q3$date), \"to\", max(test_q3$date), \"\\n\")\n```\n\n## 1.11 Build Five Baseline Models (Q3 2024)\n\n```{r prepare_factors_q3}\n# Create day of week factor with treatment coding (Monday = baseline)\ntrain_q3 <- train_q3 %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q3$dotw_simple) <- contr.treatment(7)\n\ntest_q3 <- test_q3 %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n```\n\n```{r model1_q3}\nmodel1_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q3\n)\n\ncat(\"Model 1 Q3: Time + Weather\\n\")\ncat(\"R-squared:\", round(summary(model1_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model2_q3}\nmodel2_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q3\n)\n\ncat(\"Model 2 Q3: + Temporal Lags\\n\")\ncat(\"R-squared:\", round(summary(model2_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model3_q3}\nmodel3_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q3\n)\n\ncat(\"Model 3 Q3: + Demographics\\n\")\ncat(\"R-squared:\", round(summary(model3_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model4_q3}\nmodel4_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q3\n)\n\ncat(\"Model 4 Q3: + Station FE\\n\")\ncat(\"R-squared:\", round(summary(model4_q3)$r.squared, 4), \"\\n\")\n```\n\n```{r model5_q3}\nmodel5_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q3\n)\n\ncat(\"Model 5 Q3: + Rush Hour Interaction\\n\")\ncat(\"R-squared:\", round(summary(model5_q3)$r.squared, 4), \"\\n\")\n```\n\n## 1.12 Calculate MAE for Q3 2024\n\n```{r calculate_mae_q3}\n# Get predictions\ntest_q3 <- test_q3 %>%\n  mutate(\n    pred1 = predict(model1_q3, newdata = test_q3),\n    pred2 = predict(model2_q3, newdata = test_q3),\n    pred3 = predict(model3_q3, newdata = test_q3),\n    pred4 = predict(model4_q3, newdata = test_q3),\n    pred5 = predict(model5_q3, newdata = test_q3)\n  )\n\n# Calculate MAE\nmae_q3 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE_Q3 = c(\n    mean(abs(test_q3$Trip_Count - test_q3$pred1), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred2), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred3), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred4), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred5), na.rm = TRUE)\n  )\n)\n```\n\n## 1.13 Load and Calculate MAE for Q1 2025 (For Comparison)\n\nFor a fair comparison, I now build the same 5 models on Q1 2025 data to calculate MAE values directly.\n\n```{r process_q1_full}\n#| message: false\n\n# Process Q1 data same way as Q3\nindego_q1 <- indego_q1 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Join census\nstations_sf_q1 <- indego_q1 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\nstations_census_q1 <- st_join(stations_sf_q1, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\nvalid_stations_q1 <- stations_census_q1 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\nindego_census_q1 <- indego_q1 %>%\n  filter(start_station %in% valid_stations_q1) %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Get Q1 weather\nweather_data_q1 <- riem_measures(\n  station = \"PHL\",\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\nweather_complete_q1 <- weather_data_q1 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct() %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Create panel\ntrips_panel_q1 <- indego_census_q1 %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n(), .groups = \"drop\")\n\nstation_attributes_q1 <- trips_panel_q1 %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop),\n    .groups = \"drop\"\n  )\n\nstudy_panel_q1 <- expand.grid(\n  interval60 = unique(trips_panel_q1$interval60),\n  start_station = unique(trips_panel_q1$start_station),\n  stringsAsFactors = FALSE\n) %>%\n  left_join(\n    trips_panel_q1 %>% select(interval60, start_station, Trip_Count), \n    by = c(\"interval60\", \"start_station\")\n  ) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0)) %>%\n  left_join(station_attributes_q1, by = \"start_station\") %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  ) %>%\n  left_join(weather_complete_q1, by = \"interval60\")\n\n# Add lags\nstudy_panel_q1 <- study_panel_q1 %>%\n  arrange(start_station, interval60) %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag3Hours = lag(Trip_Count, 3),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\nstudy_panel_complete_q1 <- study_panel_q1 %>%\n  filter(!is.na(lag1day))\n\n# Train/test split (Q1 has weeks 1-13)\n# Train on weeks 1-9, test on weeks 10-13\nearly_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_stations_q1 <- intersect(early_stations_q1, late_stations_q1)\n\nstudy_panel_complete_q1 <- study_panel_complete_q1 %>%\n  filter(start_station %in% common_stations_q1)\n\ntrain_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q1$dotw_simple) <- contr.treatment(7)\ncontrasts(test_q1$dotw_simple) <- contr.treatment(7)\n\ncat(\"Q1 Training observations:\", format(nrow(train_q1), big.mark = \",\"), \"\\n\")\ncat(\"Q1 Testing observations:\", format(nrow(test_q1), big.mark = \",\"), \"\\n\")\n```\n\n```{r build_q1_models}\n# Build same 5 models for Q1\nmodel1_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q1\n)\n\nmodel2_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q1\n)\n\nmodel3_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q1\n)\n\nmodel4_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q1\n)\n\nmodel5_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q1\n)\n\n# Get predictions\ntest_q1 <- test_q1 %>%\n  mutate(\n    pred1 = predict(model1_q1, newdata = test_q1),\n    pred2 = predict(model2_q1, newdata = test_q1),\n    pred3 = predict(model3_q1, newdata = test_q1),\n    pred4 = predict(model4_q1, newdata = test_q1),\n    pred5 = predict(model5_q1, newdata = test_q1)\n  )\n\n# Calculate MAE\nmae_q1 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE_Q1 = c(\n    mean(abs(test_q1$Trip_Count - test_q1$pred1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred2), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred3), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred4), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred5), na.rm = TRUE)\n  )\n)\n\ncat(\"✓ Q1 2025 models built and evaluated\\n\")\n```\n\n## 1.14 Direct Q1 vs Q3 Comparison\n\n```{r final_comparison}\n# Combine results\nmae_comparison <- mae_q3 %>%\n  left_join(mae_q1, by = \"Model\") %>%\n  mutate(\n    Q3_Better = MAE_Q3 < MAE_Q1,\n    Improvement = round((MAE_Q1 - MAE_Q3) / MAE_Q1 * 100, 1)\n  )\n\nkable(mae_comparison,\n      caption = \"Part 1 Results: Q3 2024 Summer vs Q1 2025 Winter Performance\",\n      col.names = c(\"Model\", \"Q3 MAE\\n(Summer)\", \"Q1 MAE\\n(Winter)\", \n                    \"Summer\\nBetter?\", \"% Improvement\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r viz_final_comparison}\n#| fig-width: 12\n#| fig-height: 6\n\nmae_long <- mae_comparison %>%\n  select(Model, MAE_Q3, MAE_Q1) %>%\n  pivot_longer(cols = c(MAE_Q3, MAE_Q1), names_to = \"Quarter\", values_to = \"MAE\") %>%\n  mutate(Quarter = recode(Quarter, \n                          \"MAE_Q3\" = \"Q3 2024 (Summer)\", \n                          \"MAE_Q1\" = \"Q1 2025 (Winter)\"))\n\nggplot(mae_long, aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  scale_fill_manual(values = c(\"Q3 2024 (Summer)\" = \"#08519c\", \n                                \"Q1 2025 (Winter)\" = \"#6baed6\")) +\n  labs(\n    title = \"Model Performance: Q3 2024 Summer vs Q1 2025 Winter\",\n    subtitle = \"Summer achieves lower MAE across all models despite 38% higher ridership\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Quarter\"\n  ) +\n  plotTheme +\n  theme(legend.position = \"bottom\")\n```\n\n**Part 1 Key Findings:**\n\n-   **Summer is more predictable**: Q3 achieves 10-20% lower MAE than Q1 across all models\n-   **Temporal lags dominate**: Model 2 achieves biggest improvement in both seasons\n-   **Similar improvement patterns**: Features add value consistently across seasons\n-   **Core approach generalizes**: Same model architecture works well in both winter and summer\n\n# Part 2: Error Analysis (Q3 2024 Focus)\n\nThe remainder of the analysis focuses on Q3 2024 to conduct detailed error analysis and feature engineering.\n\n## 2.1 Spatial Error Patterns\n\n```{r spatial_errors_q3}\n#| fig-width: 12\n#| fig-height: 8\n\n# Calculate errors\ntest_q3 <- test_q3 %>%\n  mutate(\n    error = Trip_Count - pred5,\n    abs_error = abs(error)\n  )\n\nstation_errors_q3 <- test_q3 %>%\n  filter(!is.na(pred5)) %>%\n  group_by(start_station, start_lat, start_lon) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    mean_error = mean(error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat), !is.na(start_lon))\n\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(data = station_errors_q3, aes(x = start_lon, y = start_lat, color = MAE),\n             size = 3, alpha = 0.7) +\n  scale_color_viridis(option = \"plasma\", name = \"MAE\\n(trips)\", direction = -1) +\n  labs(title = \"Prediction Errors by Station\", \n       subtitle = \"Higher in Center City high-demand areas\") +\n  mapTheme\n\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(data = station_errors_q3, aes(x = start_lon, y = start_lat, color = avg_demand),\n             size = 3, alpha = 0.7) +\n  scale_color_viridis(option = \"viridis\", name = \"Avg\\nDemand\", direction = -1) +\n  labs(title = \"Average Demand by Station\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme\n\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n**Spatial Finding**: Errors concentrate in Center City/University City where demand is highest.\n\n## 2.2 Temporal Error Patterns\n\n```{r temporal_errors_q3}\n#| fig-width: 12\n#| fig-height: 10\n\n# Errors by hour\nhourly_errors_q3 <- test_q3 %>%\n  group_by(hour) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    mean_error = mean(error, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\np1 <- ggplot(hourly_errors_q3, aes(x = hour)) +\n  geom_col(aes(y = MAE), fill = \"#3182bd\", alpha = 0.7) +\n  geom_line(aes(y = mean_error * 2), color = \"red\", linewidth = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Prediction Errors by Hour (Q3 2024)\",\n       subtitle = \"Blue = MAE; Red = Mean Error (×2 for scale)\",\n       x = \"Hour\", y = \"Error (trips)\") +\n  plotTheme\n\n# Errors by time of day\ntest_q3 <- test_q3 %>%\n  mutate(\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM_Rush\",\n      hour >= 10 & hour < 15 ~ \"Midday\",\n      hour >= 15 & hour <= 18 ~ \"PM_Rush\",\n      hour > 18 ~ \"Evening\"\n    ),\n    time_of_day = factor(time_of_day, \n                         levels = c(\"Overnight\", \"AM_Rush\", \"Midday\", \"PM_Rush\", \"Evening\")),\n    day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\ntemporal_errors_q3 <- test_q3 %>%\n  group_by(time_of_day, day_type) %>%\n  summarize(MAE = mean(abs_error, na.rm = TRUE), .groups = \"drop\")\n\np2 <- ggplot(temporal_errors_q3, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(title = \"Errors by Time Period (Q3 2024)\",\n       subtitle = \"Highest during weekday PM rush\",\n       x = \"Time of Day\", y = \"MAE (trips)\", fill = \"Day Type\") +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngrid.arrange(p1, p2, ncol = 1)\n```\n\n**Temporal Finding**: PM Rush on weekdays shows highest errors—the most operationally critical period.\n\n## 2.3 Equity Analysis\n\n```{r equity_analysis_q3}\nstation_errors_demo_q3 <- station_errors_q3 %>%\n  left_join(station_attributes_q3 %>% \n              select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n            by = \"start_station\") %>%\n  filter(!is.na(Med_Inc)) %>%\n  mutate(\n    pct_error = ifelse(avg_demand > 0, (MAE / avg_demand) * 100, NA),\n    income_quartile = cut(Med_Inc,\n                          breaks = quantile(Med_Inc, probs = 0:4/4, na.rm = TRUE),\n                          labels = c(\"Q1 (Lowest)\", \"Q2\", \"Q3\", \"Q4 (Highest)\"),\n                          include.lowest = TRUE)\n  )\n\nequity_summary_q3 <- station_errors_demo_q3 %>%\n  filter(!is.na(pct_error), is.finite(pct_error)) %>%\n  group_by(income_quartile) %>%\n  summarize(\n    avg_MAE = mean(MAE, na.rm = TRUE),\n    avg_pct_error = mean(pct_error, na.rm = TRUE),\n    avg_demand = mean(avg_demand, na.rm = TRUE),\n    stations = n(),\n    .groups = \"drop\"\n  )\n\nkable(equity_summary_q3,\n      caption = \"Part 2: Performance by Income Level (Q3 2024)\",\n      col.names = c(\"Income Quartile\", \"Avg MAE\", \"Avg % Error\", \"Avg Demand\", \"# Stations\"),\n      digits = c(0, 2, 1, 2, 0)) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r equity_viz_q3}\n#| fig-width: 12\n#| fig-height: 5\n\np_abs <- ggplot(equity_summary_q3, aes(x = income_quartile, y = avg_MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(avg_MAE, 2)), vjust = -0.5) +\n  labs(title = \"Absolute Errors by Income (Q3 2024)\",\n       subtitle = \"Higher in wealthier areas (reflects demand)\",\n       x = \"Income Quartile\", y = \"Avg MAE\") +\n  plotTheme\n\np_pct <- ggplot(equity_summary_q3, aes(x = income_quartile, y = avg_pct_error)) +\n  geom_col(fill = \"#6baed6\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(avg_pct_error, 1), \"%\")), vjust = -0.5) +\n  labs(title = \"Percentage Errors by Income (Q3 2024)\",\n       subtitle = \"Similar across groups - no bias\",\n       x = \"Income Quartile\", y = \"Avg % Error\") +\n  plotTheme\n\ngrid.arrange(p_abs, p_pct, ncol = 2)\n```\n\n**Part 2 Equity Finding**: No systematic bias when measured as percentage errors. Higher absolute errors in wealthier areas reflect higher demand, not worse model performance.\n\n# Part 3: Feature Engineering\n\n## 3.1 Add New Features for Q3\n\n```{r add_new_features_q3}\n# Add to complete panel\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  arrange(start_station, interval60) %>%\n  group_by(start_station) %>%\n  mutate(\n    # Feature 1: Holidays\n    july4 = ifelse(date == as.Date(\"2024-07-04\"), 1, 0),\n    labor_day = ifelse(date >= as.Date(\"2024-08-31\") & date <= as.Date(\"2024-09-02\"), 1, 0),\n    holiday = ifelse(july4 == 1 | labor_day == 1, 1, 0),\n    \n    # Feature 2: Weather conditions\n    perfect_weather = ifelse(Temperature >= 60 & Temperature <= 75 & Precipitation == 0, 1, 0),\n    too_hot = ifelse(Temperature > 85, 1, 0),\n    weekend_nice = weekend * perfect_weather,\n    \n    # Feature 3: Rolling averages\n    lag7day_avg = zoo::rollmean(Trip_Count, k = 168, fill = NA, align = \"right\"),\n    lag1week_samehour = lag(Trip_Count, 168)\n  ) %>%\n  ungroup()\n\n# Re-create train/test with new features\ntrain_q3_new <- study_panel_complete_q3 %>%\n  filter(week < 36, start_station %in% common_stations_q3) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q3_new <- study_panel_complete_q3 %>%\n  filter(week >= 36, start_station %in% common_stations_q3) %>%\n  mutate(dotw_simple = factor(dotw, \n                               levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q3_new$dotw_simple) <- contr.treatment(7)\ncontrasts(test_q3_new$dotw_simple) <- contr.treatment(7)\n```\n\n## 3.2 Model 6: Add New Features\n\n```{r model6_q3}\nmodel6_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag7day_avg + lag1week_samehour +\n    rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    holiday + perfect_weather + too_hot + weekend_nice +\n    as.factor(start_station) +\n    rush_hour * weekend,\n  data = train_q3_new\n)\n\ncat(\"Model 6 Q3: + New Features\\n\")\ncat(\"R-squared:\", round(summary(model6_q3)$r.squared, 4), \"\\n\")\n```\n\n## 3.3 Model 7: Poisson Regression\n\n```{r model7_q3}\nmodel7_q3 <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag7day_avg +\n    holiday + perfect_weather + too_hot +\n    as.factor(start_station),\n  data = train_q3_new,\n  family = poisson(link = \"log\")\n)\n\ncat(\"Model 7 Q3: Poisson Regression\\n\")\ncat(\"AIC:\", round(AIC(model7_q3), 0), \"\\n\")\n```\n\n## 3.4 Evaluate All Models\n\n```{r evaluate_all_models_q3}\n# Get predictions for new models\ntest_q3_new <- test_q3_new %>%\n  mutate(\n    pred6 = predict(model6_q3, newdata = test_q3_new),\n    pred7 = predict(model7_q3, newdata = test_q3_new, type = \"response\")\n  )\n\n# Also need predictions from original 5 models\ntest_q3_new <- test_q3_new %>%\n  mutate(\n    pred1 = predict(model1_q3, newdata = test_q3_new),\n    pred2 = predict(model2_q3, newdata = test_q3_new),\n    pred3 = predict(model3_q3, newdata = test_q3_new),\n    pred4 = predict(model4_q3, newdata = test_q3_new),\n    pred5 = predict(model5_q3, newdata = test_q3_new)\n  )\n\nmae_all_q3 <- data.frame(\n  Model = paste0(\"Model \", 1:7),\n  Description = c(\n    \"Time + Weather\",\n    \"+ Temporal Lags\",\n    \"+ Demographics\",\n    \"+ Station FE\",\n    \"+ Rush Hour Interaction\",\n    \"+ New Features\",\n    \"Poisson\"\n  ),\n  MAE = c(\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred1), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred2), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred3), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred4), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred5), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred6), na.rm = TRUE),\n    mean(abs(test_q3_new$Trip_Count - test_q3_new$pred7), na.rm = TRUE)\n  )\n) %>%\n  mutate(improvement = round((MAE[1] - MAE) / MAE[1] * 100, 1))\n\nkable(mae_all_q3,\n      caption = \"Part 3: All Models Performance (Q3 2024)\",\n      col.names = c(\"Model\", \"Description\", \"MAE (trips)\", \"% Improvement\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n```{r viz_all_models_q3}\n#| fig-width: 10\n#| fig-height: 6\n\nggplot(mae_all_q3, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 3)), vjust = -0.5, size = 3) +\n  geom_hline(yintercept = mae_all_q3$MAE[2], linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"All Models Performance - Q3 2024\",\n    subtitle = \"Model 2 (temporal lags) captures most improvement; additional features add minimal value\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\",\n    caption = \"Dashed line = Model 2 (temporal lags)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Part 3 Results**: Temporal lags (Model 2) capture most of the achievable improvement. New features and Poisson regression add only marginal gains. **Finding: Simple temporal lags are the key to performance.**\n\n# Part 4: Critical Reflection\n\n## 4.1 Operational Implications\n\n```{r operational_metrics_q3}\navg_demand_q3 <- mean(test_q3_new$Trip_Count, na.rm = TRUE)\nmae_best_q3 <- min(mae_all_q3$MAE)\nmedian_demand_q3 <- median(test_q3_new$Trip_Count, na.rm = TRUE)\nzero_pct_q3 <- mean(test_q3_new$Trip_Count == 0, na.rm = TRUE) * 100\n\ncat(\"Q3 2024 Operational Metrics:\\n\")\ncat(\"Average demand:\", round(avg_demand_q3, 2), \"trips/hour\\n\")\ncat(\"Median demand:\", median_demand_q3, \"trips/hour\\n\")\ncat(\"Zero observations:\", round(zero_pct_q3, 1), \"%\\n\")\ncat(\"Best MAE:\", round(mae_best_q3, 3), \"trips/hour\\n\")\ncat(\"MAE as % of mean:\", round((mae_best_q3/avg_demand_q3)*100, 1), \"%\\n\")\n```\n\n**Deployment Recommendation:**\n\nYES, conditionally. Deploy for regional rebalancing strategy and medium-confidence routing. Combine with real-time dock data, weather forecasts, and human oversight. Don't use alone for critical AM rush decisions at busiest stations. Requires quarterly retraining with recent data.\n\n## 4.2 Equity Considerations\n\n**Finding**: No systematic bias when measured as percentage errors. All income quartiles show similar error rates.\n\n**Potential Concerns**: Spatial coverage bias, data feedback loops, supply-driven demand.\n\n**Recommended Safeguards**: Equity audit dashboard, minimum service standards, proactive over-supply in underserved areas, community feedback integration.\n\n## 4.3 Model Limitations\n\n**Missing patterns**: Special events, weather forecasts (not actuals), supply constraints, academic calendar impacts, infrastructure changes.\n\n**Violated assumptions**: Past predicts future, station independence, no capacity constraints, normal operations.\n\n**Improvements needed**: - High priority: Weather forecasts, zero-inflated models, event calendar API - Medium priority: Station-to-station flows, real-time features, spatial features - Lower priority: Ensemble methods, user-level modeling\n\n# Conclusion\n\nThis analysis demonstrates that **seasonal stability matters more than absolute volume for prediction accuracy**. Q3 summer achieves 10-20% lower MAE than Q1 winter despite 38% higher ridership.\n\n**Key Findings:**\n\n1.  **Seasonal Performance**: Summer's stable patterns enable better predictions than winter's volatile weather\n2.  **Model Architecture**: Simple temporal lags capture 95% of achievable improvement\n3.  **Feature Engineering**: Complex features add minimal value beyond basic lags\n4.  **Equity**: No systematic bias across income levels when measured appropriately\n5.  **Generalizability**: Core modeling approach works well across both seasons\n\n**Operational Recommendation**: Conditionally deploy as decision support for regional rebalancing, combined with real-time data and human oversight.\n\n**Research Contribution**: Demonstrates that stability enables prediction more than volume does, with important implications for bike share operations and predictive modeling broadly.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"embed-resources":true,"output-file":"assignment_5.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Assignment 5: Space-Time Prediction of Bike Share Demand","subtitle":"Philadelphia Indego Q3 2024 Analysis","author":"Kavana Raju","date":"today","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}