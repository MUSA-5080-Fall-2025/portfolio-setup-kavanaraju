{"title":"Space-Time Prediction","markdown":{"yaml":{"title":"Space-Time Prediction","subtitle":"Bike Share Demand Forecasting with Panel Data & Temporal Lags","author":"Dr. Elizabeth Delmelle","date":"November 17, 2025","format":{"revealjs":{"theme":"simple","slide-number":true,"chalkboard":true,"preview-links":"auto","css":"custom.css"}}},"headingText":"Part 1: The Space-Time Challenge","containsRefs":false,"markdown":"\n\n\n---\n\n## Real-World Problem: Bike Rebalancing\n\n**The dreaded empty bikeshare station:**\n\n![](images/bike_share.png)\n\n:::{.incremental}\n- 7-9 AM: Residential areas empty out → Downtown fills up\n- 11 AM-2 PM: Lunch rush redistributes bikes\n- 4-6 PM: Reverse commute → Downtown empties\n- **Challenge:** How do we get bikes where they'll be needed *before* demand hits?\n:::\n\n---\n\n## Why This Matters for Policy\n\n**Operational question:** \n\n> \"At 6:00 AM, which stations will run out of bikes by 8:00 AM?\"\n\n:::{.incremental}\n- **Can't wait** for stations to empty before rebalancing\n- **Must predict** demand 1-2 hours ahead\n- **Need to optimize** truck routes based on forecasts\n:::\n\n:::{.fragment}\n**Your job:** Build a system that predicts demand in space AND time\n:::\n\n---\n\n## What Makes This Different? {.smaller}\n\n**Previous weeks (Weeks 5-7):**\n\n- Cross-sectional prediction: predict 2024 house prices\n- Spatial features: crimes within 500ft, distance to downtown\n- Spatial fixed effects: neighborhood baseline differences\n\n**This week:**\n\n- Panel data: Same stations observed over time\n- Temporal features: What happened last hour?\n- Space-time interaction: Different patterns by location AND time\n\n\n---\n\n# Part 2: Understanding Panel Data\n\n---\n\n## What is Panel Data?\n\n**Definition:** Data that follows the same units over multiple time periods\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Cross-sectional data:**\n\n- Each row = one observation\n- House prices in 2024\n- One snapshot in time\n:::\n\n:::{.column width=\"50%\"}\n**Panel data:**\n\n- Each row = unit × time period\n- Station × hour combinations\n- Repeated observations\n:::\n:::\n\n\n---\n\n## Example: Bike Share Panel\n\n```{r eval=FALSE, echo=TRUE}\n# Cross-sectional: One row per station\nStation_A, May_2018, 4,250_total_trips\nStation_B, May_2018, 2,100_total_trips\n\n# Panel: One row per station-hour\nStation_A, May_1_08:00, 12_trips\nStation_A, May_1_09:00, 15_trips\nStation_A, May_1_10:00,  8_trips\nStation_B, May_1_08:00,  5_trips\nStation_B, May_1_09:00,  7_trips\n```\n\n:::{.fragment}\n**Key insight:** Now we can see how demand changes WITHIN stations over time\n:::\n\n---\n\n## Panel Data Structure {.smaller}\n\n| Station ID | Date-Hour | Trip Count | Temperature | Day of Week |\n|------------|-----------|------------|-------------|-------------|\n| 1 | 2018-05-01 08:00 | 12 | 65°F | Tuesday |\n| 1 | 2018-05-01 09:00 | 15 | 67°F | Tuesday |\n| 1 | 2018-05-01 10:00 | 8 | 69°F | Tuesday |\n| 2 | 2018-05-01 08:00 | 5 | 65°F | Tuesday |\n| 2 | 2018-05-01 09:00 | 7 | 67°F | Tuesday |\n\n:::{.fragment}\n**Each row** = station-hour observation with features and outcome\n:::\n\n---\n\n## Why Panel Data for Bike Share? {.smaller}\n\n**Station-specific baselines:**\n\n- Station A (downtown): High demand during work hours\n- Station B (residential): High demand mornings/evenings\n- Station C (tourist area): High demand weekends\n\n**Time-based patterns:**\n\n- Rush hour peaks\n- Weekend vs. weekday differences\n- Weather effects\n- Holiday impacts\n\n:::{.fragment}\n**Panel structure** lets us capture BOTH station differences AND time patterns\n:::\n\n---\n\n# Part 3: Binning Data into Time Intervals\n\n---\n\n## Why Bin the Data?\n\n**Raw trip data:**\n\n```\nTrip 1: Started at 8:05:23 AM\nTrip 2: Started at 8:07:41 AM\nTrip 3: Started at 8:15:12 AM\nTrip 4: Started at 8:23:08 AM\n```\n\n:::{.incremental}\n- **Problem:** Every trip starts at a unique timestamp\n- **Can't aggregate** or find patterns at the second-level\n- **Solution:** Group trips into uniform time intervals (bins)\n:::\n\n---\n\n## Binning in Practice\n\n**Hourly binning:**\n\n```{r eval=FALSE, echo=TRUE}\n# All trips between 8:00-8:59 AM → \"08:00\" bin\ndat <- dat %>%\n  mutate(interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"))\n```\n\n**Result:**\n\n- Trip at 8:05 AM → 08:00 bin\n- Trip at 8:23 AM → 08:00 bin\n- Trip at 9:07 AM → 09:00 bin\n\n:::{.fragment}\n**Now we can count:** \"Station A had 15 trips in the 8:00 AM hour\"\n:::\n\n---\n\n## Alternative: 15-Minute Bins {.smaller}\n\n**Finer temporal resolution:**\n\n```{r eval=FALSE, echo=TRUE}\ndat <- dat %>%\n  mutate(interval15 = floor_date(ymd_hms(start_time), unit = \"15 mins\"))\n```\n\n**Trade-offs:**\n\n- (+) More granular patterns (peak vs. off-peak within hour)\n- (+) Better for short-term forecasting\n- (-) More sparse data (some 15-min periods have zero trips)\n- (-) More complex models\n\n:::{.fragment}\n**Today:** We'll use hourly bins for simplicity\n:::\n\n---\n\n## Extracting Time Features\n\n```{r eval=FALSE, echo=TRUE}\ndat <- dat %>%\n  mutate(\n    interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"),\n    week = week(interval60),           # Week of year (1-52)\n    dotw = wday(interval60, label=TRUE), # Day of week (Mon, Tue, ...)\n    hour = hour(interval60)            # Hour of day (0-23)\n  )\n```\n\n:::{.fragment}\n**These become predictors:**\n\n- Rush hour indicator: `hour %in% c(7,8,9, 17,18,19)`\n- Weekend indicator: `dotw %in% c(\"Sat\", \"Sun\")`\n- Holiday effects: Memorial Day weekend\n:::\n\n---\n\n# Part 4: Temporal Lags\n\n---\n\n## What Are Temporal Lags?\n\n**Core idea:** Past demand predicts future demand\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Spatial features (Week 6):**\n\n- Crimes within 500ft\n- Distance to downtown\n- Nearby amenities\n:::\n\n:::{.column width=\"50%\"}\n**Temporal features (This week):**\n\n- Demand 1 hour ago\n- Demand 2 hours ago\n- Demand yesterday (24 hours ago)\n:::\n:::\n\n:::{.fragment}\n**Intuition:** If there were 15 trips at 8 AM, there will probably be ~15 trips at 9 AM\n:::\n\n---\n\n## Creating Lag Variables\n\n```{r eval=FALSE, echo=TRUE}\nstudy.panel <- study.panel %>%\n  arrange(from_station_id, interval60) %>%  # Sort by station, then time\n  group_by(from_station_id) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),    # Previous hour\n    lag2Hours = lag(Trip_Count, 2),   # 2 hours ago\n    lag3Hours = lag(Trip_Count, 3),   # 3 hours ago\n    lag12Hours = lag(Trip_Count, 12), # 12 hours ago\n    lag1day = lag(Trip_Count, 24)     # Yesterday same time\n  ) %>%\n  ungroup()\n```\n\n:::{.fragment}\n**Important:** Lags are calculated WITHIN each station\n:::\n\n---\n\n## Lag Variable Example {.smaller}\n\n**Station A on Monday:**\n\n| Time | Trip Count | lag1Hour | lag12Hours | lag1day |\n|------|------------|----------|------------|---------|\n| Mon 07:00 | 5 | NA | NA | NA |\n| Mon 08:00 | 12 | 5 | NA | NA |\n| Mon 09:00 | 15 | 12 | NA | NA |\n| Mon 19:00 | 8 | 10 | 5 | NA |\n| Tue 08:00 | 14 | 6 | 10 | 12 |\n\n:::{.fragment}\n**Interpretation:** At Tue 08:00, demand was 14. Same time yesterday (Mon 08:00) was 12.\n:::\n\n---\n\n## Why Multiple Lags?\n\n**Different lags capture different patterns:**\n\n:::{.incremental}\n- **lag1Hour:** Short-term persistence (smooth demand changes)\n- **lag3Hours:** Medium-term trends (morning rush building)\n- **lag12Hours:** Half-day cycle (AM vs. PM patterns)\n- **lag1day (24 hours):** Daily periodicity (same time yesterday)\n:::\n\n:::{.fragment}\n**Model will learn** which lags are most predictive for each station/time combination\n:::\n\n---\n\n## Connection to Week 6: Spatial Features\n\n**Remember Week 6?**\n\n```{r eval=FALSE, echo=TRUE}\n# Spatial features we created:\nboston.sf <- boston.sf %>%\n  mutate(\n    crimes_500ft = ...,        # Count crimes nearby\n    crime_nn3 = ...,           # Average crime at 3 nearest neighbors\n    dist_downtown = ...        # Distance to downtown\n  )\n```\n\n:::{.fragment}\n**This week is the same concept:**\n\n```{r eval=FALSE, echo=TRUE}\n# Temporal features we're creating:\nstudy.panel <- study.panel %>%\n  mutate(\n    lag1Hour = ...,            # Demand at nearby TIME\n    lag1day = ...,             # Demand at similar TIME\n  )\n```\n:::\n\n---\n\n# Part 5: Creating the Space-Time Panel\n\n---\n\n## The Challenge: Missing Observations\n\n**Problem:** Not every station has trips every hour\n\n```{r eval=FALSE, echo=TRUE}\n# Data we have (sparse):\nStation_A, May_1_08:00, 12_trips  ✓\nStation_A, May_1_09:00,  0_trips  ✗ (missing row!)\nStation_A, May_1_10:00,  8_trips  ✓\n```\n\n:::{.fragment}\n**But we NEED:**\n```{r eval=FALSE, echo=TRUE}\n# Complete panel (every station-hour combination):\nStation_A, May_1_08:00, 12_trips\nStation_A, May_1_09:00,  0_trips  ← Must exist with 0!\nStation_A, May_1_10:00,  8_trips\n```\n:::\n\n:::{.fragment}\n**Why?** Lag calculations break if rows are missing\n:::\n\n---\n\n## Creating a Complete Panel\n\n**Step 1:** Calculate all possible combinations\n\n```{r eval=FALSE, echo=TRUE}\n# How many unique stations?\nlength(unique(dat_census$from_station_id))  # e.g., 600 stations\n\n# How many unique hours?\nlength(unique(dat_census$interval60))       # e.g., 744 hours (31 days)\n\n# Total combinations needed:\n600 stations × 744 hours = 446,400 rows\n```\n\n:::{.fragment}\n**Reality check:** Do we have 446,400 rows? Probably not!\n:::\n\n---\n\n## expand.grid() to the Rescue\n\n```{r eval=FALSE, echo=TRUE}\n# Create every possible station-hour combination\nstudy.panel <- expand.grid(\n  interval60 = unique(dat_census$interval60),\n  from_station_id = unique(dat_census$from_station_id)\n)\n\n# Join to actual trip counts\nstudy.panel <- study.panel %>%\n  left_join(\n    dat_census %>% \n      group_by(interval60, from_station_id) %>%\n      summarize(Trip_Count = n()),\n    by = c(\"interval60\", \"from_station_id\")\n  ) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0))  # Fill missing with 0\n```\n\n:::{.fragment}\n**Now every station-hour exists,** even if Trip_Count = 0\n:::\n\n---\n\n## Joining Station Attributes\n\n**Each station has fixed characteristics:**\n\n```{r eval=FALSE, echo=TRUE}\n# Station location, demographics from census\nstation_data <- dat_census %>%\n  group_by(from_station_id) %>%\n  summarize(\n    from_latitude = first(from_latitude),\n    from_longitude = first(from_longitude),\n    Med_Inc = first(Med_Inc),\n    Percent_White = first(Percent_White),\n    # ... other demographics\n  )\n\n# Join to panel\nstudy.panel <- study.panel %>%\n  left_join(station_data, by = \"from_station_id\")\n```\n\n:::{.fragment}\n**Result:** Every row has station location + demographics\n:::\n\n---\n\n## Adding Time-Varying Features\n\n**Some features change over time:**\n\n```{r eval=FALSE, echo=TRUE}\n# Weather changes hourly\nweather <- weather_data %>%\n  select(interval60, Temperature, Precipitation)\n\nstudy.panel <- study.panel %>%\n  left_join(weather, by = \"interval60\")\n\n# Create time features\nstudy.panel <- study.panel %>%\n  mutate(\n    week = week(interval60),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0)\n  )\n```\n\n---\n\n## Final Panel Structure\n\n**What we have now:**\n\n- Every station-hour combination exists\n- Trip counts (including zeros)\n- Station fixed attributes (location, demographics)\n- Time-varying features (weather, day of week, hour)\n- Temporal lags (lag1Hour, lag1day, etc.)\n\n:::{.fragment}\n**Ready to model!** But first... temporal validation\n:::\n\n---\n\n# Part 6: Temporal Validation\n\n---\n\n## Critical Callback: Week 7 Discussion {.smaller}\n\n**Remember when we talked about spatial lag models?**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Spatial Lag Model (SAR):**\n\n$$Y_i = \\rho \\sum_j w_{ij}Y_j + \\beta X_i + \\varepsilon$$\n\n**Why NOT for prediction:**\n\n- Circular dependency (Y depends on Y)\n- Can't predict new areas\n- Need neighbors' outcomes\n:::\n\n:::{.column width=\"50%\"}\n**Our Approach Today:**\n\n$$Y_{it} = \\alpha_i + \\beta_1 X_{it} + \\beta_2 Y_{i,t-1} + \\varepsilon_{it}$$\n\n**Station fixed effects + temporal lags:**\n\n- $\\alpha_i$ = Station baseline\n- $Y_{i,t-1}$ = Past demand (not neighbors!)\n- Can forecast future periods\n:::\n:::\n\n:::{.fragment}\n**Key difference:** We use PAST outcomes as features, not NEIGHBOR outcomes\n:::\n\n---\n\n## The Temporal Validation Problem\n\n**You CANNOT train on the future to predict the past!**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n** WRONG approach:**\n```{r eval=FALSE, echo=TRUE}\n# Train on Weeks 3-4\ntrain <- data %>% \n  filter(week >= 19)\n\n# Test on Weeks 1-2\ntest <- data %>% \n  filter(week < 19)\n```\n\n**This is predicting the past using the future!**\n:::\n\n:::{.column width=\"50%\"}\n** CORRECT approach:**\n```{r eval=FALSE, echo=TRUE}\n# Train on Weeks 1-2\ntrain <- data %>% \n  filter(week < 19)\n\n# Test on Weeks 3-4\ntest <- data %>% \n  filter(week >= 19)\n```\n\n**This is predicting the future using the past!**\n:::\n:::\n\n---\n\n## Why This Matters {.center}\n\n**Real-world scenario:**\n\n> It's May 15, 2018. You need to forecast demand for May 16-31.\n\n:::{.incremental}\n- You have data from: May 1-15 ✓\n- You don't have data from: May 16-31 (it hasn't happened yet!)\n- **You must train on May 1-15 and test on May 16-31**\n:::\n\n---\n\n## Temporal Train/Test Split\n\n```{r eval=FALSE, echo=TRUE}\n# Split by time (week of year)\ntrain <- study.panel %>%\n  filter(week < 19)  # Weeks 1-2 of May (early period)\n\ntest <- study.panel %>%\n  filter(week >= 19) # Weeks 3-4 of May (later period)\n\n# Fit models on training data only\nmodel <- lm(Trip_Count ~ lag1Hour + lag1day + Temperature + weekend, \n            data = train)\n\n# Evaluate on test data\npredictions <- predict(model, newdata = test)\n```\n\n:::{.fragment}\n**This mirrors operational deployment:** Predict tomorrow using yesterday's patterns\n:::\n\n---\n\n## Comparison to Spatial CV {.smaller}\n\n**Week 7: Spatial cross-validation**\n\n- Prevented spatial leakage\n- Left out entire neighborhoods for testing\n- Ensured model generalizes to new areas\n\n**This week: Temporal validation**\n\n- Prevents temporal leakage\n- Holds out future time periods for testing\n- Ensures model generalizes to future\n\n:::{.fragment}\n**Both are about out-of-sample generalization!**\n:::\n\n---\n\n# Part 7: Building Models\n\n---\n\n## Model Progression Strategy\n\n**We'll build 5 models, adding complexity:**\n\n1. **Baseline:** Time + Weather only\n2. **+ Temporal lags:** Add lag1Hour, lag1day\n3. **+ Spatial features:** Add demographics, location\n4. **+ Station fixed effects:** Control for station-specific baselines\n5. **+ Holiday effects:** Account for Memorial Day weekend\n\n:::{.fragment}\n**Goal:** See which features improve prediction accuracy\n:::\n\n---\n\n## Model 1: Baseline (Time + Weather)\n\n```{r eval=FALSE, echo=TRUE}\nmodel1 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation,\n  data = train\n)\n```\n\n**Predictors:**\n\n- `hour`: Hour of day (0-23)\n- `dotw`: Day of week (Mon, Tue, ..., Sun)\n- `Temperature`: Hourly temperature\n- `Precipitation`: Rainfall amount\n\n:::{.fragment}\n**Captures:** Daily and weekly cycles, weather effects\n:::\n\n---\n\n## Model 2: + Temporal Lags\n\n```{r eval=FALSE, echo=TRUE}\nmodel2 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n```\n\n**New predictors:**\n\n- `lag1Hour`: Demand 1 hour ago\n- `lag3Hours`: Demand 3 hours ago\n- `lag1day`: Demand 24 hours ago\n\n:::{.fragment}\n**Hypothesis:** Past demand predicts future demand\n:::\n\n---\n\n## Model 3: + Spatial Features\n\n```{r eval=FALSE, echo=TRUE}\nmodel3 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White,\n  data = train\n)\n```\n\n**New predictors:**\n\n- Demographics from census (station location characteristics)\n- These are **fixed over time** but vary across stations\n\n:::{.fragment}\n**Captures:** Neighborhood effects on demand\n:::\n\n---\n\n## Model 4: + Station Fixed Effects\n\n```{r eval=FALSE, echo=TRUE}\nmodel4 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White +\n               as.factor(from_station_id),  # Station dummies\n  data = train\n)\n```\n\n**Station fixed effects:**\n\n- One dummy variable per station\n- Captures station-specific baseline demand\n- Controls for unobserved station characteristics\n\n:::{.fragment}\n**Why?** Some stations are just busier than others!\n:::\n\n---\n\n## Model 5: + Holiday Effects\n\n```{r eval=FALSE, echo=TRUE}\nmodel5 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White +\n               as.factor(from_station_id) +\n               holiday + holiday_lag1 + holiday_lag2,  # Holiday indicators\n  data = train\n)\n```\n\n**Memorial Day weekend (May 28-29, 2018):**\n\n- `holiday`: Current hour is during holiday\n- `holiday_lag1`: 1 hour into holiday\n- `holiday_lag2`: 2 hours into holiday\n\n:::{.fragment}\n**Captures:** Disruption to normal patterns during holidays\n:::\n\n---\n\n## Evaluating Models: MAE {.smaller}\n\n**Mean Absolute Error:**\n\n$$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n\n**Interpretation:**\n\n- \"On average, our predictions are off by X trips\"\n- Lower MAE = better predictions\n- **Same units as outcome** (unlike RMSE that emphasizes large errors)\n\n:::{.fragment}\n**Example:** MAE = 5 means predictions are typically off by ±5 trips\n:::\n\n---\n\n## Model Comparison (Hypothetical Results) {.smaller}\n\n| Model | MAE (Test Set) | What Improved? |\n|-------|----------------|----------------|\n| 1. Baseline | 8.2 trips | — |\n| 2. + Lags | 6.5 trips | Temporal persistence |\n| 3. + Demographics | 6.1 trips | Neighborhood effects |\n| 4. + Fixed Effects | 5.3 trips | Station baselines |\n| 5. + Holidays | 5.1 trips | Disruption events |\n\n:::{.fragment}\n**Biggest improvement:** Adding temporal lags (8.2 → 6.5)\n:::\n\n---\n\n# Part 8: Space-Time Error Analysis\n\n---\n\n## Where Are We Wrong?\n\n**Not all errors are equal!**\n\n:::{.incremental}\n- High MAE at high-volume stations might be acceptable\n- High MAE at low-volume stations might indicate systematic bias\n- Spatial patterns in errors suggest missing features\n- Temporal patterns suggest missing time dynamics\n:::\n\n:::{.fragment}\n**Question for operations:** When do prediction errors cause bikes to run out?\n:::\n\n---\n\n## Spatial Error Patterns\n\n**Map errors by station:**\n\n![](images/map_error.png)\n\n---\n\n## Temporal Error Patterns\n\n**When are we most wrong?**\n\n![](images/error2.png)\n\n---\n\n## Observed vs. Predicted\n\n**Scatterplot by time of day:**\n\n![](images/errors.png)\n\n:::{.fragment}\n**Diagonal red line:** Perfect predictions\n\n**Blue line:** Our actual performance\n:::\n\n---\n\n## Common Error Patterns\n\n**What you might see:**\n\n:::{.incremental}\n- **Underpredicting peaks:** Missing high-demand periods (rush hour)\n- **Weekend vs. weekday differences:** Holiday patterns not fully captured\n- **Spatial clustering:** Errors concentrated in certain neighborhoods\n  - Waterfront (leisure rides?)\n  - Downtown (tourist activity?)\n  - Transit hubs (commuter substitution?)\n:::\n\n:::{.fragment}\n**Critical question:** Are errors related to demographics? (Equity concern!)\n:::\n\n---\n\n## Errors and Demographics\n\n```{r eval=FALSE, echo=TRUE}\n# Join errors back to demographic data\nstation_errors <- station_errors %>%\n  left_join(\n    dat_census %>% \n      distinct(from_station_id, Med_Inc, \n               Percent_Taking_Public_Trans, Percent_White),\n    by = \"from_station_id\"\n  )\n\n# Plot relationships\nstation_errors %>%\n  pivot_longer(cols = c(Med_Inc, Percent_Taking_Public_Trans, \n                        Percent_White),\n               names_to = \"variable\", values_to = \"value\") %>%\n  ggplot(aes(x = value, y = MAE)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~variable, scales = \"free_x\")\n```\n\n---\n\n# Part 9: Policy Implications\n\n---\n\n## Interpreting Results for Operations {.smaller}\n\n**For a bike rebalancing system:**\n\n:::{.incremental}\n1. **Prediction accuracy matters most at high-volume stations**\n   - Running out of bikes downtown causes more complaints\n   - But: Is this equitable?\n\n2. **Temporal patterns reveal operational windows**\n   - Rebalance during overnight hours (low demand)\n   - Pre-position bikes before AM rush\n\n3. **Spatial patterns suggest infrastructure gaps**\n   - Persistent errors in certain neighborhoods\n   - Maybe add more stations? Increase capacity?\n:::\n\n---\n\n## The Equity Question\n\n**Who benefits from accurate predictions?**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Higher accuracy in:**\n\n- Downtown stations\n- High-income neighborhoods\n- Tourist areas\n- Transit hubs\n:::\n\n:::{.column width=\"50%\"}\n**Lower accuracy in:**\n\n- Residential periphery\n- Lower-income areas\n- Newer stations\n- Less transit access\n:::\n:::\n\n:::{.fragment}\n**Critical analysis:** Are we reinforcing unequal service quality?\n:::\n\n---\n\n## When Should We Deploy This?\n\n**Questions to consider:**\n\n:::{.incremental}\n- Is MAE = 5 trips \"good enough\" for operations?\n- What are consequences of underpredicting by 10 trips?\n- Do prediction errors disproportionately affect certain groups?\n- What feedback loops might emerge?\n  - Poor predictions → bikes not available → people stop using → even less data\n:::\n\n---\n\n## Next Steps to Improve {.smaller}\n\n**What could reduce errors?** \n\n:::{.incremental}\n1. **More temporal features:**\n   - Precipitation *forecast* (not just current)\n   - Event calendars (concerts, sports games)\n   - School schedules\n\n2. **More spatial features:**\n   - Points of interest (offices, restaurants, parks)\n   - Transit service frequency\n   - Bike lane connectivity\n\n3. **Better model specification:**\n   - Interactions (e.g., `weekend * hour`)\n   - Non-linear effects (splines for time of day)\n   - Different models for different station types\n:::\n\n---\n\n# Part 10: Connection to Your Work\n\n\n---\n\n\n## When Else Would You Use Panel Data?\n\n**Common policy applications:**\n\n:::{.incremental}\n- **Transportation:** Transit ridership over time\n- **Public safety:** Crime patterns by beat over months\n- **Housing:** Rent changes in neighborhoods over years\n- **Health:** Disease incidence by zip code over weeks\n- **Education:** School performance over academic years\n- **Environment:** Air quality at monitoring sites over days\n:::\n\n:::{.fragment}\n**Anytime you have:** Same units observed repeatedly over time\n:::\n\n---\n\n# Lab Time!\n\n---\n\n## Today's Lab Exercise {.smaller}\n\n**Your task:** Build space-time models for Chicago bike share\n\n**Working through the code:**\n\n1. Load and explore data (10 min)\n2. Create panel structure with `expand.grid()` (15 min)\n3. Generate temporal lags (10 min)\n4. Build multiple models (20 min)\n5. Compare model performance (15 min)\n6. Analyze error patterns in space and time (20 min)\n\n**Discussion questions:**\n\n- Why do certain time periods have higher errors?\n- Which demographic characteristics predict higher errors?\n- How would you improve the model?\n- Should this system be deployed? Under what conditions?\n\n---\n\n## Code Walk-Through Preview\n\n**Key functions you'll use:**\n\n```{r eval=FALSE, echo=TRUE}\n# 1. Binning time\nfloor_date(datetime, unit = \"hour\")\n\n# 2. Creating complete panel\nexpand.grid(station = stations, time = times)\n\n# 3. Temporal lags\ngroup_by(station_id) %>% mutate(lag1 = lag(outcome, 1))\n\n# 4. Fixed effects\nlm(y ~ x + as.factor(station_id))\n\n# 5. Evaluation\nMAE = mean(abs(observed - predicted))\n```\n\n---\n\n## Getting Started\n\n**Open the lab file:** `week11_bike_share_lab.Rmd`\n\n**Work in groups of 2-3**\n\n**I'll circulate to help with:**\n\n- Data structure questions\n- Lag variable confusion\n- Fixed effects interpretation\n- Visualization challenges\n\n**Take your time** - this is complex material!\n\n---\n\n## Key Takeaways {.center}\n\n:::{.incremental}\n1. **Panel data** = same units observed over time\n2. **Temporal lags** capture demand persistence\n3. **Train on past → test on future** for temporal validation\n4. **Station fixed effects** control for baseline differences\n5. **Space-time errors** reveal both spatial and temporal patterns\n6. **Policy question:** When is \"good enough\" actually good enough?\n7. **Equity concern:** Do errors disproportionately affect certain groups?\n:::\n\n---\n\n","srcMarkdownNoYaml":"\n\n# Part 1: The Space-Time Challenge\n\n---\n\n## Real-World Problem: Bike Rebalancing\n\n**The dreaded empty bikeshare station:**\n\n![](images/bike_share.png)\n\n:::{.incremental}\n- 7-9 AM: Residential areas empty out → Downtown fills up\n- 11 AM-2 PM: Lunch rush redistributes bikes\n- 4-6 PM: Reverse commute → Downtown empties\n- **Challenge:** How do we get bikes where they'll be needed *before* demand hits?\n:::\n\n---\n\n## Why This Matters for Policy\n\n**Operational question:** \n\n> \"At 6:00 AM, which stations will run out of bikes by 8:00 AM?\"\n\n:::{.incremental}\n- **Can't wait** for stations to empty before rebalancing\n- **Must predict** demand 1-2 hours ahead\n- **Need to optimize** truck routes based on forecasts\n:::\n\n:::{.fragment}\n**Your job:** Build a system that predicts demand in space AND time\n:::\n\n---\n\n## What Makes This Different? {.smaller}\n\n**Previous weeks (Weeks 5-7):**\n\n- Cross-sectional prediction: predict 2024 house prices\n- Spatial features: crimes within 500ft, distance to downtown\n- Spatial fixed effects: neighborhood baseline differences\n\n**This week:**\n\n- Panel data: Same stations observed over time\n- Temporal features: What happened last hour?\n- Space-time interaction: Different patterns by location AND time\n\n\n---\n\n# Part 2: Understanding Panel Data\n\n---\n\n## What is Panel Data?\n\n**Definition:** Data that follows the same units over multiple time periods\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Cross-sectional data:**\n\n- Each row = one observation\n- House prices in 2024\n- One snapshot in time\n:::\n\n:::{.column width=\"50%\"}\n**Panel data:**\n\n- Each row = unit × time period\n- Station × hour combinations\n- Repeated observations\n:::\n:::\n\n\n---\n\n## Example: Bike Share Panel\n\n```{r eval=FALSE, echo=TRUE}\n# Cross-sectional: One row per station\nStation_A, May_2018, 4,250_total_trips\nStation_B, May_2018, 2,100_total_trips\n\n# Panel: One row per station-hour\nStation_A, May_1_08:00, 12_trips\nStation_A, May_1_09:00, 15_trips\nStation_A, May_1_10:00,  8_trips\nStation_B, May_1_08:00,  5_trips\nStation_B, May_1_09:00,  7_trips\n```\n\n:::{.fragment}\n**Key insight:** Now we can see how demand changes WITHIN stations over time\n:::\n\n---\n\n## Panel Data Structure {.smaller}\n\n| Station ID | Date-Hour | Trip Count | Temperature | Day of Week |\n|------------|-----------|------------|-------------|-------------|\n| 1 | 2018-05-01 08:00 | 12 | 65°F | Tuesday |\n| 1 | 2018-05-01 09:00 | 15 | 67°F | Tuesday |\n| 1 | 2018-05-01 10:00 | 8 | 69°F | Tuesday |\n| 2 | 2018-05-01 08:00 | 5 | 65°F | Tuesday |\n| 2 | 2018-05-01 09:00 | 7 | 67°F | Tuesday |\n\n:::{.fragment}\n**Each row** = station-hour observation with features and outcome\n:::\n\n---\n\n## Why Panel Data for Bike Share? {.smaller}\n\n**Station-specific baselines:**\n\n- Station A (downtown): High demand during work hours\n- Station B (residential): High demand mornings/evenings\n- Station C (tourist area): High demand weekends\n\n**Time-based patterns:**\n\n- Rush hour peaks\n- Weekend vs. weekday differences\n- Weather effects\n- Holiday impacts\n\n:::{.fragment}\n**Panel structure** lets us capture BOTH station differences AND time patterns\n:::\n\n---\n\n# Part 3: Binning Data into Time Intervals\n\n---\n\n## Why Bin the Data?\n\n**Raw trip data:**\n\n```\nTrip 1: Started at 8:05:23 AM\nTrip 2: Started at 8:07:41 AM\nTrip 3: Started at 8:15:12 AM\nTrip 4: Started at 8:23:08 AM\n```\n\n:::{.incremental}\n- **Problem:** Every trip starts at a unique timestamp\n- **Can't aggregate** or find patterns at the second-level\n- **Solution:** Group trips into uniform time intervals (bins)\n:::\n\n---\n\n## Binning in Practice\n\n**Hourly binning:**\n\n```{r eval=FALSE, echo=TRUE}\n# All trips between 8:00-8:59 AM → \"08:00\" bin\ndat <- dat %>%\n  mutate(interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"))\n```\n\n**Result:**\n\n- Trip at 8:05 AM → 08:00 bin\n- Trip at 8:23 AM → 08:00 bin\n- Trip at 9:07 AM → 09:00 bin\n\n:::{.fragment}\n**Now we can count:** \"Station A had 15 trips in the 8:00 AM hour\"\n:::\n\n---\n\n## Alternative: 15-Minute Bins {.smaller}\n\n**Finer temporal resolution:**\n\n```{r eval=FALSE, echo=TRUE}\ndat <- dat %>%\n  mutate(interval15 = floor_date(ymd_hms(start_time), unit = \"15 mins\"))\n```\n\n**Trade-offs:**\n\n- (+) More granular patterns (peak vs. off-peak within hour)\n- (+) Better for short-term forecasting\n- (-) More sparse data (some 15-min periods have zero trips)\n- (-) More complex models\n\n:::{.fragment}\n**Today:** We'll use hourly bins for simplicity\n:::\n\n---\n\n## Extracting Time Features\n\n```{r eval=FALSE, echo=TRUE}\ndat <- dat %>%\n  mutate(\n    interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"),\n    week = week(interval60),           # Week of year (1-52)\n    dotw = wday(interval60, label=TRUE), # Day of week (Mon, Tue, ...)\n    hour = hour(interval60)            # Hour of day (0-23)\n  )\n```\n\n:::{.fragment}\n**These become predictors:**\n\n- Rush hour indicator: `hour %in% c(7,8,9, 17,18,19)`\n- Weekend indicator: `dotw %in% c(\"Sat\", \"Sun\")`\n- Holiday effects: Memorial Day weekend\n:::\n\n---\n\n# Part 4: Temporal Lags\n\n---\n\n## What Are Temporal Lags?\n\n**Core idea:** Past demand predicts future demand\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Spatial features (Week 6):**\n\n- Crimes within 500ft\n- Distance to downtown\n- Nearby amenities\n:::\n\n:::{.column width=\"50%\"}\n**Temporal features (This week):**\n\n- Demand 1 hour ago\n- Demand 2 hours ago\n- Demand yesterday (24 hours ago)\n:::\n:::\n\n:::{.fragment}\n**Intuition:** If there were 15 trips at 8 AM, there will probably be ~15 trips at 9 AM\n:::\n\n---\n\n## Creating Lag Variables\n\n```{r eval=FALSE, echo=TRUE}\nstudy.panel <- study.panel %>%\n  arrange(from_station_id, interval60) %>%  # Sort by station, then time\n  group_by(from_station_id) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),    # Previous hour\n    lag2Hours = lag(Trip_Count, 2),   # 2 hours ago\n    lag3Hours = lag(Trip_Count, 3),   # 3 hours ago\n    lag12Hours = lag(Trip_Count, 12), # 12 hours ago\n    lag1day = lag(Trip_Count, 24)     # Yesterday same time\n  ) %>%\n  ungroup()\n```\n\n:::{.fragment}\n**Important:** Lags are calculated WITHIN each station\n:::\n\n---\n\n## Lag Variable Example {.smaller}\n\n**Station A on Monday:**\n\n| Time | Trip Count | lag1Hour | lag12Hours | lag1day |\n|------|------------|----------|------------|---------|\n| Mon 07:00 | 5 | NA | NA | NA |\n| Mon 08:00 | 12 | 5 | NA | NA |\n| Mon 09:00 | 15 | 12 | NA | NA |\n| Mon 19:00 | 8 | 10 | 5 | NA |\n| Tue 08:00 | 14 | 6 | 10 | 12 |\n\n:::{.fragment}\n**Interpretation:** At Tue 08:00, demand was 14. Same time yesterday (Mon 08:00) was 12.\n:::\n\n---\n\n## Why Multiple Lags?\n\n**Different lags capture different patterns:**\n\n:::{.incremental}\n- **lag1Hour:** Short-term persistence (smooth demand changes)\n- **lag3Hours:** Medium-term trends (morning rush building)\n- **lag12Hours:** Half-day cycle (AM vs. PM patterns)\n- **lag1day (24 hours):** Daily periodicity (same time yesterday)\n:::\n\n:::{.fragment}\n**Model will learn** which lags are most predictive for each station/time combination\n:::\n\n---\n\n## Connection to Week 6: Spatial Features\n\n**Remember Week 6?**\n\n```{r eval=FALSE, echo=TRUE}\n# Spatial features we created:\nboston.sf <- boston.sf %>%\n  mutate(\n    crimes_500ft = ...,        # Count crimes nearby\n    crime_nn3 = ...,           # Average crime at 3 nearest neighbors\n    dist_downtown = ...        # Distance to downtown\n  )\n```\n\n:::{.fragment}\n**This week is the same concept:**\n\n```{r eval=FALSE, echo=TRUE}\n# Temporal features we're creating:\nstudy.panel <- study.panel %>%\n  mutate(\n    lag1Hour = ...,            # Demand at nearby TIME\n    lag1day = ...,             # Demand at similar TIME\n  )\n```\n:::\n\n---\n\n# Part 5: Creating the Space-Time Panel\n\n---\n\n## The Challenge: Missing Observations\n\n**Problem:** Not every station has trips every hour\n\n```{r eval=FALSE, echo=TRUE}\n# Data we have (sparse):\nStation_A, May_1_08:00, 12_trips  ✓\nStation_A, May_1_09:00,  0_trips  ✗ (missing row!)\nStation_A, May_1_10:00,  8_trips  ✓\n```\n\n:::{.fragment}\n**But we NEED:**\n```{r eval=FALSE, echo=TRUE}\n# Complete panel (every station-hour combination):\nStation_A, May_1_08:00, 12_trips\nStation_A, May_1_09:00,  0_trips  ← Must exist with 0!\nStation_A, May_1_10:00,  8_trips\n```\n:::\n\n:::{.fragment}\n**Why?** Lag calculations break if rows are missing\n:::\n\n---\n\n## Creating a Complete Panel\n\n**Step 1:** Calculate all possible combinations\n\n```{r eval=FALSE, echo=TRUE}\n# How many unique stations?\nlength(unique(dat_census$from_station_id))  # e.g., 600 stations\n\n# How many unique hours?\nlength(unique(dat_census$interval60))       # e.g., 744 hours (31 days)\n\n# Total combinations needed:\n600 stations × 744 hours = 446,400 rows\n```\n\n:::{.fragment}\n**Reality check:** Do we have 446,400 rows? Probably not!\n:::\n\n---\n\n## expand.grid() to the Rescue\n\n```{r eval=FALSE, echo=TRUE}\n# Create every possible station-hour combination\nstudy.panel <- expand.grid(\n  interval60 = unique(dat_census$interval60),\n  from_station_id = unique(dat_census$from_station_id)\n)\n\n# Join to actual trip counts\nstudy.panel <- study.panel %>%\n  left_join(\n    dat_census %>% \n      group_by(interval60, from_station_id) %>%\n      summarize(Trip_Count = n()),\n    by = c(\"interval60\", \"from_station_id\")\n  ) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0))  # Fill missing with 0\n```\n\n:::{.fragment}\n**Now every station-hour exists,** even if Trip_Count = 0\n:::\n\n---\n\n## Joining Station Attributes\n\n**Each station has fixed characteristics:**\n\n```{r eval=FALSE, echo=TRUE}\n# Station location, demographics from census\nstation_data <- dat_census %>%\n  group_by(from_station_id) %>%\n  summarize(\n    from_latitude = first(from_latitude),\n    from_longitude = first(from_longitude),\n    Med_Inc = first(Med_Inc),\n    Percent_White = first(Percent_White),\n    # ... other demographics\n  )\n\n# Join to panel\nstudy.panel <- study.panel %>%\n  left_join(station_data, by = \"from_station_id\")\n```\n\n:::{.fragment}\n**Result:** Every row has station location + demographics\n:::\n\n---\n\n## Adding Time-Varying Features\n\n**Some features change over time:**\n\n```{r eval=FALSE, echo=TRUE}\n# Weather changes hourly\nweather <- weather_data %>%\n  select(interval60, Temperature, Precipitation)\n\nstudy.panel <- study.panel %>%\n  left_join(weather, by = \"interval60\")\n\n# Create time features\nstudy.panel <- study.panel %>%\n  mutate(\n    week = week(interval60),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0)\n  )\n```\n\n---\n\n## Final Panel Structure\n\n**What we have now:**\n\n- Every station-hour combination exists\n- Trip counts (including zeros)\n- Station fixed attributes (location, demographics)\n- Time-varying features (weather, day of week, hour)\n- Temporal lags (lag1Hour, lag1day, etc.)\n\n:::{.fragment}\n**Ready to model!** But first... temporal validation\n:::\n\n---\n\n# Part 6: Temporal Validation\n\n---\n\n## Critical Callback: Week 7 Discussion {.smaller}\n\n**Remember when we talked about spatial lag models?**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Spatial Lag Model (SAR):**\n\n$$Y_i = \\rho \\sum_j w_{ij}Y_j + \\beta X_i + \\varepsilon$$\n\n**Why NOT for prediction:**\n\n- Circular dependency (Y depends on Y)\n- Can't predict new areas\n- Need neighbors' outcomes\n:::\n\n:::{.column width=\"50%\"}\n**Our Approach Today:**\n\n$$Y_{it} = \\alpha_i + \\beta_1 X_{it} + \\beta_2 Y_{i,t-1} + \\varepsilon_{it}$$\n\n**Station fixed effects + temporal lags:**\n\n- $\\alpha_i$ = Station baseline\n- $Y_{i,t-1}$ = Past demand (not neighbors!)\n- Can forecast future periods\n:::\n:::\n\n:::{.fragment}\n**Key difference:** We use PAST outcomes as features, not NEIGHBOR outcomes\n:::\n\n---\n\n## The Temporal Validation Problem\n\n**You CANNOT train on the future to predict the past!**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n** WRONG approach:**\n```{r eval=FALSE, echo=TRUE}\n# Train on Weeks 3-4\ntrain <- data %>% \n  filter(week >= 19)\n\n# Test on Weeks 1-2\ntest <- data %>% \n  filter(week < 19)\n```\n\n**This is predicting the past using the future!**\n:::\n\n:::{.column width=\"50%\"}\n** CORRECT approach:**\n```{r eval=FALSE, echo=TRUE}\n# Train on Weeks 1-2\ntrain <- data %>% \n  filter(week < 19)\n\n# Test on Weeks 3-4\ntest <- data %>% \n  filter(week >= 19)\n```\n\n**This is predicting the future using the past!**\n:::\n:::\n\n---\n\n## Why This Matters {.center}\n\n**Real-world scenario:**\n\n> It's May 15, 2018. You need to forecast demand for May 16-31.\n\n:::{.incremental}\n- You have data from: May 1-15 ✓\n- You don't have data from: May 16-31 (it hasn't happened yet!)\n- **You must train on May 1-15 and test on May 16-31**\n:::\n\n---\n\n## Temporal Train/Test Split\n\n```{r eval=FALSE, echo=TRUE}\n# Split by time (week of year)\ntrain <- study.panel %>%\n  filter(week < 19)  # Weeks 1-2 of May (early period)\n\ntest <- study.panel %>%\n  filter(week >= 19) # Weeks 3-4 of May (later period)\n\n# Fit models on training data only\nmodel <- lm(Trip_Count ~ lag1Hour + lag1day + Temperature + weekend, \n            data = train)\n\n# Evaluate on test data\npredictions <- predict(model, newdata = test)\n```\n\n:::{.fragment}\n**This mirrors operational deployment:** Predict tomorrow using yesterday's patterns\n:::\n\n---\n\n## Comparison to Spatial CV {.smaller}\n\n**Week 7: Spatial cross-validation**\n\n- Prevented spatial leakage\n- Left out entire neighborhoods for testing\n- Ensured model generalizes to new areas\n\n**This week: Temporal validation**\n\n- Prevents temporal leakage\n- Holds out future time periods for testing\n- Ensures model generalizes to future\n\n:::{.fragment}\n**Both are about out-of-sample generalization!**\n:::\n\n---\n\n# Part 7: Building Models\n\n---\n\n## Model Progression Strategy\n\n**We'll build 5 models, adding complexity:**\n\n1. **Baseline:** Time + Weather only\n2. **+ Temporal lags:** Add lag1Hour, lag1day\n3. **+ Spatial features:** Add demographics, location\n4. **+ Station fixed effects:** Control for station-specific baselines\n5. **+ Holiday effects:** Account for Memorial Day weekend\n\n:::{.fragment}\n**Goal:** See which features improve prediction accuracy\n:::\n\n---\n\n## Model 1: Baseline (Time + Weather)\n\n```{r eval=FALSE, echo=TRUE}\nmodel1 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation,\n  data = train\n)\n```\n\n**Predictors:**\n\n- `hour`: Hour of day (0-23)\n- `dotw`: Day of week (Mon, Tue, ..., Sun)\n- `Temperature`: Hourly temperature\n- `Precipitation`: Rainfall amount\n\n:::{.fragment}\n**Captures:** Daily and weekly cycles, weather effects\n:::\n\n---\n\n## Model 2: + Temporal Lags\n\n```{r eval=FALSE, echo=TRUE}\nmodel2 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n```\n\n**New predictors:**\n\n- `lag1Hour`: Demand 1 hour ago\n- `lag3Hours`: Demand 3 hours ago\n- `lag1day`: Demand 24 hours ago\n\n:::{.fragment}\n**Hypothesis:** Past demand predicts future demand\n:::\n\n---\n\n## Model 3: + Spatial Features\n\n```{r eval=FALSE, echo=TRUE}\nmodel3 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White,\n  data = train\n)\n```\n\n**New predictors:**\n\n- Demographics from census (station location characteristics)\n- These are **fixed over time** but vary across stations\n\n:::{.fragment}\n**Captures:** Neighborhood effects on demand\n:::\n\n---\n\n## Model 4: + Station Fixed Effects\n\n```{r eval=FALSE, echo=TRUE}\nmodel4 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White +\n               as.factor(from_station_id),  # Station dummies\n  data = train\n)\n```\n\n**Station fixed effects:**\n\n- One dummy variable per station\n- Captures station-specific baseline demand\n- Controls for unobserved station characteristics\n\n:::{.fragment}\n**Why?** Some stations are just busier than others!\n:::\n\n---\n\n## Model 5: + Holiday Effects\n\n```{r eval=FALSE, echo=TRUE}\nmodel5 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation +\n               lag1Hour + lag3Hours + lag1day +\n               Med_Inc + Percent_Taking_Public_Trans + Percent_White +\n               as.factor(from_station_id) +\n               holiday + holiday_lag1 + holiday_lag2,  # Holiday indicators\n  data = train\n)\n```\n\n**Memorial Day weekend (May 28-29, 2018):**\n\n- `holiday`: Current hour is during holiday\n- `holiday_lag1`: 1 hour into holiday\n- `holiday_lag2`: 2 hours into holiday\n\n:::{.fragment}\n**Captures:** Disruption to normal patterns during holidays\n:::\n\n---\n\n## Evaluating Models: MAE {.smaller}\n\n**Mean Absolute Error:**\n\n$$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n\n**Interpretation:**\n\n- \"On average, our predictions are off by X trips\"\n- Lower MAE = better predictions\n- **Same units as outcome** (unlike RMSE that emphasizes large errors)\n\n:::{.fragment}\n**Example:** MAE = 5 means predictions are typically off by ±5 trips\n:::\n\n---\n\n## Model Comparison (Hypothetical Results) {.smaller}\n\n| Model | MAE (Test Set) | What Improved? |\n|-------|----------------|----------------|\n| 1. Baseline | 8.2 trips | — |\n| 2. + Lags | 6.5 trips | Temporal persistence |\n| 3. + Demographics | 6.1 trips | Neighborhood effects |\n| 4. + Fixed Effects | 5.3 trips | Station baselines |\n| 5. + Holidays | 5.1 trips | Disruption events |\n\n:::{.fragment}\n**Biggest improvement:** Adding temporal lags (8.2 → 6.5)\n:::\n\n---\n\n# Part 8: Space-Time Error Analysis\n\n---\n\n## Where Are We Wrong?\n\n**Not all errors are equal!**\n\n:::{.incremental}\n- High MAE at high-volume stations might be acceptable\n- High MAE at low-volume stations might indicate systematic bias\n- Spatial patterns in errors suggest missing features\n- Temporal patterns suggest missing time dynamics\n:::\n\n:::{.fragment}\n**Question for operations:** When do prediction errors cause bikes to run out?\n:::\n\n---\n\n## Spatial Error Patterns\n\n**Map errors by station:**\n\n![](images/map_error.png)\n\n---\n\n## Temporal Error Patterns\n\n**When are we most wrong?**\n\n![](images/error2.png)\n\n---\n\n## Observed vs. Predicted\n\n**Scatterplot by time of day:**\n\n![](images/errors.png)\n\n:::{.fragment}\n**Diagonal red line:** Perfect predictions\n\n**Blue line:** Our actual performance\n:::\n\n---\n\n## Common Error Patterns\n\n**What you might see:**\n\n:::{.incremental}\n- **Underpredicting peaks:** Missing high-demand periods (rush hour)\n- **Weekend vs. weekday differences:** Holiday patterns not fully captured\n- **Spatial clustering:** Errors concentrated in certain neighborhoods\n  - Waterfront (leisure rides?)\n  - Downtown (tourist activity?)\n  - Transit hubs (commuter substitution?)\n:::\n\n:::{.fragment}\n**Critical question:** Are errors related to demographics? (Equity concern!)\n:::\n\n---\n\n## Errors and Demographics\n\n```{r eval=FALSE, echo=TRUE}\n# Join errors back to demographic data\nstation_errors <- station_errors %>%\n  left_join(\n    dat_census %>% \n      distinct(from_station_id, Med_Inc, \n               Percent_Taking_Public_Trans, Percent_White),\n    by = \"from_station_id\"\n  )\n\n# Plot relationships\nstation_errors %>%\n  pivot_longer(cols = c(Med_Inc, Percent_Taking_Public_Trans, \n                        Percent_White),\n               names_to = \"variable\", values_to = \"value\") %>%\n  ggplot(aes(x = value, y = MAE)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~variable, scales = \"free_x\")\n```\n\n---\n\n# Part 9: Policy Implications\n\n---\n\n## Interpreting Results for Operations {.smaller}\n\n**For a bike rebalancing system:**\n\n:::{.incremental}\n1. **Prediction accuracy matters most at high-volume stations**\n   - Running out of bikes downtown causes more complaints\n   - But: Is this equitable?\n\n2. **Temporal patterns reveal operational windows**\n   - Rebalance during overnight hours (low demand)\n   - Pre-position bikes before AM rush\n\n3. **Spatial patterns suggest infrastructure gaps**\n   - Persistent errors in certain neighborhoods\n   - Maybe add more stations? Increase capacity?\n:::\n\n---\n\n## The Equity Question\n\n**Who benefits from accurate predictions?**\n\n:::{.columns}\n:::{.column width=\"50%\"}\n**Higher accuracy in:**\n\n- Downtown stations\n- High-income neighborhoods\n- Tourist areas\n- Transit hubs\n:::\n\n:::{.column width=\"50%\"}\n**Lower accuracy in:**\n\n- Residential periphery\n- Lower-income areas\n- Newer stations\n- Less transit access\n:::\n:::\n\n:::{.fragment}\n**Critical analysis:** Are we reinforcing unequal service quality?\n:::\n\n---\n\n## When Should We Deploy This?\n\n**Questions to consider:**\n\n:::{.incremental}\n- Is MAE = 5 trips \"good enough\" for operations?\n- What are consequences of underpredicting by 10 trips?\n- Do prediction errors disproportionately affect certain groups?\n- What feedback loops might emerge?\n  - Poor predictions → bikes not available → people stop using → even less data\n:::\n\n---\n\n## Next Steps to Improve {.smaller}\n\n**What could reduce errors?** \n\n:::{.incremental}\n1. **More temporal features:**\n   - Precipitation *forecast* (not just current)\n   - Event calendars (concerts, sports games)\n   - School schedules\n\n2. **More spatial features:**\n   - Points of interest (offices, restaurants, parks)\n   - Transit service frequency\n   - Bike lane connectivity\n\n3. **Better model specification:**\n   - Interactions (e.g., `weekend * hour`)\n   - Non-linear effects (splines for time of day)\n   - Different models for different station types\n:::\n\n---\n\n# Part 10: Connection to Your Work\n\n\n---\n\n\n## When Else Would You Use Panel Data?\n\n**Common policy applications:**\n\n:::{.incremental}\n- **Transportation:** Transit ridership over time\n- **Public safety:** Crime patterns by beat over months\n- **Housing:** Rent changes in neighborhoods over years\n- **Health:** Disease incidence by zip code over weeks\n- **Education:** School performance over academic years\n- **Environment:** Air quality at monitoring sites over days\n:::\n\n:::{.fragment}\n**Anytime you have:** Same units observed repeatedly over time\n:::\n\n---\n\n# Lab Time!\n\n---\n\n## Today's Lab Exercise {.smaller}\n\n**Your task:** Build space-time models for Chicago bike share\n\n**Working through the code:**\n\n1. Load and explore data (10 min)\n2. Create panel structure with `expand.grid()` (15 min)\n3. Generate temporal lags (10 min)\n4. Build multiple models (20 min)\n5. Compare model performance (15 min)\n6. Analyze error patterns in space and time (20 min)\n\n**Discussion questions:**\n\n- Why do certain time periods have higher errors?\n- Which demographic characteristics predict higher errors?\n- How would you improve the model?\n- Should this system be deployed? Under what conditions?\n\n---\n\n## Code Walk-Through Preview\n\n**Key functions you'll use:**\n\n```{r eval=FALSE, echo=TRUE}\n# 1. Binning time\nfloor_date(datetime, unit = \"hour\")\n\n# 2. Creating complete panel\nexpand.grid(station = stations, time = times)\n\n# 3. Temporal lags\ngroup_by(station_id) %>% mutate(lag1 = lag(outcome, 1))\n\n# 4. Fixed effects\nlm(y ~ x + as.factor(station_id))\n\n# 5. Evaluation\nMAE = mean(abs(observed - predicted))\n```\n\n---\n\n## Getting Started\n\n**Open the lab file:** `week11_bike_share_lab.Rmd`\n\n**Work in groups of 2-3**\n\n**I'll circulate to help with:**\n\n- Data structure questions\n- Lag variable confusion\n- Fixed effects interpretation\n- Visualization challenges\n\n**Take your time** - this is complex material!\n\n---\n\n## Key Takeaways {.center}\n\n:::{.incremental}\n1. **Panel data** = same units observed over time\n2. **Temporal lags** capture demand persistence\n3. **Train on past → test on future** for temporal validation\n4. **Station fixed effects** control for baseline differences\n5. **Space-time errors** reveal both spatial and temporal patterns\n6. **Policy question:** When is \"good enough\" actually good enough?\n7. **Equity concern:** Do errors disproportionately affect certain groups?\n:::\n\n---\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["custom.css"],"output-file":"week11-slides.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.24","auto-stretch":true,"title":"Space-Time Prediction","subtitle":"Bike Share Demand Forecasting with Panel Data & Temporal Lags","author":"Dr. Elizabeth Delmelle","date":"November 17, 2025","theme":"simple","slideNumber":true,"chalkboard":true,"previewLinks":"auto"}}},"projectFormats":["html"]}