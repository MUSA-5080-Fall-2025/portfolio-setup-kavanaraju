{"title":"Model Diagnostics & Spatial Autocorrelation","markdown":{"yaml":{"title":"Model Diagnostics & Spatial Autocorrelation","subtitle":"Week 7: MUSA 5080","author":"Dr. Elizabeth Delmelle","date":"October 21, 2025","format":{"revealjs":{"theme":"simple","slide-number":true,"chalkboard":true,"code-line-numbers":true,"incremental":false,"smaller":true,"scrollable":true}}},"headingText":"Homework Feedback & Tips","containsRefs":false,"markdown":"\n\n\n## Before We Start: A Quick Note on Your Submissions\n\n**We noticed something in your homework submissions...**\n\nMany of you have **messy output** in your rendered HTML files from `tigris` and `tidycensus` functions.\n\n**Example of what we're seeing:**\n```\nRetrieving data for the year 2022\n  |======================================================================| 100%\n  |======================================================================| 100%\nDownloading: 4.3 MB     \nDownloading: 3.7 MB\n```\n\n**This clutters your professional report!**\n\n---\n\n## The Problem: Progress Bars in Rendered Output {.smaller}\n\n**What's happening:**\n\nWhen you use `tigris` or `tidycensus` functions, they show download progress by default.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **In your console (good!):**\n```{r}\n#| eval: false\n#| echo: true\ntracts <- get_acs(\n  geography = \"tract\",\n  variables = \"B01003_001\",\n  state = \"PA\",\n  geometry = TRUE\n)\n```\n\nShows:\n```\nGetting data from the 2018-2022 5-year ACS\n  |======| 100%\n```\n\n**This is helpful when coding!**\n:::\n\n::: {.column width=\"50%\"}\n### **In your rendered HTML (bad!):**\n\nAll those progress messages appear as ugly text in your final document.\n\n**This looks unprofessional** and makes your work harder to read.\n\n**Solution:** Suppress progress messages in your code chunks\n:::\n::::\n\n---\n\n## The Solution: Add `progress = FALSE` {.smaller}\n\n**Two ways to fix this:**\n\n### **Option 1: In each function call**\n```{r}\n#| eval: false\n#| echo: true\n# Add progress = FALSE to EVERY tigris/tidycensus call\ntracts <- get_acs(\n  geography = \"tract\",\n  variables = \"B01003_001\",\n  state = \"PA\",\n  geometry = TRUE,\n  progress = FALSE  # <-- Add this!\n)\n\nroads <- roads(state = \"PA\", \n               county = \"Philadelphia\",\n               progress = FALSE)  # <-- Add this!\n```\n\n### **Option 2: Set globally at top of document** (Recommended!)\n```{r}\n#| eval: false\n#| echo: true\n# Add this near the top of your .qmd after loading libraries\noptions(tigris_use_cache = TRUE)\noptions(tigris_progress = FALSE)  # Suppress tigris progress bars\n```\n\n---\n\n## Action Required: Re-Render Before Final Grading {.smaller}\n\n::: {.callout-important}\n## **ðŸ“ To-Do Before We Grade**\n\n**Please go back to your homework and:**\n\n1. Open your `.qmd` file\n2. Add `progress = FALSE` to all `get_acs()`, `get_decennial()`, and `tigris` function calls\n   - OR add the global options at the top of your document\n3. **Re-render** your document (Click \"Render\" button)\n4. Check that the HTML output is clean\n5. **Re-submit** on Canvas if needed (but it should all update on your website once you re-render!)\n\n**Deadline:** Before our next class meeting\n\n**Why this matters:** We gotta look good!\n:::\n\n---\n\n# Today's Plan\n\n## Agenda Overview\n\n**Part 1: Review & Connect**\n\n- Where we've been and where we're going\n- The regression workflow so far\n\n**Part 2: Evaluating Model Quality**\n\n- Train/test splits vs. cross-validation review\n- Spatial patterns in errors\n- Introduction to spatial autocorrelation\n\n**Part 3: Moran's I as a Diagnostic**\n\n- Understanding spatial clustering\n- Calculating and interpreting Moran's I\n- Local vs. global measures\n\n**BREAK (10 min)**\n\n**Part 4: Midterm Work Session (90+ min)**\n\n---\n\n# Part 1: Where We Are\n\n## The Journey So Far\n\n**Weeks 1-3:** Data foundations\n\n- Census data, tidycensus, spatial data basics\n- Visualization and exploratory analysis\n\n**Week 5:** Linear regression fundamentals\n\n- Y = f(X) + Îµ framework\n- Train/test splits, cross-validation\n- Checking assumptions\n\n**Week 6:** Expanding the toolkit\n\n- Categorical variables and interactions\n- Spatial features (buffers, kNN, distance)\n- Neighborhood fixed effects\n\n## Last Week's Key Innovation\n\n**You learned to create spatial features:**\n\n```{r eval=FALSE}\n# Buffer aggregation\ncrimes_500ft <- count_features_in_buffer(houses, crimes, 500)\n\n# k-Nearest Neighbors\ncrime_nn3 <- average_distance_to_knn(houses, crimes, k=3)\n\n# Fixed effects\nlm(SalePrice ~ ... + as.factor(neighborhood))\n```\n\n**Today's Question:**\n\n> *How do we know if our model still has spatial structure in its errors?*\n\nIf errors are spatially clustered, we're missing something important!\n\n## The Regression Workflow (Updated)\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Building the model:**\n\n1. Visualize relationships\n2. Engineer features\n3. Fit the model\n4. Evaluate performance (RMSE, RÂ²)\n5. Check assumptions\n:::\n\n::: {.column width=\"50%\"}\n**NEW: Spatial diagnostics:**\n\n6. **Are errors random or clustered?**\n7. **Do we predict better in some areas?**\n8. **Is there remaining spatial structure?**\n:::\n:::\n\n::: {.callout-important}\n## Why This Matters\n\nIf errors cluster spatially, it suggests:\n\n- Missing spatial variables\n- Misspecified relationships\n- Non-stationarity (relationships vary across space)\n:::\n\n---\n\n# Part 2: Understanding Spatial Patterns in Errors\n\n## What Are Model Errors?\n\n**Prediction error** for observation *i*:\n\n$$e_i = \\hat{y}_i - y_i$$\n\nWhere:\n\n- $\\hat{y}_i$ = predicted value\n- $y_i$ = actual value\n\n**In our house price context:**\n\n```{r}\n#| eval: true\n#| echo: true\n\n# Load packages and data\nlibrary(sf)\nlibrary(here)\nlibrary(tidyverse)\n\n# Load Boston housing data\nboston <- read_csv(here(\"data/boston.csv\"))\n\n# Simple model: Predict price from living area\nbaseline_model <- lm(SalePrice ~ LivingArea, data = boston)\nsummary(baseline_model)\n\n\nboston_test <- boston %>%\n  mutate(\n    predicted = predict(baseline_model, boston),\n    error = predicted - SalePrice,\n    abs_error = abs(error),\n    pct_error = abs(error) / SalePrice\n  )\n\n```\n\n## Good Errors vs. Bad Errors\n\n::: {.columns}\n::: {.column width=\"50%\"}\n** Random errors (good)**\n\n- No systematic pattern\n- Scattered across space\n- Prediction equally good everywhere\n- Model captures key relationships\n:::\n\n::: {.column width=\"50%\"}\n** Clustered errors (bad)**\n\n- Spatial pattern visible\n- Under/over-predict in areas\n- Model misses something about location\n- Need more spatial features!\n:::\n:::\n\n**How do we test this?**\n\nLook for **spatial autocorrelation** in the errors\n\n## Tobler's First Law (Revisited)\n\n::: {.callout-note}\n## The First Law of Geography\n\n*\"Everything is related to everything else, but near things are more related than distant things.\"*\n\nâ€” Waldo Tobler (1970)\n:::\n\n**Applied to house prices:**\n\n- Nearby houses have similar prices\n- Nearby neighborhoods have similar characteristics\n- Crime in one block affects adjacent blocks\n\n**Applied to model errors:**\n\n- If nearby houses have similar errors...\n- ...our model is missing a spatial pattern!\n- Need to add more spatial features or fixed effects\n\n## Visualizing Error Patterns\n\n**Map your errors to see patterns:**\n\n```{r}\nlibrary(sf)\noptions(scipen = 999)\n# Convert boston data to sf object\nboston_test <- boston_test %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102286')  # MA State Plane (feet)\n\n\n# Install if needed: install.packages(\"hexbin\")\nlibrary(hexbin)\n\nggplot(boston_test) +\n  geom_sf(aes(fill = error),\n          shape = 21,\n          size = 1,\n          alpha = 0.6,\n          stroke = 0.2) +\n  scale_fill_gradient2(\n    low = \"blue\",\n    mid = \"white\",\n    high = \"red\",\n    midpoint = 0,\n    limits = c(-300000, 300000),\n    oob = scales::squish\n  ) +\n  theme_void()\n```\n\n**What to look for:**\n\n- Blue clusters (we under-predict)\n- Red clusters (we over-predict)\n- Random scatter (good!)\n\n## Scatter Plot: Spatial Lag of Errors\n\n**Create the spatial lag:**\n\n```{r}\n#| eval: true\n#| echo: true\nlibrary(spdep)\n\n# Define neighbors (5 nearest)\ncoords <- st_coordinates(boston_test)\nneighbors <- knn2nb(knearneigh(coords, k=5))\nweights <- nb2listw(neighbors, style=\"W\")\n\n# Calculate spatial lag of errors\nboston_test$error_lag <- lag.listw(weights, boston_test$error)\n```\n\n**Then plot:**\n\n```{r}\nggplot(boston_test, aes(x=error_lag, y=error)) +\n  geom_point(alpha=0.5) +\n  geom_smooth(method=\"lm\", color=\"red\") +\n  labs(title=\"Is my error correlated with neighbors' errors?\",\n       x=\"Avg error of 5 nearest neighbors\",\n       y=\"My error\")\n```\n\n---\n\n# Part 3: Moran's I\n\n## What is Moran's I?\n\n**Moran's I** measures spatial autocorrelation\n\n**Range:** -1 to +1\n\n- **+1** = Perfect positive correlation (clustering)\n- **0** = Random spatial pattern\n- **-1** = Perfect negative correlation (dispersion)\n\n**Formula (look's scary, but its so intuitive!):**\n\n$$I = \\frac{n \\sum_i \\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i \\sum_j w_{ij} \\sum_i (x_i - \\bar{x})^2}$$\n\nWhere $w_{ij}$ = spatial weight between locations *i* and *j*\n\n## Worked Example: Understanding the Formula\n\n**5 houses in a row, predicting sale prices:**\n\n| House | Actual Price | Predicted Price | Error | \n|-------|-------------|-----------------|-------|\n| A     | $500k       | $400k          | +$100k |\n| B     | $480k       | $400k          | +$80k  |\n| C     | $420k       | $400k          | +$20k  |\n| D     | $350k       | $400k          | -$50k  |\n| E     | $330k       | $400k          | -$70k  |\n\n**Mean error = +$16k**\n\n**The question:** Are errors for nearby houses similar to each other?\n\n---\n\n## Step 1: Calculate Deviations from Mean\n\n**Subtract the mean error from each house's error:**\n\n| House | Error | Mean Error | Deviation from Mean |\n|-------|-------|------------|-------------------|\n| A     | +$100k | +$16k     | +$84k            |\n| B     | +$80k  | +$16k     | +$64k            |\n| C     | +$20k  | +$16k     | +$4k             |\n| D     | -$50k  | +$16k     | -$66k            |\n| E     | -$70k  | +$16k     | -$86k            |\n\n**Positive deviation** = we over-predicted (actual > predicted)  \n**Negative deviation** = we under-predicted (actual < predicted)\n\n---\n\n## Step 2: Multiply Neighbor Deviations\n\n**For each neighbor pair, multiply their deviations:**\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Neighbor Pairs:**\n\n- A-B: $(+84k) \\times (+64k) = +5,376$\n- B-C: $(+64k) \\times (+4k) = +256$\n- C-D: $(+4k) \\times (-66k) = -264$\n- D-E: $(-66k) \\times (-86k) = +5,676$\n\n**Sum of products = 11,044**\n:::\n\n::: {.column width=\"50%\"}\n**What does this mean?**\n\n**Positive products** = similar neighbors\n- A-B: both over-predicted (both positive)\n- D-E: both under-predicted (both negative)\n\n**Negative product** = dissimilar neighbors  \n- C-D: one over, one under\n\n**The pattern:** High-error houses cluster together, low-error houses cluster together\n:::\n::::\n\n---\n\n## The Intuition Behind Moran's I\n\n**The formula is really just asking:**\n\n> _\"When I'm above/below average, are my neighbors also above/below average?\"_\n\n**Breaking it down:**\n\n1. $(x_i - \\bar{x})$ = How far is my house's error from the mean?\n\n2. $(x_j - \\bar{x})$ = How far is my neighbor's error from the mean?\n\n3. **Multiply them:**\n   - If both positive or both negative â†’ **positive product** (similar)\n   - If opposite signs â†’ **negative product** (dissimilar)\n\n4. **Sum across all neighbor pairs** and normalize\n\n**Result:**\n\n- Lots of positive products â†’ **High Moran's I** (clustering)\n- Products near zero â†’ **Low Moran's I** (random)\n- Negative products â†’ **Negative Moran's I** (rare with errors)\n\n---\n\n## The Intuition Behind Moran's I\n\n**The formula is really just asking:**\n\n> *\"When I'm above/below average, are my neighbors also above/below average?\"*\n\n**Breaking it down:**\n\n1. $(x_i - \\bar{x})$ = How far am I from the mean?\n2. $(x_j - \\bar{x})$ = How far is my neighbor from the mean?\n\n3. **Multiply them:** \n\n   - If both positive or both negative â†’ **positive product** (similar)\n   - If opposite signs â†’ **negative product** (dissimilar)\n   \n4. **Sum across all neighbor pairs** and normalize\n\n**Result:**\n\n- Lots of positive products â†’ **High Moran's I** (clustering)\n- Products near zero â†’ **Low Moran's I** (random)\n- Negative products â†’ **Negative Moran's I** (rare with errors)\n\n\n## Defining \"Neighbors\"\n\n**Different ways to define spatial relationships:**\n\n::: {.columns}\n::: {.column width=\"33%\"}\n**Contiguity**\n\n- Polygons that share a border\n- Queen vs. Rook\n:::\n\n::: {.column width=\"33%\"}\n**Distance**\n\n- All within X meters\n- Fixed threshold\n:::\n\n::: {.column width=\"33%\"}\n**k-Nearest**\n\n- Closest k points\n- Adaptive distance\n:::\n:::\n\n**For point data (houses), use k-nearest neighbors**\n\n```{r}\n#| eval: true\n#| echo: true\n# Create 5-nearest neighbors\ncoords <- st_coordinates(boston_test)\nnb <- knn2nb(knearneigh(coords, k=5))\nweights <- nb2listw(nb, style=\"W\")\n```\n\n## Calculating Spatial Lag\n\n**Spatial lag** = average value of neighbors\n\n::: {.callout-tip}\n## Example: 5 houses\n\n| House | Sale Price | 2 Nearest | Spatial Lag |\n|-------|-----------|-----------|-------------|\n| A     | $200k     | B, C      | $275k       |\n| B     | $250k     | A, C      | $250k       |\n| C     | $300k     | B, D      | $275k       |\n| D     | $350k     | C, E      | $350k       |\n| E     | $400k     | D         | $350k       |\n:::\n\n**In R:**\n\n```{r}\n#| eval: true\n#| echo: true\nboston$price_lag <- lag.listw(weights, boston$SalePrice)\n```\n\n## Computing Moran's I\n\n**Calculate Moran's I for your errors:**\n\n```{r}\n#| eval: true\n#| echo: true\n# Test for spatial autocorrelation in errors\nmoran_test <- moran.mc(\n  boston_test$error,        # Your errors\n  weights,                  # Spatial weights matrix\n  nsim = 999                # Number of permutations\n)\n\n# View results\nmoran_test$statistic         # Moran's I value\nmoran_test$p.value          # Is it significant?\n```\n\n**Interpretation:**\n\n- **I > 0** and *p* < 0.05 â†’ Significant clustering\n- **I â‰ˆ 0** â†’ Random pattern (good!)\n- **I < 0** â†’ Dispersion (rare with errors)\n\n## Visualizing Significance\n\n**Compare observed I to random permutations:**\n\n```{r}\n#| eval: true\n#| echo: false\nlibrary(ggplot2)\n\nmoran_df <- data.frame(sim_I = moran_test$res[1:999])\n\nggplot(moran_df, aes(x = sim_I)) +\n  geom_histogram(binwidth = 0.01, fill = \"gray70\", color = \"white\") +\n  geom_vline(aes(xintercept = moran_test$statistic), \n             color = \"#FA7800\", linewidth = 1.5) +\n  labs(\n    title = \"Observed vs. Expected Moran's I\",\n    subtitle = \"Orange line = observed | Gray = random permutations\",\n    x = \"Moran's I\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n```\n\n## What Moran's I Tells You\n\n::: {.callout-important}\n## Decision Framework\n\n**If Moran's I is high (errors clustered):**\n\n1. Add more spatial features\n   - Try different buffer sizes\n   - Include more amenities/disamenities\n   - Create neighborhood-specific variables\n\n2. Try spatial fixed effects\n   - Neighborhood dummies\n   - Grid cell dummies\n\n3. Consider spatial regression models\n   - Spatial lag model\n   - Spatial error model\n   - (Advanced topic, not covered today)\n:::\n\n**If Moran's I â‰ˆ 0 (random errors):**\n\nâœ… Your model adequately captures spatial relationships!\n\n---\n\n## \"What About Spatial Lag/Error Models?\" {.smaller}\n\n*\"In my spatial statistics class, I learned about spatial lag and spatial error models for dealing with spatial autocorrelation. Why aren't we using those here?\"*\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **Spatial Econometrics Models**\n**(Spatial Statistics Class)**\n\n**Spatial Lag Model:** $Y_i = \\rho WY + \\beta X_i + \\varepsilon$\n\n**Spatial Error Model:** $Y_i = \\beta X_i + \\lambda W\\varepsilon + \\xi$\n\n**Purpose:** \n\n- Causal inference with spatial spillovers\n- Understanding neighbor effects\n- Correct standard errors for hypothesis testing\n- Cross-sectional analysis\n\n**When to use:** Academic research on spillover effects, peer influence, regional economics\n:::\n\n::: {.column width=\"50%\"}\n### **Predictive Spatial Features**\n**(This Class)**\n\n**Our Approach:** \n$$Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2(\\text{crimes}_{500ft}) + \\beta_3(\\text{dist}_{downtown}) + \\varepsilon_i$$\n\n**Purpose:**\n\n- Out-of-sample prediction\n- Forecasting new observations  \n- Applied machine learning\n- Generalization to new areas\n\n**When to use:** Real estate prediction, housing market forecasting, policy planning\n:::\n::::\n\n---\n\n## Why Not Spatial Lag Models for Prediction? {.smaller}\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **The Problems with Spatial Lag for Prediction:**\n\n**1. Simultaneity Problem**\n\n- Including $WY$ (neighbor prices) creates circular logic\n- My price affects neighbors â†’ neighbors affect me\n- OLS estimates are **biased and inconsistent**\n\n**2. Prediction Paradox**\n\n- Need neighbors' prices to predict my price\n- But for new developments or future periods, those prices **don't exist yet**\n- Can't generalize to truly new areas\n\n**3. Data Leakage in CV**\n\n- Geographic CV holds out spatial regions\n- Spatial lag \"leaks\" information from test set\n- Artificially good performance that won't hold\n:::\n\n::: {.column width=\"50%\"}\n### **Our Solution: Spatial Features of X (Not Y)**\n\nInstead of modeling dependence in **Y** (prices), model proximity in **X** (predictors)\n\n| âŒ Spatial Lag | âœ… Our Approach |\n|----------------|-----------------|\n| \"Near expensive houses\" | \"Near low crime areas\" |\n| Uses neighbor **prices** | Uses neighbor **characteristics** |\n| Circular logic | Causal mechanism |\n| Can't predict new areas | Generalizes well |\n\n**If Moran's I shows clustered errors:**\n\nâœ… **Add more spatial features** (different buffers, more amenities)  \nâœ… **Try neighborhood fixed effects**  \nâœ… **Use spatial cross-validation**\n\nâŒ Don't add spatial lag of Y for prediction purposes\n\n::: {.callout-tip}\n## **The Bottom Line**\nBoth approaches are valid for different goals! Match method to purpose: **inference** â†’ spatial lag/error models; **prediction** â†’ spatial features.\n:::\n:::\n::::\n\n---\n\n## Quick Clarification: Biased vs. Inconsistent {.smaller}\n\nWhen we say OLS estimates are **\"biased and inconsistent\"** with spatial lag models, what does that mean?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **Biased Estimator**\n\n**Definition:** Expected value â‰  true parameter\n\n$$E[\\hat{\\beta}] \\neq \\beta$$\n\n**What this means:**\n\n- On average, across all possible samples, your estimate is **systematically wrong**\n- Doesn't get the right answer even in expectation\n- More data doesn't fix it\n\n**Example:**\n\n- True effect: Î² = 100\n- Your estimates average to: 80\n- You're systematically **20 units off**\n:::\n\n::: {.column width=\"50%\"}\n### **Inconsistent Estimator**\n\n**Definition:** Doesn't converge to true value as n â†’ âˆž\n\n$$\\hat{\\beta} \\not\\to \\beta \\text{ as } n \\to \\infty$$\n\n**What this means:**\n\n- Even with **infinite data**, you won't get the right answer\n- The problem doesn't go away with bigger samples\n- Violates a fundamental property of good estimators\n\n**Example:**\n- n = 100 â†’ estimate = 80\n- n = 10,000 â†’ estimate = 82\n- n = 1,000,000 â†’ estimate = 84\n- Never reaches true value of 100\n:::\n::::\n\n---\n\n# Summary & Next Steps\n\n## Key Takeaways\n\n**Spatial autocorrelation in errors indicates model misspecification**\n\n**Moran's I is a diagnostic tool:**\n\n- Global I: overall clustering\n- Maps of residuals give clues to what you might be missing\n\n**Iterative improvement:**\n\n- Diagnose â†’ Engineer features â†’ Re-test â†’ Repeat\n- Document what you try!\n\n\n\n## Resources\n\n**Spatial autocorrelation:**\n- [https://mgimond.github.io/Spatial/spatial-autocorrelation.html](https://mgimond.github.io/Spatial/spatial-autocorrelation.html)\n\n**spdep package:**\n- [https://r-spatial.github.io/spdep/](https://r-spatial.github.io/spdep/)\n\n---\n\n# Questions Before Work Time?\n\nCome see me during the work session for:\n\n- Help with Moran's I calculation\n- Ideas for new spatial features\n- Debugging code issues\n- Discussing your model strategy\n\n","srcMarkdownNoYaml":"\n\n# Homework Feedback & Tips\n\n## Before We Start: A Quick Note on Your Submissions\n\n**We noticed something in your homework submissions...**\n\nMany of you have **messy output** in your rendered HTML files from `tigris` and `tidycensus` functions.\n\n**Example of what we're seeing:**\n```\nRetrieving data for the year 2022\n  |======================================================================| 100%\n  |======================================================================| 100%\nDownloading: 4.3 MB     \nDownloading: 3.7 MB\n```\n\n**This clutters your professional report!**\n\n---\n\n## The Problem: Progress Bars in Rendered Output {.smaller}\n\n**What's happening:**\n\nWhen you use `tigris` or `tidycensus` functions, they show download progress by default.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **In your console (good!):**\n```{r}\n#| eval: false\n#| echo: true\ntracts <- get_acs(\n  geography = \"tract\",\n  variables = \"B01003_001\",\n  state = \"PA\",\n  geometry = TRUE\n)\n```\n\nShows:\n```\nGetting data from the 2018-2022 5-year ACS\n  |======| 100%\n```\n\n**This is helpful when coding!**\n:::\n\n::: {.column width=\"50%\"}\n### **In your rendered HTML (bad!):**\n\nAll those progress messages appear as ugly text in your final document.\n\n**This looks unprofessional** and makes your work harder to read.\n\n**Solution:** Suppress progress messages in your code chunks\n:::\n::::\n\n---\n\n## The Solution: Add `progress = FALSE` {.smaller}\n\n**Two ways to fix this:**\n\n### **Option 1: In each function call**\n```{r}\n#| eval: false\n#| echo: true\n# Add progress = FALSE to EVERY tigris/tidycensus call\ntracts <- get_acs(\n  geography = \"tract\",\n  variables = \"B01003_001\",\n  state = \"PA\",\n  geometry = TRUE,\n  progress = FALSE  # <-- Add this!\n)\n\nroads <- roads(state = \"PA\", \n               county = \"Philadelphia\",\n               progress = FALSE)  # <-- Add this!\n```\n\n### **Option 2: Set globally at top of document** (Recommended!)\n```{r}\n#| eval: false\n#| echo: true\n# Add this near the top of your .qmd after loading libraries\noptions(tigris_use_cache = TRUE)\noptions(tigris_progress = FALSE)  # Suppress tigris progress bars\n```\n\n---\n\n## Action Required: Re-Render Before Final Grading {.smaller}\n\n::: {.callout-important}\n## **ðŸ“ To-Do Before We Grade**\n\n**Please go back to your homework and:**\n\n1. Open your `.qmd` file\n2. Add `progress = FALSE` to all `get_acs()`, `get_decennial()`, and `tigris` function calls\n   - OR add the global options at the top of your document\n3. **Re-render** your document (Click \"Render\" button)\n4. Check that the HTML output is clean\n5. **Re-submit** on Canvas if needed (but it should all update on your website once you re-render!)\n\n**Deadline:** Before our next class meeting\n\n**Why this matters:** We gotta look good!\n:::\n\n---\n\n# Today's Plan\n\n## Agenda Overview\n\n**Part 1: Review & Connect**\n\n- Where we've been and where we're going\n- The regression workflow so far\n\n**Part 2: Evaluating Model Quality**\n\n- Train/test splits vs. cross-validation review\n- Spatial patterns in errors\n- Introduction to spatial autocorrelation\n\n**Part 3: Moran's I as a Diagnostic**\n\n- Understanding spatial clustering\n- Calculating and interpreting Moran's I\n- Local vs. global measures\n\n**BREAK (10 min)**\n\n**Part 4: Midterm Work Session (90+ min)**\n\n---\n\n# Part 1: Where We Are\n\n## The Journey So Far\n\n**Weeks 1-3:** Data foundations\n\n- Census data, tidycensus, spatial data basics\n- Visualization and exploratory analysis\n\n**Week 5:** Linear regression fundamentals\n\n- Y = f(X) + Îµ framework\n- Train/test splits, cross-validation\n- Checking assumptions\n\n**Week 6:** Expanding the toolkit\n\n- Categorical variables and interactions\n- Spatial features (buffers, kNN, distance)\n- Neighborhood fixed effects\n\n## Last Week's Key Innovation\n\n**You learned to create spatial features:**\n\n```{r eval=FALSE}\n# Buffer aggregation\ncrimes_500ft <- count_features_in_buffer(houses, crimes, 500)\n\n# k-Nearest Neighbors\ncrime_nn3 <- average_distance_to_knn(houses, crimes, k=3)\n\n# Fixed effects\nlm(SalePrice ~ ... + as.factor(neighborhood))\n```\n\n**Today's Question:**\n\n> *How do we know if our model still has spatial structure in its errors?*\n\nIf errors are spatially clustered, we're missing something important!\n\n## The Regression Workflow (Updated)\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Building the model:**\n\n1. Visualize relationships\n2. Engineer features\n3. Fit the model\n4. Evaluate performance (RMSE, RÂ²)\n5. Check assumptions\n:::\n\n::: {.column width=\"50%\"}\n**NEW: Spatial diagnostics:**\n\n6. **Are errors random or clustered?**\n7. **Do we predict better in some areas?**\n8. **Is there remaining spatial structure?**\n:::\n:::\n\n::: {.callout-important}\n## Why This Matters\n\nIf errors cluster spatially, it suggests:\n\n- Missing spatial variables\n- Misspecified relationships\n- Non-stationarity (relationships vary across space)\n:::\n\n---\n\n# Part 2: Understanding Spatial Patterns in Errors\n\n## What Are Model Errors?\n\n**Prediction error** for observation *i*:\n\n$$e_i = \\hat{y}_i - y_i$$\n\nWhere:\n\n- $\\hat{y}_i$ = predicted value\n- $y_i$ = actual value\n\n**In our house price context:**\n\n```{r}\n#| eval: true\n#| echo: true\n\n# Load packages and data\nlibrary(sf)\nlibrary(here)\nlibrary(tidyverse)\n\n# Load Boston housing data\nboston <- read_csv(here(\"data/boston.csv\"))\n\n# Simple model: Predict price from living area\nbaseline_model <- lm(SalePrice ~ LivingArea, data = boston)\nsummary(baseline_model)\n\n\nboston_test <- boston %>%\n  mutate(\n    predicted = predict(baseline_model, boston),\n    error = predicted - SalePrice,\n    abs_error = abs(error),\n    pct_error = abs(error) / SalePrice\n  )\n\n```\n\n## Good Errors vs. Bad Errors\n\n::: {.columns}\n::: {.column width=\"50%\"}\n** Random errors (good)**\n\n- No systematic pattern\n- Scattered across space\n- Prediction equally good everywhere\n- Model captures key relationships\n:::\n\n::: {.column width=\"50%\"}\n** Clustered errors (bad)**\n\n- Spatial pattern visible\n- Under/over-predict in areas\n- Model misses something about location\n- Need more spatial features!\n:::\n:::\n\n**How do we test this?**\n\nLook for **spatial autocorrelation** in the errors\n\n## Tobler's First Law (Revisited)\n\n::: {.callout-note}\n## The First Law of Geography\n\n*\"Everything is related to everything else, but near things are more related than distant things.\"*\n\nâ€” Waldo Tobler (1970)\n:::\n\n**Applied to house prices:**\n\n- Nearby houses have similar prices\n- Nearby neighborhoods have similar characteristics\n- Crime in one block affects adjacent blocks\n\n**Applied to model errors:**\n\n- If nearby houses have similar errors...\n- ...our model is missing a spatial pattern!\n- Need to add more spatial features or fixed effects\n\n## Visualizing Error Patterns\n\n**Map your errors to see patterns:**\n\n```{r}\nlibrary(sf)\noptions(scipen = 999)\n# Convert boston data to sf object\nboston_test <- boston_test %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102286')  # MA State Plane (feet)\n\n\n# Install if needed: install.packages(\"hexbin\")\nlibrary(hexbin)\n\nggplot(boston_test) +\n  geom_sf(aes(fill = error),\n          shape = 21,\n          size = 1,\n          alpha = 0.6,\n          stroke = 0.2) +\n  scale_fill_gradient2(\n    low = \"blue\",\n    mid = \"white\",\n    high = \"red\",\n    midpoint = 0,\n    limits = c(-300000, 300000),\n    oob = scales::squish\n  ) +\n  theme_void()\n```\n\n**What to look for:**\n\n- Blue clusters (we under-predict)\n- Red clusters (we over-predict)\n- Random scatter (good!)\n\n## Scatter Plot: Spatial Lag of Errors\n\n**Create the spatial lag:**\n\n```{r}\n#| eval: true\n#| echo: true\nlibrary(spdep)\n\n# Define neighbors (5 nearest)\ncoords <- st_coordinates(boston_test)\nneighbors <- knn2nb(knearneigh(coords, k=5))\nweights <- nb2listw(neighbors, style=\"W\")\n\n# Calculate spatial lag of errors\nboston_test$error_lag <- lag.listw(weights, boston_test$error)\n```\n\n**Then plot:**\n\n```{r}\nggplot(boston_test, aes(x=error_lag, y=error)) +\n  geom_point(alpha=0.5) +\n  geom_smooth(method=\"lm\", color=\"red\") +\n  labs(title=\"Is my error correlated with neighbors' errors?\",\n       x=\"Avg error of 5 nearest neighbors\",\n       y=\"My error\")\n```\n\n---\n\n# Part 3: Moran's I\n\n## What is Moran's I?\n\n**Moran's I** measures spatial autocorrelation\n\n**Range:** -1 to +1\n\n- **+1** = Perfect positive correlation (clustering)\n- **0** = Random spatial pattern\n- **-1** = Perfect negative correlation (dispersion)\n\n**Formula (look's scary, but its so intuitive!):**\n\n$$I = \\frac{n \\sum_i \\sum_j w_{ij}(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i \\sum_j w_{ij} \\sum_i (x_i - \\bar{x})^2}$$\n\nWhere $w_{ij}$ = spatial weight between locations *i* and *j*\n\n## Worked Example: Understanding the Formula\n\n**5 houses in a row, predicting sale prices:**\n\n| House | Actual Price | Predicted Price | Error | \n|-------|-------------|-----------------|-------|\n| A     | $500k       | $400k          | +$100k |\n| B     | $480k       | $400k          | +$80k  |\n| C     | $420k       | $400k          | +$20k  |\n| D     | $350k       | $400k          | -$50k  |\n| E     | $330k       | $400k          | -$70k  |\n\n**Mean error = +$16k**\n\n**The question:** Are errors for nearby houses similar to each other?\n\n---\n\n## Step 1: Calculate Deviations from Mean\n\n**Subtract the mean error from each house's error:**\n\n| House | Error | Mean Error | Deviation from Mean |\n|-------|-------|------------|-------------------|\n| A     | +$100k | +$16k     | +$84k            |\n| B     | +$80k  | +$16k     | +$64k            |\n| C     | +$20k  | +$16k     | +$4k             |\n| D     | -$50k  | +$16k     | -$66k            |\n| E     | -$70k  | +$16k     | -$86k            |\n\n**Positive deviation** = we over-predicted (actual > predicted)  \n**Negative deviation** = we under-predicted (actual < predicted)\n\n---\n\n## Step 2: Multiply Neighbor Deviations\n\n**For each neighbor pair, multiply their deviations:**\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Neighbor Pairs:**\n\n- A-B: $(+84k) \\times (+64k) = +5,376$\n- B-C: $(+64k) \\times (+4k) = +256$\n- C-D: $(+4k) \\times (-66k) = -264$\n- D-E: $(-66k) \\times (-86k) = +5,676$\n\n**Sum of products = 11,044**\n:::\n\n::: {.column width=\"50%\"}\n**What does this mean?**\n\n**Positive products** = similar neighbors\n- A-B: both over-predicted (both positive)\n- D-E: both under-predicted (both negative)\n\n**Negative product** = dissimilar neighbors  \n- C-D: one over, one under\n\n**The pattern:** High-error houses cluster together, low-error houses cluster together\n:::\n::::\n\n---\n\n## The Intuition Behind Moran's I\n\n**The formula is really just asking:**\n\n> _\"When I'm above/below average, are my neighbors also above/below average?\"_\n\n**Breaking it down:**\n\n1. $(x_i - \\bar{x})$ = How far is my house's error from the mean?\n\n2. $(x_j - \\bar{x})$ = How far is my neighbor's error from the mean?\n\n3. **Multiply them:**\n   - If both positive or both negative â†’ **positive product** (similar)\n   - If opposite signs â†’ **negative product** (dissimilar)\n\n4. **Sum across all neighbor pairs** and normalize\n\n**Result:**\n\n- Lots of positive products â†’ **High Moran's I** (clustering)\n- Products near zero â†’ **Low Moran's I** (random)\n- Negative products â†’ **Negative Moran's I** (rare with errors)\n\n---\n\n## The Intuition Behind Moran's I\n\n**The formula is really just asking:**\n\n> *\"When I'm above/below average, are my neighbors also above/below average?\"*\n\n**Breaking it down:**\n\n1. $(x_i - \\bar{x})$ = How far am I from the mean?\n2. $(x_j - \\bar{x})$ = How far is my neighbor from the mean?\n\n3. **Multiply them:** \n\n   - If both positive or both negative â†’ **positive product** (similar)\n   - If opposite signs â†’ **negative product** (dissimilar)\n   \n4. **Sum across all neighbor pairs** and normalize\n\n**Result:**\n\n- Lots of positive products â†’ **High Moran's I** (clustering)\n- Products near zero â†’ **Low Moran's I** (random)\n- Negative products â†’ **Negative Moran's I** (rare with errors)\n\n\n## Defining \"Neighbors\"\n\n**Different ways to define spatial relationships:**\n\n::: {.columns}\n::: {.column width=\"33%\"}\n**Contiguity**\n\n- Polygons that share a border\n- Queen vs. Rook\n:::\n\n::: {.column width=\"33%\"}\n**Distance**\n\n- All within X meters\n- Fixed threshold\n:::\n\n::: {.column width=\"33%\"}\n**k-Nearest**\n\n- Closest k points\n- Adaptive distance\n:::\n:::\n\n**For point data (houses), use k-nearest neighbors**\n\n```{r}\n#| eval: true\n#| echo: true\n# Create 5-nearest neighbors\ncoords <- st_coordinates(boston_test)\nnb <- knn2nb(knearneigh(coords, k=5))\nweights <- nb2listw(nb, style=\"W\")\n```\n\n## Calculating Spatial Lag\n\n**Spatial lag** = average value of neighbors\n\n::: {.callout-tip}\n## Example: 5 houses\n\n| House | Sale Price | 2 Nearest | Spatial Lag |\n|-------|-----------|-----------|-------------|\n| A     | $200k     | B, C      | $275k       |\n| B     | $250k     | A, C      | $250k       |\n| C     | $300k     | B, D      | $275k       |\n| D     | $350k     | C, E      | $350k       |\n| E     | $400k     | D         | $350k       |\n:::\n\n**In R:**\n\n```{r}\n#| eval: true\n#| echo: true\nboston$price_lag <- lag.listw(weights, boston$SalePrice)\n```\n\n## Computing Moran's I\n\n**Calculate Moran's I for your errors:**\n\n```{r}\n#| eval: true\n#| echo: true\n# Test for spatial autocorrelation in errors\nmoran_test <- moran.mc(\n  boston_test$error,        # Your errors\n  weights,                  # Spatial weights matrix\n  nsim = 999                # Number of permutations\n)\n\n# View results\nmoran_test$statistic         # Moran's I value\nmoran_test$p.value          # Is it significant?\n```\n\n**Interpretation:**\n\n- **I > 0** and *p* < 0.05 â†’ Significant clustering\n- **I â‰ˆ 0** â†’ Random pattern (good!)\n- **I < 0** â†’ Dispersion (rare with errors)\n\n## Visualizing Significance\n\n**Compare observed I to random permutations:**\n\n```{r}\n#| eval: true\n#| echo: false\nlibrary(ggplot2)\n\nmoran_df <- data.frame(sim_I = moran_test$res[1:999])\n\nggplot(moran_df, aes(x = sim_I)) +\n  geom_histogram(binwidth = 0.01, fill = \"gray70\", color = \"white\") +\n  geom_vline(aes(xintercept = moran_test$statistic), \n             color = \"#FA7800\", linewidth = 1.5) +\n  labs(\n    title = \"Observed vs. Expected Moran's I\",\n    subtitle = \"Orange line = observed | Gray = random permutations\",\n    x = \"Moran's I\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n```\n\n## What Moran's I Tells You\n\n::: {.callout-important}\n## Decision Framework\n\n**If Moran's I is high (errors clustered):**\n\n1. Add more spatial features\n   - Try different buffer sizes\n   - Include more amenities/disamenities\n   - Create neighborhood-specific variables\n\n2. Try spatial fixed effects\n   - Neighborhood dummies\n   - Grid cell dummies\n\n3. Consider spatial regression models\n   - Spatial lag model\n   - Spatial error model\n   - (Advanced topic, not covered today)\n:::\n\n**If Moran's I â‰ˆ 0 (random errors):**\n\nâœ… Your model adequately captures spatial relationships!\n\n---\n\n## \"What About Spatial Lag/Error Models?\" {.smaller}\n\n*\"In my spatial statistics class, I learned about spatial lag and spatial error models for dealing with spatial autocorrelation. Why aren't we using those here?\"*\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **Spatial Econometrics Models**\n**(Spatial Statistics Class)**\n\n**Spatial Lag Model:** $Y_i = \\rho WY + \\beta X_i + \\varepsilon$\n\n**Spatial Error Model:** $Y_i = \\beta X_i + \\lambda W\\varepsilon + \\xi$\n\n**Purpose:** \n\n- Causal inference with spatial spillovers\n- Understanding neighbor effects\n- Correct standard errors for hypothesis testing\n- Cross-sectional analysis\n\n**When to use:** Academic research on spillover effects, peer influence, regional economics\n:::\n\n::: {.column width=\"50%\"}\n### **Predictive Spatial Features**\n**(This Class)**\n\n**Our Approach:** \n$$Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2(\\text{crimes}_{500ft}) + \\beta_3(\\text{dist}_{downtown}) + \\varepsilon_i$$\n\n**Purpose:**\n\n- Out-of-sample prediction\n- Forecasting new observations  \n- Applied machine learning\n- Generalization to new areas\n\n**When to use:** Real estate prediction, housing market forecasting, policy planning\n:::\n::::\n\n---\n\n## Why Not Spatial Lag Models for Prediction? {.smaller}\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **The Problems with Spatial Lag for Prediction:**\n\n**1. Simultaneity Problem**\n\n- Including $WY$ (neighbor prices) creates circular logic\n- My price affects neighbors â†’ neighbors affect me\n- OLS estimates are **biased and inconsistent**\n\n**2. Prediction Paradox**\n\n- Need neighbors' prices to predict my price\n- But for new developments or future periods, those prices **don't exist yet**\n- Can't generalize to truly new areas\n\n**3. Data Leakage in CV**\n\n- Geographic CV holds out spatial regions\n- Spatial lag \"leaks\" information from test set\n- Artificially good performance that won't hold\n:::\n\n::: {.column width=\"50%\"}\n### **Our Solution: Spatial Features of X (Not Y)**\n\nInstead of modeling dependence in **Y** (prices), model proximity in **X** (predictors)\n\n| âŒ Spatial Lag | âœ… Our Approach |\n|----------------|-----------------|\n| \"Near expensive houses\" | \"Near low crime areas\" |\n| Uses neighbor **prices** | Uses neighbor **characteristics** |\n| Circular logic | Causal mechanism |\n| Can't predict new areas | Generalizes well |\n\n**If Moran's I shows clustered errors:**\n\nâœ… **Add more spatial features** (different buffers, more amenities)  \nâœ… **Try neighborhood fixed effects**  \nâœ… **Use spatial cross-validation**\n\nâŒ Don't add spatial lag of Y for prediction purposes\n\n::: {.callout-tip}\n## **The Bottom Line**\nBoth approaches are valid for different goals! Match method to purpose: **inference** â†’ spatial lag/error models; **prediction** â†’ spatial features.\n:::\n:::\n::::\n\n---\n\n## Quick Clarification: Biased vs. Inconsistent {.smaller}\n\nWhen we say OLS estimates are **\"biased and inconsistent\"** with spatial lag models, what does that mean?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n### **Biased Estimator**\n\n**Definition:** Expected value â‰  true parameter\n\n$$E[\\hat{\\beta}] \\neq \\beta$$\n\n**What this means:**\n\n- On average, across all possible samples, your estimate is **systematically wrong**\n- Doesn't get the right answer even in expectation\n- More data doesn't fix it\n\n**Example:**\n\n- True effect: Î² = 100\n- Your estimates average to: 80\n- You're systematically **20 units off**\n:::\n\n::: {.column width=\"50%\"}\n### **Inconsistent Estimator**\n\n**Definition:** Doesn't converge to true value as n â†’ âˆž\n\n$$\\hat{\\beta} \\not\\to \\beta \\text{ as } n \\to \\infty$$\n\n**What this means:**\n\n- Even with **infinite data**, you won't get the right answer\n- The problem doesn't go away with bigger samples\n- Violates a fundamental property of good estimators\n\n**Example:**\n- n = 100 â†’ estimate = 80\n- n = 10,000 â†’ estimate = 82\n- n = 1,000,000 â†’ estimate = 84\n- Never reaches true value of 100\n:::\n::::\n\n---\n\n# Summary & Next Steps\n\n## Key Takeaways\n\n**Spatial autocorrelation in errors indicates model misspecification**\n\n**Moran's I is a diagnostic tool:**\n\n- Global I: overall clustering\n- Maps of residuals give clues to what you might be missing\n\n**Iterative improvement:**\n\n- Diagnose â†’ Engineer features â†’ Re-test â†’ Repeat\n- Document what you try!\n\n\n\n## Resources\n\n**Spatial autocorrelation:**\n- [https://mgimond.github.io/Spatial/spatial-autocorrelation.html](https://mgimond.github.io/Spatial/spatial-autocorrelation.html)\n\n**spdep package:**\n- [https://r-spatial.github.io/spdep/](https://r-spatial.github.io/spdep/)\n\n---\n\n# Questions Before Work Time?\n\nCome see me during the work session for:\n\n- Help with Moran's I calculation\n- Ideas for new spatial features\n- Debugging code issues\n- Discussing your model strategy\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":false,"output-file":"week7_slides.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.24","auto-stretch":true,"title":"Model Diagnostics & Spatial Autocorrelation","subtitle":"Week 7: MUSA 5080","author":"Dr. Elizabeth Delmelle","date":"October 21, 2025","theme":"simple","slideNumber":true,"chalkboard":true,"smaller":true,"scrollable":true}}},"projectFormats":["html"]}